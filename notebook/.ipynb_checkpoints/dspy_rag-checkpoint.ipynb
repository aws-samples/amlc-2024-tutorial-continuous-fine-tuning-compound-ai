{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b5e70f0",
   "metadata": {},
   "source": [
    "# RAG and prompt automation in dspy\n",
    "\n",
    "In this notebook, we implement RAG pipeline and RAG compiled with prompt automation with DSPy on Amazon Bedrock. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ecaec9-7ea9-4267-bdc7-009f7f7c41c1",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af62fea",
   "metadata": {},
   "source": [
    "Uncomment the following lines if the packages are not installed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15443e45-c466-4fea-8678-867bbfcd2119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install langchain\n",
    "!pip3 install -U langchain-community\n",
    "!pip3 install pypdf\n",
    "!pip3 install chromadb\n",
    "!pip3 install dspy\n",
    "!pip3 install dspy-ai[faiss-cpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8dc840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys\n",
    "import io, base64\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from PIL import Image as PILImage\n",
    "import unicodedata\n",
    "from IPython.display import Markdown\n",
    "import boto3\n",
    "import dspy\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json, os, shutil\n",
    "import boto3, re, os, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628e13c8",
   "metadata": {},
   "source": [
    "Environment setup : clean up temporary trace files and data files , set up loggers, bedrock session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18d1d05-82aa-48ab-9b5c-4aa987e3095b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_up_files_in_dir(dir):\n",
    "    # cleanup trace files to avoid issues\n",
    "    if os.path.isdir(dir):\n",
    "        shutil.rmtree(dir)\n",
    "    os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8334784d-36c6-4735-b7b6-bf2e9fed7d13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_up_files_in_dir('./cuad_db')\n",
    "clean_up_files_in_dir('./trace_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94d3123f-3994-4cb5-8fd3-9420d85e59b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting logging\n",
    "logging.basicConfig(filename='lab2_trace.log', \n",
    "                    filemode='a', \n",
    "                    encoding='utf-8',\n",
    "                    format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', \n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91d0d213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "boto_session = boto3.session.Session()\n",
    "region_name = boto_session.region_name\n",
    "print(region_name)\n",
    "\n",
    "session = boto3.Session()\n",
    "\n",
    "bedrock = session.client(\"bedrock\", region_name=region_name)\n",
    "br = session.client(\"bedrock-runtime\", region_name=region_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd73fc2-12d9-4cb8-9ec6-97f2cbbc1af7",
   "metadata": {},
   "source": [
    "### DSPy Language Model and Retriever Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aef97f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_sonnet_model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "clade_haiku_model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "titan_embed_model_id = \"amazon.titan-embed-text-v2:0\"\n",
    "mistral_7b_model_id = \"mistral.mistral-7b-instruct-v0:2\"\n",
    "llama_8b_model_id = \"meta.llama3-8b-instruct-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba5b60c-ae34-4f62-9fdc-17fa894cb90a",
   "metadata": {},
   "source": [
    "##### DSPy Initialization requires you to explicitly set the reion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c10beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp_bedrock = dspy.Bedrock(region_name=region_name)\n",
    "\n",
    "bedrock_sonnet = dspy.AWSAnthropic(aws_provider=dsp_bedrock,\n",
    "                                  model=claude_sonnet_model_id,\n",
    "                                  max_new_tokens=4096,\n",
    "                                  max_tokens=4096)\n",
    "\n",
    "bedrock_mistral_7b = dspy.AWSMistral(aws_provider=dsp_bedrock,\n",
    "                                 model=mistral_7b_model_id,\n",
    "                                 max_new_tokens=4096,\n",
    "                                 max_tokens=4096)\n",
    "\n",
    "bedrock_haiku = dspy.AWSAnthropic(aws_provider=dsp_bedrock,\n",
    "                                 model=clade_haiku_model_id,\n",
    "                                 max_new_tokens=4096,\n",
    "                                 max_tokens=4096)\n",
    "\n",
    "bedrock_llama_8b = dspy.AWSMeta(aws_provider=dsp_bedrock, \n",
    "                                model=llama_8b_model_id,\n",
    "                                max_new_tokens=2048,\n",
    "                                max_tokens=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a8a09-38b0-4afb-97f9-bf2f43295d4e",
   "metadata": {},
   "source": [
    "### Splitters and chunking configuration    \n",
    "\n",
    "We will be using the RecursiveCharacterTextSplitter to generate logical and syntactically readable chunks. The size and overlap percentage can be empirically determined based on the dataset. For more flexibility it is possible to generate multiple files from the dataset file and make 1 file 1 chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81f46be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader, CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load documents \n",
    "loader = PyPDFLoader(\"../cuad_data/CUAD_v1/full_contract_pdf/Part_I/Strategic Alliance//ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALLIANCE AGREEMENT.PDF\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Split documents by setting chunk size\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \" \",\n",
    "        \".\",\n",
    "        \",\",\n",
    "        \"\\u200b\",  # Zero-width space\n",
    "        \"\\uff0c\",  # Fullwidth comma\n",
    "        \"\\u3001\",  # Ideographic comma\n",
    "        \"\\uff0e\",  # Fullwidth full stop\n",
    "        \"\\u3002\",  # Ideographic full stop\n",
    "        \"\",\n",
    "    ],\n",
    "    chunk_size = 5000,      \n",
    "    chunk_overlap = 30, \n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd6567a-39ae-4460-9a22-fc9a56152acc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clean and remove any empty pages in the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b0bc88d-95e4-472a-a554-34ac23914928",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n",
    "clean_docs = []\n",
    "for doc in docs:\n",
    "    if len(doc.page_content):\n",
    "        clean_docs.append(doc)\n",
    "\n",
    "docs = clean_docs\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667df598-ff47-49b9-9b4f-523eb83f288c",
   "metadata": {},
   "source": [
    "### Setup Retriever on local disk using ChromaDB    \n",
    "\n",
    "We are using chromaDB to demonstrate the use of vector databases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "407e2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.utils.embedding_functions import AmazonBedrockEmbeddingFunction\n",
    "\n",
    "bedrock_ef = AmazonBedrockEmbeddingFunction(session=session, model_name=titan_embed_model_id)\n",
    "\n",
    "bedrock_embeddings = bedrock_ef([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbfca2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "\n",
    "collection_name=\"contexts\"\n",
    "persist_dir=\"cuad_db/\"\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(persist_dir)\n",
    "collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "if collection.count() == 0:\n",
    "    collection.add(embeddings=bedrock_embeddings,\n",
    "                   documents=[doc.page_content for doc in docs],\n",
    "                   ids=[str(i) for i in range(len(docs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f559d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = ChromadbRM(collection_name=collection_name, \n",
    "                persist_directory=persist_dir, \n",
    "                embedding_function=bedrock_ef,\n",
    "                k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a7249f-d8c2-4afd-8c3e-06767c7c254c",
   "metadata": {},
   "source": [
    "### Dataset setup in DSPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa7e2ab",
   "metadata": {},
   "source": [
    "\n",
    "Contract Understanding Atticus Dataset (CUAD) is a dataset for legal contract review. CUAD was created with dozens of legal experts from The Atticus Project and consists of over 13,000 annotations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d932a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>input</th>\n",
       "      <th>answer</th>\n",
       "      <th>qa_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What is The name of the contract?</td>\n",
       "      <td>Highlight the parts (if any) of this contract ...</td>\n",
       "      <td>STRATEGIC ALLIANCE AGREEMENT</td>\n",
       "      <td>ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is The two or more parties who signed the...</td>\n",
       "      <td>Highlight the parts (if any) of this contract ...</td>\n",
       "      <td>Dialog Semiconductor (UK) Ltd., DIALOG, Energo...</td>\n",
       "      <td>ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What is The date of the contract?</td>\n",
       "      <td>Highlight the parts (if any) of this contract ...</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What is The date when the contract is effective?</td>\n",
       "      <td>Highlight the parts (if any) of this contract ...</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>On what date will the contract's initial term ...</td>\n",
       "      <td>Highlight the parts (if any) of this contract ...</td>\n",
       "      <td>Unless earlier terminated as provided herein, ...</td>\n",
       "      <td>ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           question  \\\n",
       "0      0                  What is The name of the contract?   \n",
       "1      1  What is The two or more parties who signed the...   \n",
       "2      2                  What is The date of the contract?   \n",
       "3      3   What is The date when the contract is effective?   \n",
       "4      4  On what date will the contract's initial term ...   \n",
       "\n",
       "                                               input  \\\n",
       "0  Highlight the parts (if any) of this contract ...   \n",
       "1  Highlight the parts (if any) of this contract ...   \n",
       "2  Highlight the parts (if any) of this contract ...   \n",
       "3  Highlight the parts (if any) of this contract ...   \n",
       "4  Highlight the parts (if any) of this contract ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0                       STRATEGIC ALLIANCE AGREEMENT   \n",
       "1  Dialog Semiconductor (UK) Ltd., DIALOG, Energo...   \n",
       "2                                   November 6, 2016   \n",
       "3                                   November 6, 2016   \n",
       "4  Unless earlier terminated as provided herein, ...   \n",
       "\n",
       "                                               qa_id  \n",
       "0  ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...  \n",
       "1  ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...  \n",
       "2  ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...  \n",
       "3  ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...  \n",
       "4  ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRN_FILE = '../cuad_data/CUAD_v1/ENERGOUSCORP_qa.csv'\n",
    "df_cuad_data = pd.read_csv(TRN_FILE)\n",
    "df_cuad_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "175a1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cuad = []\n",
    "\n",
    "for index, question, input, answer, qa_id in df_cuad_data.values:\n",
    "    dataset_cuad.append(dspy.Example(question=question, answer=answer).with_inputs(\"question\"))\n",
    "\n",
    "trainset = [x.with_inputs('question') for x in dataset_cuad[0:28]]\n",
    "devset = [x.with_inputs('question') for x in dataset_cuad[28:32]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f116218-8301-4274-8186-c223184ba862",
   "metadata": {},
   "source": [
    "### Factuality Judge and Metrics setup (LLM as a judge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4004b00d",
   "metadata": {},
   "source": [
    "We will now create a Factuality Judge that will adjudicate if the predicted answer factually correct to the groundtruth answer and means the same as the groundtruth answer.\n",
    "\n",
    "A new factuality metric is created to mark whether the predicted answer is True or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "624ed66e-31f0-4efc-a4ea-34d65f2c226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactJudge(dspy.Signature):\n",
    "    \"\"\"Judge if the predicted answer factually correct to the groundtruth answer and same as groundtruth answer. Answer either Factual[True] or Factual[False]\"\"\"\n",
    "\n",
    "    question = dspy.InputField(desc=\"Question to be answered\")\n",
    "    groundtruth_answer = dspy.InputField(desc=\"groundtruth answer for the question\")\n",
    "    predicted_answer = dspy.InputField(desc=\"predicted answer for the question\")\n",
    "    factually_correct = dspy.OutputField(desc=\"Is the predicted answer factually correct to the groundtruth answer and same as groundtruth answer ?\", prefix=\"Factual[True/False]:\")\n",
    "\n",
    "\n",
    "judge = dspy.ChainOfThought(FactJudge)\n",
    "\n",
    "\n",
    "def factuality_metric(example, pred):\n",
    "    factual = judge(question=example.question, groundtruth_answer=example.answer, predicted_answer=pred.answer) #context=pred.context, \n",
    "    #logging.info(f\"\\n factual LLM judge {factual}\")\n",
    "    #logging.info(f\"\\n example.answer {example.answer}\")\n",
    "    #logging.info(f\"\\n pred.answer {pred.answer}\")\n",
    "    llm_judge_ans = bool(\"Factual[True]\" in factual.factually_correct \n",
    "                         or '100% True' in factual.factually_correct\n",
    "                         or '100% factually correct' in factual.factually_correct\n",
    "                         or factual.factually_correct=='True') #or \"correct\" in factual.factually_correct.lower()\n",
    "    print(f\"llm_judge_ans = {llm_judge_ans}\")\n",
    "    logging.info(f\"llm_judge_ans = {llm_judge_ans}\")\n",
    "    return llm_judge_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c9162c-171a-43ca-8ac5-3ac9f934464e",
   "metadata": {},
   "source": [
    "### LLM as a judge evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcea61d2",
   "metadata": {},
   "source": [
    "Let us setup the metric, dataset and RAG pipeline with input and output fields. Then we customize how to validate where we can combine multiple metrics to come up with the final output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "160bac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "# Evaluation\n",
    "metric_LLM = factuality_metric\n",
    "\n",
    "evaluate_cuad = Evaluate(devset=dataset_cuad, metric=metric_LLM, num_threads=1, display_progress=True, display_table=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed47f29",
   "metadata": {},
   "source": [
    "### Setup RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "354c2fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG pipeline\n",
    "\n",
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4067df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        #self.retrieve = ChromadbRM(\"contexts\", \"./chroma\", k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        #context = self.retrieve(question).passages\n",
    "        context = [unicodedata.normalize(\"NFKD\", r) for r in self.retrieve(question).passages]\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d63ea122-1bfd-4a26-910c-22b6607ae31a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "        answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "        answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "        answer_LLMJudge = factuality_metric(example, pred)\n",
    "\n",
    "        logging.info(f\"\\n example question :: {example.question} , example answer :: {example.answer} \")\n",
    "        logging.info(f\"\\n pred answer :: {pred.answer}\")\n",
    "        logging.info(f\"\\n answer_EM :: {answer_EM}, answer_PM ::{answer_PM} answer_LLMJudge :: {answer_LLMJudge}\")\n",
    "        return answer_LLMJudge or answer_EM or answer_PM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d102b8e-e386-488a-8408-8c30721b95fa",
   "metadata": {},
   "source": [
    "### Raw Model Evaluation and Compiled Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ffdb4",
   "metadata": {},
   "source": [
    "We will compare the performance against the raw and compiled DSPy network in this section with different model families and sub-types. Here we try out Haiku, Sonnet and Mistral 7B. This will take some time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0fbc18b-d79c-445f-839d-92edbb20f8a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_csv(rag_lm, model_id):\n",
    "    # Loop and generate CSV\n",
    "\n",
    "    csv_list = list()\n",
    "    for index, question, input, answer, qa_id in df_cuad_data.values:\n",
    "        # Get the prediction. This contains `pred.context` and `pred.answer`.\n",
    "        pred = rag_lm(question)\n",
    "        csv_list.append([question, answer, pred.answer])\n",
    "\n",
    "    df = pd.DataFrame(csv_list, columns=['question', 'gt_answer', 'pred_answer'])\n",
    "    df.to_csv(f\"RAG_{model_id}.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de27f40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START OF model_id = anthropic.claude-3-haiku-20240307-v1:0 --------------->\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated, underperform, and are about to be deleted. ***\n",
      " \t\tYou are using the client AWSAnthropic, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n",
      "  0%|          | 0/32 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 32 (0.0%):   3%|▎         | 1/32 [00:03<01:53,  3.65s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):   3%|▎         | 1/32 [00:07<01:53,  3.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 32 (0.0%):   6%|▋         | 2/32 [00:07<01:45,  3.53s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):   6%|▋         | 2/32 [00:10<01:45,  3.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 32 (0.0%):   9%|▉         | 3/32 [00:10<01:41,  3.49s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):   9%|▉         | 3/32 [00:14<01:41,  3.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 32 (0.0%):  12%|█▎        | 4/32 [00:14<01:38,  3.53s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  12%|█▎        | 4/32 [00:17<01:38,  3.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 32 (0.0%):  16%|█▌        | 5/32 [00:17<01:38,  3.64s/it]llm_judge_ans = True\n",
      "Average Metric: 0.00 / 32 (0.0%):  16%|█▌        | 5/32 [00:21<01:38,  3.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):  19%|█▉        | 6/32 [00:21<01:34,  3.63s/it]llm_judge_ans = True\n",
      "Average Metric: 1.00 / 32 (3.1%):  19%|█▉        | 6/32 [00:24<01:34,  3.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 32 (6.2%):  22%|██▏       | 7/32 [00:24<01:26,  3.48s/it]llm_judge_ans = True\n",
      "Average Metric: 2.00 / 32 (6.2%):  22%|██▏       | 7/32 [00:28<01:26,  3.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 32 (9.4%):  25%|██▌       | 8/32 [00:28<01:27,  3.63s/it]llm_judge_ans = True\n",
      "Average Metric: 3.00 / 32 (9.4%):  25%|██▌       | 8/32 [00:33<01:27,  3.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 32 (12.5%):  28%|██▊       | 9/32 [00:33<01:34,  4.09s/it]llm_judge_ans = True\n",
      "Average Metric: 4.00 / 32 (12.5%):  28%|██▊       | 9/32 [00:38<01:34,  4.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 32 (15.6%):  31%|███▏      | 10/32 [00:38<01:36,  4.36s/it]llm_judge_ans = True\n",
      "Average Metric: 5.00 / 32 (15.6%):  31%|███▏      | 10/32 [00:42<01:36,  4.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 32 (18.8%):  34%|███▍      | 11/32 [00:42<01:26,  4.12s/it]llm_judge_ans = True\n",
      "Average Metric: 6.00 / 32 (18.8%):  34%|███▍      | 11/32 [00:46<01:26,  4.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 32 (21.9%):  38%|███▊      | 12/32 [00:46<01:21,  4.09s/it]llm_judge_ans = True\n",
      "Average Metric: 7.00 / 32 (21.9%):  38%|███▊      | 12/32 [00:50<01:21,  4.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 32 (25.0%):  41%|████      | 13/32 [00:50<01:19,  4.19s/it]llm_judge_ans = True\n",
      "Average Metric: 8.00 / 32 (25.0%):  41%|████      | 13/32 [00:54<01:19,  4.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 32 (28.1%):  44%|████▍     | 14/32 [00:54<01:12,  4.03s/it]llm_judge_ans = True\n",
      "Average Metric: 9.00 / 32 (28.1%):  44%|████▍     | 14/32 [00:58<01:12,  4.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 32 (31.2%):  47%|████▋     | 15/32 [00:58<01:10,  4.14s/it]llm_judge_ans = False\n",
      "Average Metric: 10.00 / 32 (31.2%):  47%|████▋     | 15/32 [01:03<01:10,  4.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 32 (31.2%):  50%|█████     | 16/32 [01:03<01:07,  4.24s/it]llm_judge_ans = True\n",
      "Average Metric: 10.00 / 32 (31.2%):  50%|█████     | 16/32 [01:07<01:07,  4.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 32 (34.4%):  53%|█████▎    | 17/32 [01:07<01:01,  4.08s/it]llm_judge_ans = True\n",
      "Average Metric: 11.00 / 32 (34.4%):  53%|█████▎    | 17/32 [01:12<01:01,  4.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 32 (37.5%):  56%|█████▋    | 18/32 [01:12<01:01,  4.42s/it]llm_judge_ans = False\n",
      "Average Metric: 12.00 / 32 (37.5%):  56%|█████▋    | 18/32 [01:16<01:01,  4.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 32 (37.5%):  59%|█████▉    | 19/32 [01:16<00:56,  4.34s/it]llm_judge_ans = False\n",
      "Average Metric: 12.00 / 32 (37.5%):  59%|█████▉    | 19/32 [01:19<00:56,  4.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 32 (37.5%):  62%|██████▎   | 20/32 [01:19<00:47,  3.97s/it]llm_judge_ans = True\n",
      "Average Metric: 12.00 / 32 (37.5%):  62%|██████▎   | 20/32 [01:22<00:47,  3.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 32 (40.6%):  66%|██████▌   | 21/32 [01:22<00:41,  3.75s/it]llm_judge_ans = True\n",
      "Average Metric: 13.00 / 32 (40.6%):  66%|██████▌   | 21/32 [01:26<00:41,  3.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 32 (43.8%):  69%|██████▉   | 22/32 [01:26<00:38,  3.88s/it]llm_judge_ans = True\n",
      "Average Metric: 14.00 / 32 (43.8%):  69%|██████▉   | 22/32 [01:31<00:38,  3.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 32 (46.9%):  72%|███████▏  | 23/32 [01:31<00:37,  4.16s/it]llm_judge_ans = True\n",
      "Average Metric: 15.00 / 32 (46.9%):  72%|███████▏  | 23/32 [01:36<00:37,  4.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 32 (50.0%):  75%|███████▌  | 24/32 [01:36<00:35,  4.40s/it]llm_judge_ans = True\n",
      "Average Metric: 16.00 / 32 (50.0%):  75%|███████▌  | 24/32 [01:40<00:35,  4.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 32 (53.1%):  78%|███████▊  | 25/32 [01:40<00:30,  4.37s/it]llm_judge_ans = True\n",
      "Average Metric: 17.00 / 32 (53.1%):  78%|███████▊  | 25/32 [01:45<00:30,  4.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 32 (56.2%):  81%|████████▏ | 26/32 [01:45<00:26,  4.45s/it]llm_judge_ans = True\n",
      "Average Metric: 18.00 / 32 (56.2%):  81%|████████▏ | 26/32 [01:49<00:26,  4.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 32 (59.4%):  84%|████████▍ | 27/32 [01:49<00:21,  4.33s/it]llm_judge_ans = False\n",
      "Average Metric: 19.00 / 32 (59.4%):  84%|████████▍ | 27/32 [01:53<00:21,  4.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 32 (59.4%):  88%|████████▊ | 28/32 [01:53<00:16,  4.25s/it]llm_judge_ans = True\n",
      "Average Metric: 19.00 / 32 (59.4%):  88%|████████▊ | 28/32 [01:57<00:16,  4.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%):  91%|█████████ | 29/32 [01:57<00:12,  4.13s/it]llm_judge_ans = True\n",
      "Average Metric: 20.00 / 32 (62.5%):  91%|█████████ | 29/32 [02:01<00:12,  4.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 32 (65.6%):  94%|█████████▍| 30/32 [02:01<00:08,  4.18s/it]llm_judge_ans = True\n",
      "Average Metric: 21.00 / 32 (65.6%):  94%|█████████▍| 30/32 [02:04<00:08,  4.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 32 (68.8%):  97%|█████████▋| 31/32 [02:04<00:03,  3.72s/it]llm_judge_ans = True\n",
      "Average Metric: 22.00 / 32 (68.8%):  97%|█████████▋| 31/32 [02:08<00:03,  3.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 32 (71.9%): 100%|██████████| 32/32 [02:08<00:00,  4.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 01:54:53 INFO dspy.evaluate.evaluate: Average Metric: 23 / 32 (71.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "raw_score for lm_id = anthropic.claude-3-haiku-20240307-v1:0 and raw_score =  71.88\n",
      "******* COMPILING model_id = anthropic.claude-3-haiku-20240307-v1:0 ******* --------------->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1/28 [00:03<01:36,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/28 [00:06<01:23,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3/28 [00:10<01:29,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/28 [00:14<01:29,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5/28 [00:19<01:37,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 6/28 [00:23<01:34,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7/28 [00:27<01:23,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n",
      "Bootstrapped 4 full traces after 7 examples for up to 1 rounds, amounting to 7 attempts.\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = True\n",
      "  0%|          | 0/32 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):   3%|▎         | 1/32 [00:04<02:13,  4.31s/it]llm_judge_ans = True\n",
      "Average Metric: 1.00 / 32 (3.1%):   3%|▎         | 1/32 [00:09<02:13,  4.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 32 (6.2%):   6%|▋         | 2/32 [00:09<02:23,  4.78s/it]llm_judge_ans = True\n",
      "Average Metric: 2.00 / 32 (6.2%):   6%|▋         | 2/32 [00:13<02:23,  4.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 32 (9.4%):   9%|▉         | 3/32 [00:13<02:08,  4.44s/it]llm_judge_ans = True\n",
      "Average Metric: 3.00 / 32 (9.4%):   9%|▉         | 3/32 [00:17<02:08,  4.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 32 (12.5%):  12%|█▎        | 4/32 [00:17<01:55,  4.14s/it]llm_judge_ans = True\n",
      "Average Metric: 4.00 / 32 (12.5%):  12%|█▎        | 4/32 [00:22<01:55,  4.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 32 (15.6%):  16%|█▌        | 5/32 [00:22<01:59,  4.42s/it]llm_judge_ans = True\n",
      "Average Metric: 5.00 / 32 (15.6%):  16%|█▌        | 5/32 [00:27<01:59,  4.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 32 (18.8%):  19%|█▉        | 6/32 [00:27<02:01,  4.67s/it]llm_judge_ans = True\n",
      "Average Metric: 6.00 / 32 (18.8%):  19%|█▉        | 6/32 [00:32<02:01,  4.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 32 (21.9%):  22%|██▏       | 7/32 [00:32<01:58,  4.72s/it]llm_judge_ans = True\n",
      "Average Metric: 7.00 / 32 (21.9%):  22%|██▏       | 7/32 [00:35<01:58,  4.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 32 (25.0%):  25%|██▌       | 8/32 [00:35<01:44,  4.34s/it]llm_judge_ans = False\n",
      "Average Metric: 8.00 / 32 (25.0%):  25%|██▌       | 8/32 [00:41<01:44,  4.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 32 (25.0%):  28%|██▊       | 9/32 [00:41<01:51,  4.86s/it]llm_judge_ans = True\n",
      "Average Metric: 8.00 / 32 (25.0%):  28%|██▊       | 9/32 [00:46<01:51,  4.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 32 (28.1%):  31%|███▏      | 10/32 [00:46<01:49,  5.00s/it]llm_judge_ans = False\n",
      "Average Metric: 9.00 / 32 (28.1%):  31%|███▏      | 10/32 [00:51<01:49,  5.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 32 (28.1%):  34%|███▍      | 11/32 [00:51<01:45,  5.04s/it]llm_judge_ans = False\n",
      "Average Metric: 9.00 / 32 (28.1%):  34%|███▍      | 11/32 [00:58<01:45,  5.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 32 (28.1%):  38%|███▊      | 12/32 [00:58<01:49,  5.50s/it]llm_judge_ans = True\n",
      "Average Metric: 9.00 / 32 (28.1%):  38%|███▊      | 12/32 [01:04<01:49,  5.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 32 (31.2%):  41%|████      | 13/32 [01:04<01:44,  5.52s/it]llm_judge_ans = True\n",
      "Average Metric: 10.00 / 32 (31.2%):  41%|████      | 13/32 [01:08<01:44,  5.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 32 (34.4%):  44%|████▍     | 14/32 [01:08<01:31,  5.09s/it]llm_judge_ans = True\n",
      "Average Metric: 11.00 / 32 (34.4%):  44%|████▍     | 14/32 [01:13<01:31,  5.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 32 (37.5%):  47%|████▋     | 15/32 [01:13<01:26,  5.06s/it]llm_judge_ans = True\n",
      "Average Metric: 12.00 / 32 (37.5%):  47%|████▋     | 15/32 [01:18<01:26,  5.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 32 (40.6%):  50%|█████     | 16/32 [01:18<01:22,  5.18s/it]llm_judge_ans = True\n",
      "Average Metric: 13.00 / 32 (40.6%):  50%|█████     | 16/32 [01:23<01:22,  5.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 32 (43.8%):  53%|█████▎    | 17/32 [01:23<01:17,  5.19s/it]llm_judge_ans = True\n",
      "Average Metric: 14.00 / 32 (43.8%):  53%|█████▎    | 17/32 [01:30<01:17,  5.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 32 (46.9%):  56%|█████▋    | 18/32 [01:30<01:16,  5.49s/it]llm_judge_ans = True\n",
      "Average Metric: 15.00 / 32 (46.9%):  56%|█████▋    | 18/32 [01:35<01:16,  5.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 32 (50.0%):  59%|█████▉    | 19/32 [01:35<01:11,  5.47s/it]llm_judge_ans = False\n",
      "Average Metric: 16.00 / 32 (50.0%):  59%|█████▉    | 19/32 [01:41<01:11,  5.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 32 (50.0%):  62%|██████▎   | 20/32 [01:41<01:06,  5.55s/it]llm_judge_ans = True\n",
      "Average Metric: 16.00 / 32 (50.0%):  62%|██████▎   | 20/32 [01:46<01:06,  5.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 32 (53.1%):  66%|██████▌   | 21/32 [01:46<00:58,  5.33s/it]llm_judge_ans = True\n",
      "Average Metric: 17.00 / 32 (53.1%):  66%|██████▌   | 21/32 [01:52<00:58,  5.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 32 (56.2%):  69%|██████▉   | 22/32 [01:52<00:55,  5.53s/it]llm_judge_ans = True\n",
      "Average Metric: 18.00 / 32 (56.2%):  69%|██████▉   | 22/32 [01:57<00:55,  5.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 32 (59.4%):  72%|███████▏  | 23/32 [01:57<00:48,  5.37s/it]llm_judge_ans = True\n",
      "Average Metric: 19.00 / 32 (59.4%):  72%|███████▏  | 23/32 [02:01<00:48,  5.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%):  75%|███████▌  | 24/32 [02:01<00:40,  5.10s/it]llm_judge_ans = True\n",
      "Average Metric: 20.00 / 32 (62.5%):  75%|███████▌  | 24/32 [02:05<00:40,  5.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 32 (65.6%):  78%|███████▊  | 25/32 [02:05<00:34,  4.90s/it]llm_judge_ans = True\n",
      "Average Metric: 21.00 / 32 (65.6%):  78%|███████▊  | 25/32 [02:10<00:34,  4.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 32 (68.8%):  81%|████████▏ | 26/32 [02:10<00:29,  4.84s/it]llm_judge_ans = True\n",
      "Average Metric: 22.00 / 32 (68.8%):  81%|████████▏ | 26/32 [02:15<00:29,  4.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 32 (71.9%):  84%|████████▍ | 27/32 [02:15<00:24,  4.82s/it]llm_judge_ans = False\n",
      "Average Metric: 23.00 / 32 (71.9%):  84%|████████▍ | 27/32 [02:20<00:24,  4.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 32 (71.9%):  88%|████████▊ | 28/32 [02:20<00:19,  4.79s/it]llm_judge_ans = False\n",
      "Average Metric: 23.00 / 32 (71.9%):  88%|████████▊ | 28/32 [02:25<00:19,  4.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23.00 / 32 (71.9%):  91%|█████████ | 29/32 [02:25<00:15,  5.02s/it]llm_judge_ans = True\n",
      "Average Metric: 23.00 / 32 (71.9%):  91%|█████████ | 29/32 [02:32<00:15,  5.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.00 / 32 (75.0%):  94%|█████████▍| 30/32 [02:32<00:10,  5.46s/it]llm_judge_ans = True\n",
      "Average Metric: 24.00 / 32 (75.0%):  94%|█████████▍| 30/32 [02:38<00:10,  5.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 32 (78.1%):  97%|█████████▋| 31/32 [02:38<00:05,  5.83s/it]llm_judge_ans = True\n",
      "Average Metric: 25.00 / 32 (78.1%):  97%|█████████▋| 31/32 [02:43<00:05,  5.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 32 (81.2%): 100%|██████████| 32/32 [02:43<00:00,  5.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 01:58:05 INFO dspy.evaluate.evaluate: Average Metric: 26 / 32 (81.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "compiled_score for COMPILED lm_id = anthropic.claude-3-haiku-20240307-v1:0 and raw_score =  81.25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Human: Judge if the predicted answer factually correct to the groundtruth answer and same as groundtruth answer. Answer either Factual[True] or Factual[False]\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: Question to be answered\n",
      "\n",
      "Groundtruth Answer: groundtruth answer for the question\n",
      "\n",
      "Predicted Answer: predicted answer for the question\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the factually_correct}. We ...\n",
      "\n",
      "Factual[True/False]: Is the predicted answer factually correct to the groundtruth answer and same as groundtruth answer ?\n",
      "\n",
      "---\n",
      "\n",
      "Question: Is there a requirement for insurance that must be maintained by one party for the benefit of the counterparty?\n",
      "\n",
      "Groundtruth Answer: Each party will maintain, during the Term and for three (3) years thereafter, such comprehensive general liability insurance (including without limitation, products liability) as will adequately protect it against its potential liabilities under this Agreement, in amounts customary in the semiconductor industry for similar services and products., Each party will, at the other party's request, provide to the other party a certificate of insurance evidencing the foregoing insurance coverage.\n",
      "\n",
      "Predicted Answer: Yes, the contract requires each party to maintain comprehensive general liability insurance, including products liability insurance, during the term of the agreement and for 3 years thereafter. This insurance must adequately protect each party against its potential liabilities under the agreement, in amounts customary in the semiconductor industry for similar services and products. Each party must provide the other party with a certificate of\n",
      "\n",
      "Reasoning: Let's think step by step in order to Factual[True]: The predicted answer is factually correct and the same as the groundtruth answer. The predicted answer accurately summarizes the key requirements for insurance that must be maintained by each party for the benefit of the counterparty, as stated in the groundtruth answer.\n",
      "\n",
      "Factual[True/False]:\n",
      "\n",
      "Assistant:\u001b[32mFactual[True]\n",
      "\n",
      "The predicted answer is factually correct and the same as the groundtruth answer. The predicted answer accurately summarizes the key requirements for insurance that must be maintained by each party for the benefit of the counterparty, as stated in the groundtruth answer.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "END OF model_id = anthropic.claude-3-haiku-20240307-v1:0 --------------->\n",
      "START OF model_id = anthropic.claude-3-sonnet-20240229-v1:0 --------------->\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = False\n",
      "  0%|          | 0/32 [00:11<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 32 (0.0%):   3%|▎         | 1/32 [00:11<06:00, 11.64s/it]llm_judge_ans = True\n",
      "Average Metric: 0.00 / 32 (0.0%):   3%|▎         | 1/32 [00:33<06:00, 11.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):   6%|▋         | 2/32 [00:33<08:46, 17.53s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):   6%|▋         | 2/32 [00:44<08:46, 17.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):   9%|▉         | 3/32 [00:44<07:04, 14.62s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):   9%|▉         | 3/32 [00:49<07:04, 14.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):  12%|█▎        | 4/32 [00:49<05:05, 10.91s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):  12%|█▎        | 4/32 [01:00<05:05, 10.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):  16%|█▌        | 5/32 [01:00<04:53, 10.86s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):  16%|█▌        | 5/32 [01:10<04:53, 10.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):  19%|█▉        | 6/32 [01:10<04:31, 10.43s/it]llm_judge_ans = True\n",
      "Average Metric: 1.00 / 32 (3.1%):  19%|█▉        | 6/32 [01:16<04:31, 10.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 32 (6.2%):  22%|██▏       | 7/32 [01:16<03:47,  9.10s/it]llm_judge_ans = False\n",
      "Average Metric: 2.00 / 32 (6.2%):  22%|██▏       | 7/32 [01:22<03:47,  9.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 32 (6.2%):  25%|██▌       | 8/32 [01:22<03:13,  8.04s/it]llm_judge_ans = True\n",
      "Average Metric: 2.00 / 32 (6.2%):  25%|██▌       | 8/32 [01:37<03:13,  8.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 32 (9.4%):  28%|██▊       | 9/32 [01:37<03:56, 10.27s/it]llm_judge_ans = False\n",
      "Average Metric: 3.00 / 32 (9.4%):  28%|██▊       | 9/32 [01:46<03:56, 10.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 32 (9.4%):  31%|███▏      | 10/32 [01:46<03:38,  9.95s/it]llm_judge_ans = False\n",
      "Average Metric: 3.00 / 32 (9.4%):  31%|███▏      | 10/32 [01:53<03:38,  9.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 32 (9.4%):  34%|███▍      | 11/32 [01:53<03:12,  9.16s/it]llm_judge_ans = False\n",
      "Average Metric: 3.00 / 32 (9.4%):  34%|███▍      | 11/32 [01:59<03:12,  9.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 32 (9.4%):  38%|███▊      | 12/32 [01:59<02:39,  8.00s/it]llm_judge_ans = True\n",
      "Average Metric: 3.00 / 32 (9.4%):  38%|███▊      | 12/32 [02:05<02:39,  8.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 32 (12.5%):  41%|████      | 13/32 [02:05<02:19,  7.32s/it]llm_judge_ans = False\n",
      "Average Metric: 4.00 / 32 (12.5%):  41%|████      | 13/32 [02:13<02:19,  7.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 32 (12.5%):  44%|████▍     | 14/32 [02:13<02:17,  7.64s/it]llm_judge_ans = True\n",
      "Average Metric: 4.00 / 32 (12.5%):  44%|████▍     | 14/32 [02:25<02:17,  7.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 32 (15.6%):  47%|████▋     | 15/32 [02:25<02:35,  9.12s/it]llm_judge_ans = True\n",
      "Average Metric: 5.00 / 32 (15.6%):  47%|████▋     | 15/32 [02:37<02:35,  9.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 32 (18.8%):  50%|█████     | 16/32 [02:37<02:39,  9.94s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  50%|█████     | 16/32 [02:49<02:39,  9.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 32 (18.8%):  53%|█████▎    | 17/32 [02:49<02:35, 10.38s/it]llm_judge_ans = True\n",
      "Average Metric: 6.00 / 32 (18.8%):  53%|█████▎    | 17/32 [02:59<02:35, 10.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 32 (21.9%):  56%|█████▋    | 18/32 [02:59<02:22, 10.20s/it]llm_judge_ans = True\n",
      "Average Metric: 7.00 / 32 (21.9%):  56%|█████▋    | 18/32 [03:13<02:22, 10.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 32 (25.0%):  59%|█████▉    | 19/32 [03:13<02:30, 11.54s/it]llm_judge_ans = False\n",
      "Average Metric: 8.00 / 32 (25.0%):  59%|█████▉    | 19/32 [03:24<02:30, 11.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 32 (25.0%):  62%|██████▎   | 20/32 [03:24<02:14, 11.22s/it]llm_judge_ans = True\n",
      "Average Metric: 8.00 / 32 (25.0%):  62%|██████▎   | 20/32 [03:35<02:14, 11.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 32 (28.1%):  66%|██████▌   | 21/32 [03:35<02:03, 11.19s/it]llm_judge_ans = True\n",
      "Average Metric: 9.00 / 32 (28.1%):  66%|██████▌   | 21/32 [03:40<02:03, 11.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 32 (31.2%):  69%|██████▉   | 22/32 [03:40<01:33,  9.39s/it]llm_judge_ans = True\n",
      "Average Metric: 10.00 / 32 (31.2%):  69%|██████▉   | 22/32 [03:52<01:33,  9.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 32 (34.4%):  72%|███████▏  | 23/32 [03:52<01:32, 10.29s/it]llm_judge_ans = True\n",
      "Average Metric: 11.00 / 32 (34.4%):  72%|███████▏  | 23/32 [04:03<01:32, 10.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 32 (37.5%):  75%|███████▌  | 24/32 [04:03<01:23, 10.42s/it]llm_judge_ans = False\n",
      "Average Metric: 12.00 / 32 (37.5%):  75%|███████▌  | 24/32 [04:12<01:23, 10.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 32 (37.5%):  78%|███████▊  | 25/32 [04:12<01:10, 10.11s/it]llm_judge_ans = True\n",
      "Average Metric: 12.00 / 32 (37.5%):  78%|███████▊  | 25/32 [04:20<01:10, 10.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 32 (40.6%):  81%|████████▏ | 26/32 [04:20<00:55,  9.27s/it]llm_judge_ans = True\n",
      "Average Metric: 13.00 / 32 (40.6%):  81%|████████▏ | 26/32 [04:27<00:55,  9.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 32 (43.8%):  84%|████████▍ | 27/32 [04:27<00:42,  8.51s/it]llm_judge_ans = False\n",
      "Average Metric: 14.00 / 32 (43.8%):  84%|████████▍ | 27/32 [04:33<00:42,  8.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 32 (43.8%):  88%|████████▊ | 28/32 [04:33<00:31,  7.91s/it]llm_judge_ans = False\n",
      "Average Metric: 14.00 / 32 (43.8%):  88%|████████▊ | 28/32 [04:41<00:31,  7.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 32 (43.8%):  91%|█████████ | 29/32 [04:41<00:24,  8.02s/it]llm_judge_ans = True\n",
      "Average Metric: 14.00 / 32 (43.8%):  91%|█████████ | 29/32 [04:49<00:24,  8.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 32 (46.9%):  94%|█████████▍| 30/32 [04:49<00:16,  8.06s/it]llm_judge_ans = True\n",
      "Average Metric: 15.00 / 32 (46.9%):  94%|█████████▍| 30/32 [04:56<00:16,  8.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 32 (50.0%):  97%|█████████▋| 31/32 [04:56<00:07,  7.74s/it]llm_judge_ans = True\n",
      "Average Metric: 16.00 / 32 (50.0%):  97%|█████████▋| 31/32 [05:04<00:07,  7.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 32 (53.1%): 100%|██████████| 32/32 [05:04<00:00,  9.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 02:04:20 INFO dspy.evaluate.evaluate: Average Metric: 17 / 32 (53.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "raw_score for lm_id = anthropic.claude-3-sonnet-20240229-v1:0 and raw_score =  53.12\n",
      "******* COMPILING model_id = anthropic.claude-3-sonnet-20240229-v1:0 ******* --------------->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1/28 [00:06<03:08,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/28 [00:15<03:17,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3/28 [00:26<03:57,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/28 [00:35<03:36,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5/28 [00:44<03:33,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 6/28 [00:54<03:24,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7/28 [01:04<03:20,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 8/28 [01:16<03:11,  9.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n",
      "Bootstrapped 4 full traces after 8 examples for up to 1 rounds, amounting to 8 attempts.\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = True\n",
      "  0%|          | 0/32 [00:14<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):   3%|▎         | 1/32 [00:14<07:15, 14.05s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):   3%|▎         | 1/32 [00:28<07:15, 14.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):   6%|▋         | 2/32 [00:28<07:15, 14.52s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):   6%|▋         | 2/32 [00:43<07:15, 14.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):   9%|▉         | 3/32 [00:43<07:02, 14.58s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):   9%|▉         | 3/32 [01:02<07:02, 14.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):  12%|█▎        | 4/32 [01:02<07:33, 16.20s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):  12%|█▎        | 4/32 [01:24<07:33, 16.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):  16%|█▌        | 5/32 [01:24<08:19, 18.52s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):  16%|█▌        | 5/32 [01:50<08:19, 18.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):  19%|█▉        | 6/32 [01:50<09:05, 20.97s/it]llm_judge_ans = True\n",
      "Average Metric: 1.00 / 32 (3.1%):  19%|█▉        | 6/32 [02:09<09:05, 20.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 32 (6.2%):  22%|██▏       | 7/32 [02:09<08:25, 20.21s/it]llm_judge_ans = True\n",
      "Average Metric: 2.00 / 32 (6.2%):  22%|██▏       | 7/32 [02:26<08:25, 20.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 32 (9.4%):  25%|██▌       | 8/32 [02:26<07:45, 19.41s/it]llm_judge_ans = False\n",
      "Average Metric: 3.00 / 32 (9.4%):  25%|██▌       | 8/32 [02:47<07:45, 19.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 32 (9.4%):  28%|██▊       | 9/32 [02:47<07:36, 19.83s/it]llm_judge_ans = False\n",
      "Average Metric: 3.00 / 32 (9.4%):  28%|██▊       | 9/32 [03:03<07:36, 19.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 32 (9.4%):  31%|███▏      | 10/32 [03:03<06:52, 18.74s/it]llm_judge_ans = False\n",
      "Average Metric: 3.00 / 32 (9.4%):  31%|███▏      | 10/32 [03:17<06:52, 18.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 32 (9.4%):  34%|███▍      | 11/32 [03:17<06:02, 17.28s/it]llm_judge_ans = False\n",
      "Average Metric: 3.00 / 32 (9.4%):  34%|███▍      | 11/32 [03:34<06:02, 17.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 32 (9.4%):  38%|███▊      | 12/32 [03:34<05:44, 17.20s/it]llm_judge_ans = True\n",
      "Average Metric: 3.00 / 32 (9.4%):  38%|███▊      | 12/32 [03:49<05:44, 17.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 32 (12.5%):  41%|████      | 13/32 [03:49<05:13, 16.49s/it]llm_judge_ans = False\n",
      "Average Metric: 4.00 / 32 (12.5%):  41%|████      | 13/32 [04:04<05:13, 16.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 32 (12.5%):  44%|████▍     | 14/32 [04:04<04:48, 16.01s/it]llm_judge_ans = True\n",
      "Average Metric: 4.00 / 32 (12.5%):  44%|████▍     | 14/32 [04:19<04:48, 16.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 32 (15.6%):  47%|████▋     | 15/32 [04:19<04:24, 15.54s/it]llm_judge_ans = True\n",
      "Average Metric: 5.00 / 32 (15.6%):  47%|████▋     | 15/32 [04:35<04:24, 15.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 32 (18.8%):  50%|█████     | 16/32 [04:35<04:13, 15.86s/it]llm_judge_ans = True\n",
      "Average Metric: 6.00 / 32 (18.8%):  50%|█████     | 16/32 [04:50<04:13, 15.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 32 (21.9%):  53%|█████▎    | 17/32 [04:50<03:53, 15.53s/it]llm_judge_ans = True\n",
      "Average Metric: 7.00 / 32 (21.9%):  53%|█████▎    | 17/32 [05:07<03:53, 15.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 32 (25.0%):  56%|█████▋    | 18/32 [05:07<03:42, 15.86s/it]llm_judge_ans = False\n",
      "Average Metric: 8.00 / 32 (25.0%):  56%|█████▋    | 18/32 [05:28<03:42, 15.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 32 (25.0%):  59%|█████▉    | 19/32 [05:28<03:46, 17.46s/it]llm_judge_ans = False\n",
      "Average Metric: 8.00 / 32 (25.0%):  59%|█████▉    | 19/32 [05:44<03:46, 17.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 32 (25.0%):  62%|██████▎   | 20/32 [05:44<03:25, 17.15s/it]llm_judge_ans = True\n",
      "Average Metric: 8.00 / 32 (25.0%):  62%|██████▎   | 20/32 [05:59<03:25, 17.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 32 (28.1%):  66%|██████▌   | 21/32 [05:59<03:01, 16.50s/it]llm_judge_ans = True\n",
      "Average Metric: 9.00 / 32 (28.1%):  66%|██████▌   | 21/32 [06:17<03:01, 16.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 32 (31.2%):  69%|██████▉   | 22/32 [06:17<02:47, 16.76s/it]llm_judge_ans = True\n",
      "Average Metric: 10.00 / 32 (31.2%):  69%|██████▉   | 22/32 [06:38<02:47, 16.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 32 (34.4%):  72%|███████▏  | 23/32 [06:38<02:42, 18.07s/it]llm_judge_ans = False\n",
      "Average Metric: 11.00 / 32 (34.4%):  72%|███████▏  | 23/32 [06:55<02:42, 18.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 32 (34.4%):  75%|███████▌  | 24/32 [06:55<02:23, 17.90s/it]llm_judge_ans = True\n",
      "Average Metric: 11.00 / 32 (34.4%):  75%|███████▌  | 24/32 [07:12<02:23, 17.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 32 (37.5%):  78%|███████▊  | 25/32 [07:12<02:03, 17.65s/it]llm_judge_ans = True\n",
      "Average Metric: 12.00 / 32 (37.5%):  78%|███████▊  | 25/32 [07:33<02:03, 17.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 32 (40.6%):  81%|████████▏ | 26/32 [07:33<01:50, 18.47s/it]llm_judge_ans = False\n",
      "Average Metric: 13.00 / 32 (40.6%):  81%|████████▏ | 26/32 [07:56<01:50, 18.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 32 (40.6%):  84%|████████▍ | 27/32 [07:56<01:39, 19.85s/it]llm_judge_ans = False\n",
      "Average Metric: 13.00 / 32 (40.6%):  84%|████████▍ | 27/32 [08:12<01:39, 19.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 32 (40.6%):  88%|████████▊ | 28/32 [08:12<01:15, 18.89s/it]llm_judge_ans = True\n",
      "Average Metric: 13.00 / 32 (40.6%):  88%|████████▊ | 28/32 [08:34<01:15, 18.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 32 (43.8%):  91%|█████████ | 29/32 [08:34<00:59, 19.73s/it]llm_judge_ans = True\n",
      "Average Metric: 14.00 / 32 (43.8%):  91%|█████████ | 29/32 [09:06<00:59, 19.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 32 (46.9%):  94%|█████████▍| 30/32 [09:06<00:46, 23.40s/it]llm_judge_ans = True\n",
      "Average Metric: 15.00 / 32 (46.9%):  94%|█████████▍| 30/32 [09:34<00:46, 23.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 32 (50.0%):  97%|█████████▋| 31/32 [09:34<00:24, 24.70s/it]llm_judge_ans = False\n",
      "Average Metric: 16.00 / 32 (50.0%):  97%|█████████▋| 31/32 [09:56<00:24, 24.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 32 (50.0%): 100%|██████████| 32/32 [09:56<00:00, 18.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 02:15:33 INFO dspy.evaluate.evaluate: Average Metric: 16 / 32 (50.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "compiled_score for COMPILED lm_id = anthropic.claude-3-sonnet-20240229-v1:0 and raw_score =  50.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Human: Judge if the predicted answer factually correct to the groundtruth answer and same as groundtruth answer. Answer either Factual[True] or Factual[False]\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: Question to be answered\n",
      "\n",
      "Groundtruth Answer: groundtruth answer for the question\n",
      "\n",
      "Predicted Answer: predicted answer for the question\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the factually_correct}. We ...\n",
      "\n",
      "Factual[True/False]: Is the predicted answer factually correct to the groundtruth answer and same as groundtruth answer ?\n",
      "\n",
      "---\n",
      "\n",
      "Question: Is there a requirement for insurance that must be maintained by one party for the benefit of the counterparty?\n",
      "\n",
      "Groundtruth Answer: Each party will maintain, during the Term and for three (3) years thereafter, such comprehensive general liability insurance (including without limitation, products liability) as will adequately protect it against its potential liabilities under this Agreement, in amounts customary in the semiconductor industry for similar services and products., Each party will, at the other party's request, provide to the other party a certificate of insurance evidencing the foregoing insurance coverage.\n",
      "\n",
      "Predicted Answer: Yes, there is a requirement for insurance that must be maintained by both parties according to Section 12.4: \"Each party will maintain, during the Term and for three (3) years thereafter, such comprehensive general liability insurance (including without limitation, products liability) as will adequately protect it against its potential liabilities under this Agreement, in amounts customary in\n",
      "\n",
      "Reasoning: Let's think step by step in order to Reasoning: To determine if the predicted answer is factually correct and the same as the groundtruth answer, we need to carefully analyze both answers. The groundtruth answer states that \"Each party will maintain, during the Term and for three (3) years thereafter, such comprehensive general liability insurance (including without limitation, products liability) as will adequately protect\n",
      "\n",
      "Factual[True/False]:\n",
      "\n",
      "Assistant:\u001b[32mReasoning: To determine if the predicted answer is factually correct and the same as the groundtruth answer, we need to carefully analyze both answers. The groundtruth answer states that \"Each party will maintain, during the Term and for three (3) years thereafter, such comprehensive general liability insurance (including without limitation, products liability) as will adequately protect it\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "END OF model_id = anthropic.claude-3-sonnet-20240229-v1:0 --------------->\n",
      "START OF model_id = mistral.mistral-7b-instruct-v0:2 --------------->\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated, underperform, and are about to be deleted. ***\n",
      " \t\tYou are using the client AWSMistral, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n",
      "  0%|          | 0/32 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 32 (0.0%):   3%|▎         | 1/32 [00:01<00:47,  1.53s/it]llm_judge_ans = True\n",
      "Average Metric: 0.00 / 32 (0.0%):   3%|▎         | 1/32 [00:03<00:47,  1.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):   6%|▋         | 2/32 [00:03<01:01,  2.04s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):   6%|▋         | 2/32 [00:05<01:01,  2.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):   9%|▉         | 3/32 [00:05<00:54,  1.87s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):   9%|▉         | 3/32 [00:07<00:54,  1.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):  12%|█▎        | 4/32 [00:07<00:52,  1.87s/it]llm_judge_ans = True\n",
      "Average Metric: 1.00 / 32 (3.1%):  12%|█▎        | 4/32 [00:09<00:52,  1.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 32 (6.2%):  16%|█▌        | 5/32 [00:09<00:50,  1.88s/it]llm_judge_ans = True\n",
      "Average Metric: 2.00 / 32 (6.2%):  16%|█▌        | 5/32 [00:11<00:50,  1.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 32 (9.4%):  19%|█▉        | 6/32 [00:11<00:50,  1.93s/it]llm_judge_ans = True\n",
      "Average Metric: 3.00 / 32 (9.4%):  19%|█▉        | 6/32 [00:12<00:50,  1.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 32 (12.5%):  22%|██▏       | 7/32 [00:12<00:42,  1.68s/it]llm_judge_ans = True\n",
      "Average Metric: 4.00 / 32 (12.5%):  22%|██▏       | 7/32 [00:13<00:42,  1.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 32 (15.6%):  25%|██▌       | 8/32 [00:13<00:37,  1.57s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%):  25%|██▌       | 8/32 [00:18<00:37,  1.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 32 (15.6%):  28%|██▊       | 9/32 [00:18<00:55,  2.43s/it]llm_judge_ans = True\n",
      "Average Metric: 5.00 / 32 (15.6%):  28%|██▊       | 9/32 [00:21<00:55,  2.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 32 (18.8%):  31%|███▏      | 10/32 [00:21<00:57,  2.62s/it]llm_judge_ans = True\n",
      "Average Metric: 6.00 / 32 (18.8%):  31%|███▏      | 10/32 [00:23<00:57,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 32 (21.9%):  34%|███▍      | 11/32 [00:23<00:55,  2.65s/it]llm_judge_ans = False\n",
      "Average Metric: 7.00 / 32 (21.9%):  34%|███▍      | 11/32 [00:26<00:55,  2.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 32 (21.9%):  38%|███▊      | 12/32 [00:26<00:50,  2.50s/it]llm_judge_ans = False\n",
      "Average Metric: 7.00 / 32 (21.9%):  38%|███▊      | 12/32 [00:29<00:50,  2.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 32 (21.9%):  41%|████      | 13/32 [00:29<00:52,  2.75s/it]llm_judge_ans = True\n",
      "Average Metric: 7.00 / 32 (21.9%):  41%|████      | 13/32 [00:31<00:52,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 32 (25.0%):  44%|████▍     | 14/32 [00:31<00:44,  2.48s/it]llm_judge_ans = False\n",
      "Average Metric: 8.00 / 32 (25.0%):  44%|████▍     | 14/32 [00:33<00:44,  2.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 32 (25.0%):  47%|████▋     | 15/32 [00:33<00:38,  2.29s/it]llm_judge_ans = True\n",
      "Average Metric: 8.00 / 32 (25.0%):  47%|████▋     | 15/32 [00:35<00:38,  2.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 32 (28.1%):  50%|█████     | 16/32 [00:35<00:35,  2.19s/it]llm_judge_ans = True\n",
      "Average Metric: 9.00 / 32 (28.1%):  50%|█████     | 16/32 [00:37<00:35,  2.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 32 (31.2%):  53%|█████▎    | 17/32 [00:37<00:32,  2.14s/it]llm_judge_ans = True\n",
      "Average Metric: 10.00 / 32 (31.2%):  53%|█████▎    | 17/32 [00:39<00:32,  2.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 32 (34.4%):  56%|█████▋    | 18/32 [00:39<00:30,  2.16s/it]llm_judge_ans = True\n",
      "Average Metric: 11.00 / 32 (34.4%):  56%|█████▋    | 18/32 [00:41<00:30,  2.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 32 (37.5%):  59%|█████▉    | 19/32 [00:41<00:26,  2.01s/it]llm_judge_ans = False\n",
      "Average Metric: 12.00 / 32 (37.5%):  59%|█████▉    | 19/32 [00:43<00:26,  2.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 32 (37.5%):  62%|██████▎   | 20/32 [00:43<00:26,  2.18s/it]llm_judge_ans = True\n",
      "Average Metric: 12.00 / 32 (37.5%):  62%|██████▎   | 20/32 [00:45<00:26,  2.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 32 (40.6%):  66%|██████▌   | 21/32 [00:45<00:23,  2.18s/it]llm_judge_ans = True\n",
      "Average Metric: 13.00 / 32 (40.6%):  66%|██████▌   | 21/32 [00:48<00:23,  2.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 32 (43.8%):  69%|██████▉   | 22/32 [00:48<00:22,  2.24s/it]llm_judge_ans = False\n",
      "Average Metric: 14.00 / 32 (43.8%):  69%|██████▉   | 22/32 [00:51<00:22,  2.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 32 (43.8%):  72%|███████▏  | 23/32 [00:51<00:23,  2.59s/it]llm_judge_ans = True\n",
      "Average Metric: 14.00 / 32 (43.8%):  72%|███████▏  | 23/32 [00:54<00:23,  2.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 32 (46.9%):  75%|███████▌  | 24/32 [00:54<00:21,  2.66s/it]llm_judge_ans = True\n",
      "Average Metric: 15.00 / 32 (46.9%):  75%|███████▌  | 24/32 [00:58<00:21,  2.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 32 (50.0%):  78%|███████▊  | 25/32 [00:58<00:22,  3.24s/it]llm_judge_ans = True\n",
      "Average Metric: 16.00 / 32 (50.0%):  78%|███████▊  | 25/32 [01:01<00:22,  3.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 32 (53.1%):  81%|████████▏ | 26/32 [01:01<00:18,  3.09s/it]llm_judge_ans = True\n",
      "Average Metric: 17.00 / 32 (53.1%):  81%|████████▏ | 26/32 [01:04<00:18,  3.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 32 (56.2%):  84%|████████▍ | 27/32 [01:04<00:14,  2.92s/it]llm_judge_ans = False\n",
      "Average Metric: 18.00 / 32 (56.2%):  84%|████████▍ | 27/32 [01:06<00:14,  2.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 32 (56.2%):  88%|████████▊ | 28/32 [01:06<00:10,  2.66s/it]llm_judge_ans = True\n",
      "Average Metric: 18.00 / 32 (56.2%):  88%|████████▊ | 28/32 [01:08<00:10,  2.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 32 (59.4%):  91%|█████████ | 29/32 [01:08<00:07,  2.53s/it]llm_judge_ans = False\n",
      "Average Metric: 19.00 / 32 (59.4%):  91%|█████████ | 29/32 [01:12<00:07,  2.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 32 (59.4%):  94%|█████████▍| 30/32 [01:12<00:05,  2.87s/it]llm_judge_ans = False\n",
      "Average Metric: 19.00 / 32 (59.4%):  94%|█████████▍| 30/32 [01:14<00:05,  2.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 32 (59.4%):  97%|█████████▋| 31/32 [01:14<00:02,  2.79s/it]llm_judge_ans = True\n",
      "Average Metric: 19.00 / 32 (59.4%):  97%|█████████▋| 31/32 [01:16<00:02,  2.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%): 100%|██████████| 32/32 [01:16<00:00,  2.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 02:19:31 INFO dspy.evaluate.evaluate: Average Metric: 20 / 32 (62.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "raw_score for lm_id = mistral.mistral-7b-instruct-v0:2 and raw_score =  62.5\n",
      "******* COMPILING model_id = mistral.mistral-7b-instruct-v0:2 ******* --------------->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1/28 [00:01<00:53,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/28 [00:04<00:52,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3/28 [00:07<01:04,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/28 [00:14<01:43,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5/28 [00:16<01:18,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 6/28 [00:19<01:11,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n",
      "Bootstrapped 4 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = False\n",
      "  0%|          | 0/32 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 32 (0.0%):   3%|▎         | 1/32 [00:03<01:57,  3.80s/it]llm_judge_ans = True\n",
      "Average Metric: 0.00 / 32 (0.0%):   3%|▎         | 1/32 [00:07<01:57,  3.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):   6%|▋         | 2/32 [00:07<01:51,  3.71s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):   6%|▋         | 2/32 [00:12<01:51,  3.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 32 (3.1%):   9%|▉         | 3/32 [00:12<02:03,  4.27s/it]llm_judge_ans = True\n",
      "Average Metric: 1.00 / 32 (3.1%):   9%|▉         | 3/32 [00:26<02:03,  4.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 32 (6.2%):  12%|█▎        | 4/32 [00:26<03:52,  8.31s/it]llm_judge_ans = True\n",
      "Average Metric: 2.00 / 32 (6.2%):  12%|█▎        | 4/32 [00:41<03:52,  8.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 32 (9.4%):  16%|█▌        | 5/32 [00:41<04:48, 10.67s/it]llm_judge_ans = True\n",
      "Average Metric: 3.00 / 32 (9.4%):  16%|█▌        | 5/32 [00:47<04:48, 10.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 32 (12.5%):  19%|█▉        | 6/32 [00:47<03:51,  8.91s/it]llm_judge_ans = True\n",
      "Average Metric: 4.00 / 32 (12.5%):  19%|█▉        | 6/32 [00:50<03:51,  8.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 32 (15.6%):  22%|██▏       | 7/32 [00:50<03:00,  7.22s/it]llm_judge_ans = True\n",
      "Average Metric: 5.00 / 32 (15.6%):  22%|██▏       | 7/32 [00:53<03:00,  7.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 32 (18.8%):  25%|██▌       | 8/32 [00:53<02:19,  5.83s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  25%|██▌       | 8/32 [01:10<02:19,  5.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 32 (18.8%):  28%|██▊       | 9/32 [01:10<03:31,  9.20s/it]llm_judge_ans = True\n",
      "Average Metric: 6.00 / 32 (18.8%):  28%|██▊       | 9/32 [01:18<03:31,  9.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 32 (21.9%):  31%|███▏      | 10/32 [01:18<03:14,  8.82s/it]llm_judge_ans = True\n",
      "Average Metric: 7.00 / 32 (21.9%):  31%|███▏      | 10/32 [01:25<03:14,  8.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 32 (25.0%):  34%|███▍      | 11/32 [01:25<02:56,  8.40s/it]llm_judge_ans = False\n",
      "Average Metric: 8.00 / 32 (25.0%):  34%|███▍      | 11/32 [01:35<02:56,  8.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 32 (25.0%):  38%|███▊      | 12/32 [01:35<02:56,  8.82s/it]llm_judge_ans = True\n",
      "Average Metric: 8.00 / 32 (25.0%):  38%|███▊      | 12/32 [01:40<02:56,  8.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 32 (28.1%):  41%|████      | 13/32 [01:40<02:27,  7.77s/it]llm_judge_ans = True\n",
      "Average Metric: 9.00 / 32 (28.1%):  41%|████      | 13/32 [01:48<02:27,  7.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 32 (31.2%):  44%|████▍     | 14/32 [01:48<02:16,  7.57s/it]llm_judge_ans = False\n",
      "Average Metric: 10.00 / 32 (31.2%):  44%|████▍     | 14/32 [01:52<02:16,  7.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 32 (31.2%):  47%|████▋     | 15/32 [01:52<01:50,  6.51s/it]llm_judge_ans = True\n",
      "Average Metric: 10.00 / 32 (31.2%):  47%|████▋     | 15/32 [02:04<01:50,  6.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 32 (34.4%):  50%|█████     | 16/32 [02:04<02:12,  8.30s/it]llm_judge_ans = False\n",
      "Average Metric: 11.00 / 32 (34.4%):  50%|█████     | 16/32 [02:10<02:12,  8.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 32 (34.4%):  53%|█████▎    | 17/32 [02:10<01:54,  7.64s/it]llm_judge_ans = True\n",
      "Average Metric: 11.00 / 32 (34.4%):  53%|█████▎    | 17/32 [02:17<01:54,  7.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 32 (37.5%):  56%|█████▋    | 18/32 [02:17<01:41,  7.28s/it]llm_judge_ans = False\n",
      "Average Metric: 12.00 / 32 (37.5%):  56%|█████▋    | 18/32 [02:22<01:41,  7.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 32 (37.5%):  59%|█████▉    | 19/32 [02:22<01:26,  6.64s/it]llm_judge_ans = False\n",
      "Average Metric: 12.00 / 32 (37.5%):  59%|█████▉    | 19/32 [02:29<01:26,  6.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 32 (37.5%):  62%|██████▎   | 20/32 [02:29<01:23,  6.95s/it]llm_judge_ans = True\n",
      "Average Metric: 12.00 / 32 (37.5%):  62%|██████▎   | 20/32 [02:36<01:23,  6.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 32 (40.6%):  66%|██████▌   | 21/32 [02:36<01:14,  6.79s/it]llm_judge_ans = False\n",
      "Average Metric: 13.00 / 32 (40.6%):  66%|██████▌   | 21/32 [02:44<01:14,  6.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 32 (40.6%):  69%|██████▉   | 22/32 [02:44<01:12,  7.26s/it]llm_judge_ans = True\n",
      "Average Metric: 13.00 / 32 (40.6%):  69%|██████▉   | 22/32 [02:49<01:12,  7.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 32 (43.8%):  72%|███████▏  | 23/32 [02:49<00:59,  6.63s/it]llm_judge_ans = False\n",
      "Average Metric: 14.00 / 32 (43.8%):  72%|███████▏  | 23/32 [02:58<00:59,  6.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 32 (43.8%):  75%|███████▌  | 24/32 [02:58<00:58,  7.35s/it]llm_judge_ans = True\n",
      "Average Metric: 14.00 / 32 (43.8%):  75%|███████▌  | 24/32 [03:05<00:58,  7.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 32 (46.9%):  78%|███████▊  | 25/32 [03:05<00:49,  7.10s/it]llm_judge_ans = True\n",
      "Average Metric: 15.00 / 32 (46.9%):  78%|███████▊  | 25/32 [03:12<00:49,  7.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.00 / 32 (50.0%):  81%|████████▏ | 26/32 [03:12<00:42,  7.06s/it]llm_judge_ans = True\n",
      "Average Metric: 16.00 / 32 (50.0%):  81%|████████▏ | 26/32 [03:21<00:42,  7.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 32 (53.1%):  84%|████████▍ | 27/32 [03:21<00:38,  7.64s/it]llm_judge_ans = False\n",
      "Average Metric: 17.00 / 32 (53.1%):  84%|████████▍ | 27/32 [03:27<00:38,  7.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 32 (53.1%):  88%|████████▊ | 28/32 [03:27<00:28,  7.14s/it]llm_judge_ans = True\n",
      "Average Metric: 17.00 / 32 (53.1%):  88%|████████▊ | 28/32 [03:37<00:28,  7.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 32 (56.2%):  91%|█████████ | 29/32 [03:37<00:24,  8.11s/it]llm_judge_ans = True\n",
      "Average Metric: 18.00 / 32 (56.2%):  91%|█████████ | 29/32 [03:44<00:24,  8.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 32 (59.4%):  94%|█████████▍| 30/32 [03:44<00:15,  7.81s/it]llm_judge_ans = True\n",
      "Average Metric: 19.00 / 32 (59.4%):  94%|█████████▍| 30/32 [03:49<00:15,  7.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%):  97%|█████████▋| 31/32 [03:49<00:06,  6.91s/it]llm_judge_ans = True\n",
      "Average Metric: 20.00 / 32 (62.5%):  97%|█████████▋| 31/32 [03:54<00:06,  6.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_judge_ans = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 32 (65.6%): 100%|██████████| 32/32 [03:54<00:00,  7.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 02:23:45 INFO dspy.evaluate.evaluate: Average Metric: 21 / 32 (65.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "compiled_score for COMPILED lm_id = mistral.mistral-7b-instruct-v0:2 and raw_score =  65.62\n",
      "\n",
      "\n",
      "\n",
      "<s> [INST] Human: Judge if the predicted answer factually correct to the groundtruth answer and same as groundtruth answer. Answer either Factual[True] or Factual[False]\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: Question to be answered\n",
      "\n",
      "Groundtruth Answer: groundtruth answer for the question\n",
      "\n",
      "Predicted Answer: predicted answer for the question\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the factually_correct}. We ...\n",
      "\n",
      "Factual[True/False]: Is the predicted answer factually correct to the groundtruth answer and same as groundtruth answer ?\n",
      "\n",
      "---\n",
      "\n",
      "Question: Is there a requirement for insurance that must be maintained by one party for the benefit of the counterparty?\n",
      "\n",
      "Groundtruth Answer: Each party will maintain, during the Term and for three (3) years thereafter, such comprehensive general liability insurance (including without limitation, products liability) as will adequately protect it against its potential liabilities under this Agreement, in amounts customary in the semiconductor industry for similar services and products., Each party will, at the other party's request, provide to the other party a certificate of insurance evidencing the foregoing insurance coverage.\n",
      "\n",
      "Predicted Answer: Each party must maintain comprehensive general liability insurance during the term of the agreement and for three years thereafter. They must provide a certificate of insurance to the other party upon request.\n",
      "\n",
      "Reasoning: Let's think step by step in order to Factual[True] Both the groundtruth answer and the predicted answer state that each party must maintain comprehensive general liability insurance during the term of the agreement and for three years thereafter. They also both state that they must provide a certificate of insurance to the other party upon request. Therefore, the predicted answer is factually correct to the groundtruth answer and is the same as the groundtruth answer.\n",
      "\n",
      "Factual[True/False]: [/INST] Assistant: \u001b[32m Factual[True]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "END OF model_id = mistral.mistral-7b-instruct-v0:2 --------------->\n",
      "CPU times: user 6.05 s, sys: 446 ms, total: 6.5 s\n",
      "Wall time: 31min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Evaluation\n",
    "\n",
    "raw_scores = list()\n",
    "compiled_scores = list()\n",
    "model_ids = [\"anthropic.claude-3-haiku-20240307-v1:0\", \"anthropic.claude-3-sonnet-20240229-v1:0\", \"mistral.mistral-7b-instruct-v0:2\"]\n",
    "counter = 0\n",
    "\n",
    "for lm_id in [bedrock_haiku, bedrock_sonnet, bedrock_mistral_7b]:\n",
    "\n",
    "    dspy.settings.configure(lm=lm_id)\n",
    "    dspy.settings.configure(rm=rm)\n",
    "    rag_lm = RAG()\n",
    "    print(f\"START OF model_id = {model_ids[counter]} --------------->\")\n",
    "    raw_score = evaluate_cuad(rag_lm, num_threads=1)\n",
    "    raw_scores.append(raw_score)\n",
    "    \n",
    "    print(f\"raw_score for lm_id = {model_ids[counter]} and raw_score =  {raw_score}\")\n",
    "    logging.info(f\"raw_score for lm_id = {model_ids[counter]} and raw_score =  {raw_score}\")\n",
    "    \n",
    "    # Validation logic: check that the predicted answer is correct.\n",
    "    # Also check that the retrieved context does actually contain that answer.\n",
    "    \n",
    "    # Set up a basic teleprompter, which will compile our RAG program.\n",
    "    teleprompter = BootstrapFewShot(metric=validate_context_and_answer)\n",
    "    \n",
    "    print(f\"******* COMPILING model_id = {model_ids[counter]} ******* --------------->\")\n",
    "    # Compile!\n",
    "    compiled_rag = teleprompter.compile(rag_lm, trainset=trainset)\n",
    "    \n",
    "    compiled_score = evaluate_cuad(compiled_rag, num_threads=1)\n",
    "    compiled_scores.append(compiled_score)\n",
    "    \n",
    "    print(f\"compiled_score for COMPILED lm_id = {model_ids[counter]} and raw_score =  {compiled_score}\")\n",
    "    logging.info(f\"compiled_score for COMPILED lm_id = {model_ids[counter]} and raw_score =  {compiled_score}\")\n",
    "    \n",
    "    lm_id.inspect_history(n=1)\n",
    "    generate_csv(rag_lm, model_ids[counter])\n",
    "    print(f\"END OF model_id = {model_ids[counter]} --------------->\")\n",
    "    counter +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8675812f",
   "metadata": {},
   "source": [
    "### Retriever Evaluation (RM is same across models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ad8ad",
   "metadata": {},
   "source": [
    "In RAG workflows, it is very crucial to understand the retriever performance to be able to improve the performance of the overall system. We will now create a retriever judge to understand how well the retriever is able to pull out the relevant chunks for the incoming user question. Context and Answer relevance is measured using this Retriever Judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16868fe6-0953-465b-962a-b749cfc2e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetreivalJudge(dspy.Signature):\n",
    "    \"\"\"Judge given the question to be answered, check if the groundtruth answer can be derived from the predicted context.  Answer either Retrieved[True] or Retrieved[False]\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"Context for the prediction\")\n",
    "    question = dspy.InputField(desc=\"Question to be answered\")\n",
    "    groundtruth_answer = dspy.InputField(desc=\"groundtruth answer for the question\")\n",
    "    retrieval_correctness = dspy.OutputField(desc=\"Can the groundtruth answer be derived from the predicted context?\", prefix=\"Retrieved[True/False]:\")\n",
    "\n",
    "retreival_judge = dspy.ChainOfThought(RetreivalJudge)\n",
    "\n",
    "\n",
    "def retrieval_metric(example, pred):\n",
    "    retrieval = retreival_judge(question=example.question, groundtruth_answer=example.answer, context=pred.context) \n",
    "    #logging.info(f\"\\n retrieval LLM judge {retrieval}\")\n",
    "    #logging.info(f\"\\n example {example}\")\n",
    "    #logging.info(f\"\\n pred {pred}\")\n",
    "    llm_retreiver_ans = bool(\"Retrieved[True]\" in retrieval.retrieval_correctness \n",
    "                         or '100% True' in retrieval.retrieval_correctness\n",
    "                         or '100% retrieved correct' in retrieval.retrieval_correctness\n",
    "                         or 'True.' in retrieval.retrieval_correctness) \n",
    "    #logging.info(f\"llm_retreiver_ans = {llm_retreiver_ans}\")\n",
    "    return llm_retreiver_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a06e8ce7-c34a-4637-99f4-cd578e33da7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 32 (84.4%): 100%|██████████| 32/32 [04:06<00:00,  7.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 02:28:25 INFO dspy.evaluate.evaluate: Average Metric: 27 / 32 (84.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84.38"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_passages_retrieved(example, pred, trace=None):\n",
    "    gt_answer = example['answer']\n",
    "    pred_context = set(map(dspy.evaluate.normalize_text, [c.split(' | ')[0] for c in pred.context]))\n",
    "    logging.info(f\"example['answer'] :: {example['answer']}\")\n",
    "    logging.info(f\"gt_answer :: {gt_answer}\")\n",
    "    #logging.info(f\"pred_context :: {pred_context}\")\n",
    "    return gt_answer.issubset(pred_context)\n",
    "\n",
    "compiled_rag_retrieval_score = evaluate_cuad(compiled_rag, num_threads = 1, metric=retrieval_metric)\n",
    "compiled_rag_retrieval_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967d4aaf-caf0-4ffa-addb-8b05f413a6d3",
   "metadata": {},
   "source": [
    "### RAG performance across models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d250647c",
   "metadata": {},
   "source": [
    "Let us see the performance across various model familes and types using raw and compiled DSPy framework to understand what value DSPy may bring to the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0329abca-cb99-4efd-8f0e-554fe914502c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAAHBCAYAAABwnMo3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABo+ElEQVR4nO3de3zO9f/H8efF5trRHHdy2IY5zCGKnEPllFRfp5wn1VeIkMpSjNiywio/+iYNaVJCSglhfQuFUCGkMcVaOWwYw/b+/dF3V662sYtrZutxv90+Nz7vz/vz/rw+7+uz69pr78/nfVmMMUYAAAAAAKcpUdgBAAAAAEBxQ6IFAAAAAE5GogUAAAAATkaiBQAAAABORqIFAAAAAE5GogUAAAAATkaiBQAAAABORqIFAAAAAE5GogUAAAAATkaiBaDYmT9/viwWi21xcXFRQECAevfurQMHDuS536uvviqLxaJ69epdsf3ExESNHDlSderUkaenp9zc3BQcHKz+/ftrw4YNMsY4+5Su25IlS1S3bl25u7vLYrFo586dhR0ScFWHDh2SxWLR/PnzHd5348aNslgs2rhxo9PjAoD8cCnsAACgoMTFxal27do6f/68vvrqK02dOlUbNmzQjz/+qLJly+ao/9Zbb0mSdu/era+//lpNmzbNUWflypXq27evKlSooMcee0y33nqrrFarfvrpJy1dulR33nmn1q1bp7vuuqvAzy+/fv/9dw0YMECdOnXS7NmzZbVaVbNmzcIOCwCAYo1EC0CxVa9ePTVu3FiS1LZtW2VmZmrixIlasWKFHnroIbu627Zt065du9SlSxetWrVK8+bNy5FoHTx4UH369FHdunW1bt06lS5d2ratTZs2evjhh7Vx48Zck7jCcO7cObm5uWn//v26ePGi+vfvrzZt2jil7fT0dHl4eDilLeR07tw5ubu7F3YYAIDrwK2DAP4xspOu3377Lce2efPmSZJefPFFtWjRQu+++67S09Pt6syYMUPp6emaPXu2XZJ1ubZt2+qWW265YhzZtzQtWrRIY8aMkb+/v9zd3dWmTRvt2LEjR/1t27bpvvvuU7ly5eTm5qZGjRrpvffes6uTfbvkmjVrNHjwYFWsWFEeHh7q06ePWrVqJUl68MEHZbFY1LZtW9t+K1euVPPmzeXh4SFvb2+1b99emzdvtms7MjJSFotF3377rXr06KGyZcuqevXqkqTg4GDde++9+vjjj9WoUSO5u7urTp06+vjjj21xZd9iefvtt2vbtm05zq13794KDg6Wu7u7goOD1adPHx0+fDjX89uwYYOGDh2qChUqqHz58urWrZuOHj2ao8/i4+PVvHlzeXl5ycvLSw0bNrS9xtmyRx5Lly4tDw8PtWzZUp9//vmVXjpJ0vnz5/Xkk0+qYcOG8vHxUbly5dS8eXN9+OGHOepmZWXptddeU8OGDeXu7q4yZcqoWbNmWrlypa1Odh8uW7ZMjRo1kpubmyZNmiRJ+uGHH3T//ferbNmycnNzU8OGDbVgwYIcx5gyZYpq1aplO0aDBg30yiuv2Or8/vvv+ve//60qVarIarWqYsWKatmypdatW3fFc81+7b/77jv17NnTdr5jxozRpUuXtG/fPnXq1Ene3t4KDg5WTExMjjaSkpLUv39/+fr6ymq1qk6dOpo+fbqysrLs6h09elS9evWSt7e3fHx89OCDDyo5OTnXuPLzM5Gbn3/+Wb1791ZgYKCsVqv8/Px01113cSstgALBiBaAf4zExERJynHb3Llz57R48WI1adJE9erV0+DBg/XII4/o/fffV3h4uK3e2rVrFRAQYEvYrtezzz6rW2+9VW+++aZSU1MVGRmptm3baseOHapWrZokacOGDerUqZOaNm2q119/XT4+Pnr33Xf14IMPKj09XYMGDbJrc/DgwerSpYvefvttnT17Vg0bNtQdd9yh4cOHKyoqSu3atbMlifHx8erXr586dOigxYsXKyMjQzExMWrbtq0+//xzW4KWrVu3burdu7cee+wxnT171la+a9cuRUREaPz48fLx8dGkSZPUrVs3RURE6PPPP1dUVJQsFoueeeYZ3XvvvUpMTLSN1hw6dEi1atVS7969Va5cOR07dkxz5sxRkyZNtGfPHlWoUMEuhkceeURdunRRfHy8jhw5oqeeekr9+/fX+vXrbXUmTJigF154Qd26ddOTTz4pHx8f/fDDD3bJ26JFizRw4EDdf//9WrBggVxdXfWf//xHHTt21GeffXbFWz8zMjJ04sQJjR07VpUqVdKFCxe0bt06devWTXFxcRo4cKCt7qBBg7Ro0SI9/PDDmjx5skqVKqVvv/1Whw4dsmvz22+/1d69e/Xcc88pJCREnp6e2rdvn1q0aCFfX1+9+uqrKl++vBYtWqRBgwbpt99+09NPPy1JiomJUWRkpJ577jndcccdunjxon788UedOnXK1v6AAQP07bffaurUqapZs6ZOnTqlb7/9VsePH8/zPC/Xq1cv9e/fX0OGDNHatWsVExOjixcvat26dRo2bJjGjh2r+Ph4PfPMM6pRo4a6desm6c8Er0WLFrpw4YJeeOEFBQcH6+OPP9bYsWN18OBBzZ49W9KfP4N33323jh49qujoaNWsWVOrVq3Sgw8+mCMWR38mLnfPPfcoMzNTMTExqlq1qv744w9t2rTJrq8AwGkMABQzcXFxRpLZsmWLuXjxojl9+rRZvXq18ff3N3fccYe5ePGiXf2FCxcaSeb11183xhhz+vRp4+XlZVq3bm1Xz83NzTRr1izH8TIzM83FixdtS2Zm5hXj27Bhg5Fkbr31VpOVlWUrP3TokHF1dTWPPPKIrax27dqmUaNGOWK+9957TUBAgO1Y2ec8cODAPI/3/vvv28UcGBho6tevbxfv6dOnja+vr2nRooWtbOLEiUaSmTBhQo62g4KCjLu7u/nll19sZTt37jSSTEBAgDl79qytfMWKFUaSWblyZZ59c+nSJXPmzBnj6elpXnnlFVt59vkNGzbMrn5MTIyRZI4dO2aMMebnn382JUuWNP369cvzGGfPnjXlypUzXbt2tSvPzMw0t9xyi7n99tvz3DevmC9evGgefvhh06hRI1v5F198YSSZ8ePHX3H/oKAgU7JkSbNv3z678t69exur1WqSkpLsyjt37mw8PDzMqVOnjDF/XgsNGza84jG8vLzMqFGjHDktY8xfr/306dPtyhs2bGgkmWXLltnKLl68aCpWrGi6detmKxs3bpyRZL7++mu7/YcOHWosFovtnOfMmWMkmQ8//NCu3qOPPmokmbi4OFtZfn8msq/7DRs2GGOM+eOPP4wkExsb63A/AMC14NZBAMVWs2bN5OrqKm9vb3Xq1Elly5bVhx9+KBcX+8H8efPmyd3dXb1795YkeXl5qWfPnvrvf/97xVkKs3Xr1k2urq62ZeTIkfmKr2/fvrJYLLb1oKAgtWjRQhs2bJAk/fTTT/rxxx/Vr18/SdKlS5dsyz333KNjx45p3759dm127949X8fet2+fjh49qgEDBqhEib8+Cry8vNS9e3dt2bIlx62TebXdsGFDVapUybZep04dSX/eRnn5c1zZ5ZePLJ05c8Y2CuLi4iIXFxd5eXnp7Nmz2rt3b45j3XfffXbrDRo0sGtz7dq1yszM1PDhw/M8902bNunEiRMKDw+369OsrCx16tRJW7dutRuxy83777+vli1bysvLSy4uLnJ1ddW8efPsYv70008l6YqxXH4efx9pXb9+ve666y5VqVLFrnzQoEFKT0+33eJ5++23a9euXRo2bJg+++wzpaWl5Wj/9ttv1/z58zVlyhRt2bJFFy9evGpMl7v33nvt1uvUqSOLxaLOnTvbylxcXFSjRg2713f9+vUKCwvT7bffnuMcjDG2kcgNGzbI29s7x+vbt29fu/Vr+ZnIVq5cOVWvXl0vvfSSZsyYoR07duS4fREAnIlEC0CxtXDhQm3dulXr16/XkCFDtHfvXvXp08euzk8//aQvvvhCXbp0kTFGp06d0qlTp9SjRw9Jf81EKElVq1bN8eyQJE2fPl1bt27V1q1bHYrP398/17Ls27mynyUbO3asXSLn6uqqYcOGSZL++OMPu/0DAgLydezsY+RWPzAwUFlZWTp58mS+2i5XrpzdeqlSpa5Yfv78eVtZ3759NWvWLD3yyCP67LPP9M0332jr1q2qWLGizp07l+NY5cuXt1u3Wq2SZKv7+++/S5IqV66ca6zSX/3ao0ePHP06bdo0GWN04sSJPPdftmyZevXqpUqVKmnRokXavHmztm7dqsGDB9ud2++//66SJUvm+jr/XW59e/z48Txfn+ztkhQREaGXX35ZW7ZsUefOnVW+fHndddddds/DLVmyROHh4XrzzTfVvHlzlStXTgMHDszzGai/y+219PDwkJubW47yy/sgv+dw/Phx+fn55aj39767lp+JbBaLRZ9//rk6duyomJgY3XrrrapYsaJGjhyp06dPX/H8AeBa8IwWgGKrTp06tuep2rVrp8zMTL355ptaunSpXSJljNHSpUu1dOnSHG0sWLBAU6ZMUcmSJdW+fXv93//9n7Zt22b3nFb2xBCOyu2X3OTkZFsykf18UkREhO2Zl7+rVauW3frlI2RXkn2MY8eO5dh29OhRlShRIsfsifltO79SU1P18ccfa+LEiRo3bpytPPsZqGtRsWJFSdIvv/ySYyQoW3a/vvbaa2rWrFmudXL7pT/bokWLFBISoiVLltj1SUZGRo5YMjMzlZycfNUEOLe+LV++fJ6vz+Xn4eLiojFjxmjMmDE6deqU1q1bp2effVYdO3bUkSNH5OHhoQoVKig2NlaxsbFKSkrSypUrNW7cOKWkpGj16tVXjO165Pccypcvr2+++SZHvb//jFzLz8TlgoKCbJOi7N+/X++9954iIyN14cIFvf766/k4IwDIP0a0APxjxMTEqGzZspowYYKysrKUmZmpBQsWqHr16tqwYUOO5cknn9SxY8dst4CNHj1aHh4eGj58uFP+Ar548WK7Lzc+fPiwNm3aZJsVsFatWgoNDdWuXbvUuHHjXBdvb+9rOnatWrVUqVIlxcfH28Vw9uxZffDBB7aZCAuSxWKRMcY2KpXtzTffVGZm5jW12aFDB5UsWVJz5szJs07Lli1VpkwZ7dmzJ89+zR59yyvuUqVK2SVHycnJOWYdzL6t7kqxXMldd92l9evX55hVceHChfLw8Mg1SSxTpox69Oih4cOH68SJEzkm3ZD+HJl9/PHH1b59e3377bfXFFt+3XXXXdqzZ0+O4yxcuFAWi0Xt2rWT9OcfQk6fPm03G6P054Qtl3Pmz0TNmjX13HPPqX79+gXeDwD+mRjRAvCPUbZsWUVEROjpp59WfHy8ypQpo6NHj2ratGl2U55nq1evnmbNmqV58+bp3nvvVfXq1bV48WL16dNH9evX19ChQ21fWJySkqI1a9ZIUp5Tv/9dSkqK/vWvf+nRRx9VamqqJk6cKDc3N0VERNjq/Oc//1Hnzp3VsWNHDRo0SJUqVdKJEye0d+9effvtt3r//fevqS9KlCihmJgY9evXT/fee6+GDBmijIwMvfTSSzp16pRefPHFa2rXEaVLl9Ydd9yhl156SRUqVFBwcLASEhI0b948lSlT5praDA4O1rPPPqsXXnhB586dU58+feTj46M9e/bojz/+0KRJk+Tl5aXXXntN4eHhOnHihHr06CFfX1/9/vvv2rVrl37//fcrJkfZU7EPGzZMPXr00JEjR/TCCy8oICDA7pm+1q1ba8CAAZoyZYp+++033XvvvbJardqxY4c8PDw0YsSIK57LxIkT9fHHH6tdu3aaMGGCypUrp3feeUerVq1STEyMfHx8JEldu3a1fWdcxYoVdfjwYcXGxiooKEihoaFKTU1Vu3bt1LdvX9WuXVve3t7aunWrVq9eneeokLOMHj1aCxcuVJcuXTR58mQFBQVp1apVmj17toYOHWp7Lm3gwIGaOXOmBg4cqKlTpyo0NFSffPKJPvvssxxtXuvPxHfffafHH39cPXv2VGhoqEqVKqX169fru+++sxtRBQCnKcSJOACgQGTPULd169Yc286dO2eqVq1qQkNDzQMPPGBKlSplUlJS8myrd+/exsXFxSQnJ9vKDh48aEaMGGFq1apl3N3djdVqNUFBQaZnz55m+fLldjMJ5iZ7NrS3337bjBw50lSsWNFYrVbTunVrs23bthz1d+3aZXr16mV8fX2Nq6ur8ff3N3feeadtlsSrnXNusw5mW7FihWnatKlxc3Mznp6e5q677jJfffWVXZ3smed+//33HPsHBQWZLl265CiXZIYPH25XlpiYaCSZl156yVb2yy+/mO7du5uyZcsab29v06lTJ/PDDz+YoKAgEx4eftXz+/vMctkWLlxomjRpYtzc3IyXl5dp1KiR3cx1xhiTkJBgunTpYsqVK2dcXV1NpUqVTJcuXXLtp7978cUXTXBwsLFaraZOnTpm7ty5tn66XGZmppk5c6apV6+eKVWqlPHx8THNmzc3H3300VX70Bhjvv/+e9O1a1fj4+NjSpUqZW655ZYc5zF9+nTTokULU6FCBVOqVClTtWpV8/DDD5tDhw4ZY4w5f/68eeyxx0yDBg1M6dKljbu7u6lVq5aZOHGi3ayQucnrtQ8PDzeenp456rdp08bUrVvXruzw4cOmb9++pnz58sbV1dXUqlXLvPTSSzlm58y+Fry8vIy3t7fp3r272bRpU45ZB43J38/E36+N3377zQwaNMjUrl3beHp6Gi8vL9OgQQMzc+ZMc+nSpSv2AwBcC4sxl90zAgAocBs3blS7du30/vvv254VAwAAxQvPaAEAAACAk5FoAQAAAICTcesgAAAAADgZI1oAAAAA4GQkWgAAAADgZCRaAAAAAOBkxf4Li7OysnT06FF5e3vLYrEUdjgAAAAACokxRqdPn1ZgYKBKlCjYMadin2gdPXpUVapUKewwAAAAANwkjhw5osqVKxfoMYp9ouXt7S3pz84sXbp0IUcDAAAAoLCkpaWpSpUqthyhIBX7RCv7dsHSpUuTaAEAAAC4IY8UMRkGAAAAADgZiRYAAAAAOBmJFgAAAAA4GYkWAAAAADgZiRYAAAAAOBmJFgAAAAA4GYkWcBO6dOmSnnvuOYWEhMjd3V3VqlXT5MmTlZWVZauzbNkydezYURUqVJDFYtHOnTuv2u7cuXPVunVrlS1bVmXLltXdd9+tb775xq5OZGSkLBaL3eLv7+/sUwQAACjWSLSAm9C0adP0+uuva9asWdq7d69iYmL00ksv6bXXXrPVOXv2rFq2bKkXX3wx3+1u3LhRffr00YYNG7R582ZVrVpVHTp00K+//mpXr27dujp27Jht+f777512bgAAAP8Exf4Li4GiaPPmzbr//vvVpUsXSVJwcLAWL16sbdu22eoMGDBAknTo0KF8t/vOO+/Yrc+dO1dLly7V559/roEDB9rKXVxcGMUCAAC4DoxoATehVq1a6fPPP9f+/fslSbt27dKXX36pe+65x6nHSU9P18WLF1WuXDm78gMHDigwMFAhISHq3bu3fv75Z6ceFwAAoLhjRAu4CT3zzDNKTU1V7dq1VbJkSWVmZmrq1Knq06ePU48zbtw4VapUSXfffbetrGnTplq4cKFq1qyp3377TVOmTFGLFi20e/dulS9f3qnHBwAAKK5ItICb0JIlS7Ro0SLFx8erbt262rlzp0aNGqXAwECFh4c75RgxMTFavHixNm7cKDc3N1t5586dbf+vX7++mjdvrurVq2vBggUaM2aMU44NAABQ3JFoATehp556SuPGjVPv3r0l/ZnwHD58WNHR0U5JtF5++WVFRUVp3bp1atCgwRXrenp6qn79+jpw4MB1HxcAAOCfgme0gJtQenq6SpSw//EsWbKk3fTu1+qll17SCy+8oNWrV6tx48ZXrZ+RkaG9e/cqICDguo8NAADwT8GIFnAT6tq1q6ZOnaqqVauqbt262rFjh2bMmKHBgwfb6pw4cUJJSUk6evSoJGnfvn2SJH9/f9uMgQMHDlSlSpUUHR0t6c/bBZ9//nnFx8crODhYycnJkiQvLy95eXlJksaOHauuXbuqatWqSklJ0ZQpU5SWlua0WxYBAAD+CSzGGFPYQRSktLQ0+fj4KDU1VaVLly7scAAbyyRL3hszJK2X9KOks5K8JdWT1EZ//Xlkh6QPc9m3jaR2//t/nKQykv71v/WZklKvss/7kg5LSpfkKany/7b5Xvl8zMRi/VYCAACKgRuZGzCiBdyMrJI6/2/JS6P/LVfy0N/WR+fj2D3zUQcAAABXVKjPaF26dEnPPfecQkJC5O7urmrVqmny5Ml2z6EYYxQZGanAwEC5u7urbdu22r17dyFGDQAAAABXVqiJ1rRp0/T6669r1qxZ2rt3r2JiYvTSSy/ptddes9WJiYnRjBkzNGvWLG3dulX+/v5q3769Tp8+XYiRAwAAAEDeCjXR2rx5s+6//3516dJFwcHB6tGjhzp06KBt27ZJ+nM0KzY2VuPHj1e3bt1Ur149LViwQOnp6YqPjy/M0AEAAAAgT4WaaLVq1Uqff/659u/fL0natWuXvvzyS91zzz2SpMTERCUnJ6tDhw62faxWq9q0aaNNmzbl2mZGRobS0tLsFgAAAAC4kQp1MoxnnnlGqampql27tkqWLKnMzExNnTpVffr0kSTb1NN+fn52+/n5+enw4cO5thkdHa1JkyYVbOAAAAAAcAWFOqK1ZMkSLVq0SPHx8fr222+1YMECvfzyy1qwYIFdPYvFfhpsY0yOsmwRERFKTU21LUeOHCmw+AEAAAAgN4U6ovXUU09p3Lhx6t27tySpfv36Onz4sKKjoxUeHm770tXk5GQFBATY9ktJSckxypXNarXKarUWfPAAAAAAkIdCHdFKT09XiRL2IZQsWdI2vXtISIj8/f21du1a2/YLFy4oISFBLVq0uKGxAgAAAEB+FeqIVteuXTV16lRVrVpVdevW1Y4dOzRjxgwNHjxY0p+3DI4aNUpRUVEKDQ1VaGiooqKi5OHhob59+xZm6AAAAACQp0JNtF577TU9//zzGjZsmFJSUhQYGKghQ4ZowoQJtjpPP/20zp07p2HDhunkyZNq2rSp1qxZI29v70KMHAAAAADyZjHGmMIOoiClpaXJx8dHqampKl26dGGHA9hYJuU+oUtRZSYW67cSAABQDNzI3KBQn9ECAAAAgOKIRAsAAAAAnIxECwAAAACcjEQLAAAAAJyMRAsAAAAAnIxECwAAAACcjEQLAAAAAJyMRAsAAAAAnIxECwAAAACcjEQLAAAAAJyMRAsAAAAAnIxECwAAAACcjEQLAAAAAJyMRAsAAAAAnIxECwAAAACcjEQLAAAAAJyMRAsAAAAAnIxECwAAAACcjEQLAAAAAJyMRAsAAAAAnIxE6yYTHBwsi8WSYxk+fLgkadmyZerYsaMqVKggi8WinTt35qvd2NhY1apVS+7u7qpSpYpGjx6t8+fP27ZfunRJzz33nEJCQuTu7q5q1app8uTJysrKKojTBAAAAIo1l8IOAPa2bt2qzMxM2/oPP/yg9u3bq2fPnpKks2fPqmXLlurZs6ceffTRfLX5zjvvaNy4cXrrrbfUokUL7d+/X4MGDZIkzZw5U5I0bdo0vf7661qwYIHq1q2rbdu26aGHHpKPj4+eeOIJ554kAAAAUMyRaN1kKlasaLf+4osvqnr16mrTpo0kacCAAZKkQ4cO5bvNzZs3q2XLlurbt6+kP0fN+vTpo2+++cauzv33368uXbrY6ixevFjbtm27ntMBAAAA/pG4dfAmduHCBS1atEiDBw+WxWK55nZatWql7du32xKrn3/+WZ988oktqcqu8/nnn2v//v2SpF27dunLL7/UPffcc30nAQAAAPwDMaJ1E1uxYoVOnTplu83vWvXu3Vu///67WrVqJWOMLl26pKFDh2rcuHG2Os8884xSU1NVu3ZtlSxZUpmZmZo6dar69OlznWcBAAAA/POQaN3E5s2bp86dOyswMPC62tm4caOmTp2q2bNnq2nTpvrpp5/0xBNPKCAgQM8//7wkacmSJVq0aJHi4+NVt25d7dy5U6NGjVJgYKDCw8OdcToAAADAPwaJ1k3q8OHDWrdunZYtW3bdbT3//PMaMGCAHnnkEUlS/fr1dfbsWf373//W+PHjVaJECT311FMaN26cevfubatz+PBhRUdHk2gBAAAADuIZrZtUXFycfH197Z6julbp6ekqUcL+pS5ZsqSMMTLGXLEO07sDAAAAjmNE6yaUlZWluLg4hYeHy8XF/iU6ceKEkpKSdPToUUnSvn37JEn+/v7y9/eXJA0cOFCVKlVSdHS0JKlr166aMWOGGjVqZLt18Pnnn9d9992nkiVL2upMnTpVVatWVd26dbVjxw7NmDFDgwcPvlGnDQAAABQbJFo3oXXr1ikpKSnXJGflypV66KGHbOvZt/pNnDhRkZGRkqSkpCS70annnntOFotFzz33nH799VdVrFjRllhle+211/T8889r2LBhSklJUWBgoIYMGaIJEyYU0FkCAAAAxZfFZN87VkylpaXJx8dHqampKl26dGGHI8uka5+m/WZkJhbry6dAcS0AAADcWDcyN+AZLQAAAABwMhItAAAAAHAyEi0AAAAAcLJCTbSCg4NlsVhyLMOHD5ckGWMUGRmpwMBAubu7q23bttq9e3dhhgwAAAAAV1WoidbWrVt17Ngx27J27VpJUs+ePSVJMTExmjFjhmbNmqWtW7fK399f7du31+nTpwszbAAAAAC4okJNtCpWrGj7/id/f399/PHHql69utq0aSNjjGJjYzV+/Hh169ZN9erV04IFC5Senq74+PjCDBsAAAAAruimeUbrwoULWrRokQYPHiyLxaLExEQlJyerQ4cOtjpWq1Vt2rTRpk2b8mwnIyNDaWlpdgsAAAAA3Eg3TaK1YsUKnTp1SoMGDZIkJScnS5L8/Pzs6vn5+dm25SY6Olo+Pj62pUqVKgUWMwAAAADk5qZJtObNm6fOnTsrMDDQrtxisf9SV2NMjrLLRUREKDU11bYcOXKkQOIFAAAAgLy4FHYAknT48GGtW7dOy5Yts5X5+/tL+nNkKyAgwFaekpKSY5TrclarVVarteCCBQAAAICruClGtOLi4uTr66suXbrYykJCQuTv72+biVD68zmuhIQEtWjRojDCBAAAAIB8KfQRraysLMXFxSk8PFwuLn+FY7FYNGrUKEVFRSk0NFShoaGKioqSh4eH+vbtW4gRAwAAAMCVFXqitW7dOiUlJWnw4ME5tj399NM6d+6chg0bppMnT6pp06Zas2aNvL29CyFSAAAAAMgfizHGFHYQBSktLU0+Pj5KTU1V6dKlCzscWSblPZFHUWQmFuvLp0BxLQAAANxYNzI3uCme0QIAAACA4oRECwAAAACcjEQLAAAAAJyMRAsAAAAoYn799Vf1799f5cuXl4eHhxo2bKjt27fbtg8aNEgWi8Vuadas2VXbPXXqlIYPH66AgAC5ubmpTp06+uSTT2zbo6Oj1aRJE3l7e8vX11cPPPCA9u3bVyDnWNQV+qyDAAAAAPLv5MmTatmypdq1a6dPP/1Uvr6+OnjwoMqUKWNXr1OnToqLi7OtlypV6ortXrhwQe3bt5evr6+WLl2qypUr68iRI3YzfickJGj48OFq0qSJLl26pPHjx6tDhw7as2ePPD09nXqeRR2JFgAAAFCETJs2TVWqVLFLooKDg3PUs1qt8vf3z3e7b731lk6cOKFNmzbJ1dVVkhQUFGRXZ/Xq1XbrcXFx8vX11fbt23XHHXc4cBbFH7cOAgAAAEXIypUr1bhxY/Xs2VO+vr5q1KiR5s6dm6Pexo0b5evrq5o1a+rRRx9VSkrKVdtt3ry5hg8fLj8/P9WrV09RUVHKzMzMc5/U1FRJUrly5a7vpIohEi0AAACgCPn55581Z84chYaG6rPPPtNjjz2mkSNHauHChbY6nTt31jvvvKP169dr+vTp2rp1q+68805lZGRcsd2lS5cqMzNTn3zyiZ577jlNnz5dU6dOzbW+MUZjxoxRq1atVK9ePaefZ1HHFxbfYHxJLbJxLQAAgGtRqlQpNW7cWJs2bbKVjRw5Ulu3btXmzZtz3efYsWMKCgrSu+++q27duuVap2bNmjp//rwSExNVsmRJSdKMGTP00ksv6dixYznqDx8+XKtWrdKXX36pypUrO+HMCh5fWAwAAAAgVwEBAQoLC7Mrq1OnjpKSkq64T1BQkA4cOHDFOjVr1rQlWdntJicn68KFC3Z1R4wYoZUrV2rDhg1FJsm60Ui0AAAAgCKkZcuWOaZU379/f46JKy53/PhxHTlyRAEBAVds96efflJWVpZduwEBAbYZC40xevzxx7Vs2TKtX79eISEh13k2xReJFgAAAFCEjB49Wlu2bFFUVJR++uknxcfH64033tDw4cMlSWfOnNHYsWO1efNmHTp0SBs3blTXrl1VoUIF/etf/7K1M3DgQEVERNjWhw4dquPHj+uJJ57Q/v37tWrVKkVFRdnalf68XXDRokWKj4+Xt7e3kpOTlZycrHPnzt24DigimN4dAAAAKEKaNGmi5cuXKyIiQpMnT1ZISIhiY2PVr18/SVLJkiX1/fffa+HChTp16pQCAgLUrl07LVmyxO47sZKSklSixF/jLlWqVNGaNWs0evRoNWjQQJUqVdITTzyhZ555xlZnzpw5kqS2bdvaxRQXF6dBgwYV3EkXQUyGcYMxAQKycS0AAIC88HtCwWAyDAAAAAAowki0AAAAAMDJSLQAAAAAwMlItAAAAIqwX3/9Vf3791f58uXl4eGhhg0bavv27ZKkixcv6plnnlH9+vXl6empwMBADRw4UEePHr1im/Pnz5fFYsmxnD9//kacElAsMOsgAABAEXXy5Em1bNlS7dq106effipfX18dPHhQZcqUkSSlp6fr22+/1fPPP69bbrlFJ0+e1KhRo3Tfffdp27ZtV2y7dOnSOb6ryc3NraBOBSh2SLQAAACKqGnTpqlKlSqKi4uzlQUHB9v+7+Pjo7Vr19rt89prr+n2229XUlKSqlatmmfbFotF/v7+To8Z+Kfg1kEAAIAiauXKlWrcuLF69uwpX19fNWrUSHPnzr3iPqmpqbJYLLZRr7ycOXNGQUFBqly5su69917t2LHDiZEDxR+JFgAAQBH1888/a86cOQoNDdVnn32mxx57TCNHjtTChQtzrX/+/HmNGzdOffv2veJ3CNWuXVvz58/XypUrtXjxYrm5ually5Y6cOBAQZ0KUOxw6yAAAEARlZWVpcaNGysqKkqS1KhRI+3evVtz5szRwIED7epevHhRvXv3VlZWlmbPnn3Fdps1a6ZmzZrZ1lu2bKlbb71Vr732ml599VXnnwhQDDGiBQAAUEQFBAQoLCzMrqxOnTpKSkqyK7t48aJ69eqlxMRErV279oqjWbkpUaKEmjRpwogW4AASLQAAgCKqZcuWOWYG3L9/v4KCgmzr2UnWgQMHtG7dOpUvX97h4xhjtHPnTgUEBFx3zMA/xTUlWm+//bZatmypwMBAHT58WJIUGxurDz/80KnBAQAAIG+jR4/Wli1bFBUVpZ9++knx8fF64403NHz4cEnSpUuX1KNHD23btk3vvPOOMjMzlZycrOTkZF24cMHWzsCBAxUREWFbnzRpkj777DP9/PPP2rlzpx5++GHt3LlTjz322A0/R6CocjjRmjNnjsaMGaN77rlHp06dUmZmpiSpTJkyio2NdXZ8AAAAyEOTJk20fPlyLV68WPXq1dMLL7yg2NhY9evXT5L0yy+/aOXKlfrll1/UsGFDBQQE2JZNmzbZ2klKStKxY8ds66dOndK///1v1alTRx06dNCvv/6qL774QrfffvsNP0egqLIYY4wjO4SFhSkqKkoPPPCAvL29tWvXLlWrVk0//PCD2rZtqz/++KOgYr0maWlp8vHxUWpqqsP3IxcEyyRLYYfgVGaiQ5cPLsO1AAD4Oz4bkI1roWDcyNzA4RGtxMRENWrUKEe51WrV2bNnnRIUAAAAABRlDidaISEh2rlzZ47yTz/9NMesNwAAAADwT+Tw92g99dRTGj58uM6fPy9jjL755hstXrxY0dHRevPNNwsiRgAAAAAoUhxOtB566CFdunRJTz/9tNLT09W3b19VqlRJr7zyinr37l0QMQIAAABAkeJwoiVJjz76qB599FH98ccfysrKkq+vr7PjAgAAAIAiy+FEKzExUZcuXVJoaKgqVKhgKz9w4IBcXV0VHBzszPgAAAAAoMhxeDKMQYMG2X3vQravv/5agwYNcjiAX3/9Vf3791f58uXl4eGhhg0bavv27bbtxhhFRkYqMDBQ7u7uatu2rXbv3u3wcQAAAADgRnE40dqxY4datmyZo7xZs2a5zkZ4JSdPnlTLli3l6uqqTz/9VHv27NH06dNVpkwZW52YmBjNmDFDs2bN0tatW+Xv76/27dvr9OnTjoYOAAAAADeEw7cOWiyWXJOc1NRUZWZmOtTWtGnTVKVKFcXFxdnKLr/10Bij2NhYjR8/Xt26dZMkLViwQH5+foqPj9eQIUMcDR8AAAAACpzDI1qtW7dWdHS0XVKVmZmp6OhotWrVyqG2Vq5cqcaNG6tnz57y9fVVo0aNNHfuXNv2xMREJScnq0OHDrYyq9WqNm3a5Hr7oiRlZGQoLS3NbgEAAACAG8nhEa2YmBjdcccdqlWrllq3bi1J+u9//6u0tDStX7/eobZ+/vlnzZkzR2PGjNGzzz6rb775RiNHjpTVatXAgQOVnJwsSfLz87Pbz8/PT4cPH861zejoaE2aNMnR0wIAAAAAp3F4RCssLEzfffedevXqpZSUFJ0+fVoDBw7Ujz/+qHr16jnUVlZWlm699VZFRUWpUaNGGjJkiB599FHNmTPHrp7FYrFbN8bkKMsWERGh1NRU23LkyBHHThAAAAAArtM1fY9WYGCgoqKirvvgAQEBCgsLsyurU6eOPvjgA0mSv7+/JCk5OVkBAQG2OikpKTlGubJZrVZZrdbrjg0AAAAArtU1JVqnTp3SN998o5SUFGVlZdltGzhwYL7badmypfbt22dXtn//fgUFBUmSQkJC5O/vr7Vr16pRo0aSpAsXLighIUHTpk27ltABAAAAoMA5nGh99NFH6tevn86ePStvb2+7W/gsFotDidbo0aPVokULRUVFqVevXvrmm2/0xhtv6I033rC1N2rUKEVFRSk0NFShoaGKioqSh4eH+vbt62joAAAAAHBDOJxoPfnkkxo8eLAt4bkeTZo00fLlyxUREaHJkycrJCREsbGx6tevn63O008/rXPnzmnYsGE6efKkmjZtqjVr1sjb2/u6jg0AAAAABcVijDGO7ODp6anvv/9e1apVK6iYnCotLU0+Pj5KTU1V6dKlCzscWSblPolHUWUmOnT54DJcCwCAv+OzAdm4FgrGjcwNHJ51sGPHjtq2bVtBxAIAAAAAxYLDtw526dJFTz31lPbs2aP69evL1dXVbvt9993ntOAAAAAAoChyONF69NFHJUmTJ0/Osc1isSgzM/P6owIAAACAIszhROvv07kDAAAAAOw5/IwWAAAAAODKrukLi8+ePauEhAQlJSXpwoULdttGjhzplMAAAAAAoKhyONHasWOH7rnnHqWnp+vs2bMqV66c/vjjD3l4eMjX15dECwAAAMA/nsO3Do4ePVpdu3bViRMn5O7uri1btujw4cO67bbb9PLLLxdEjAAAAABQpDicaO3cuVNPPvmkSpYsqZIlSyojI0NVqlRRTEyMnn322YKIEQAAAACKFIcTLVdXV1ksf35TtZ+fn5KSkiRJPj4+tv8DAAAAwD+Zw89oNWrUSNu2bVPNmjXVrl07TZgwQX/88Yfefvtt1a9fvyBiBAAAAIAixeERraioKAUEBEiSXnjhBZUvX15Dhw5VSkqK3njjDacHCAAAAABFjcMjWo0bN7b9v2LFivrkk0+cGhAAAAAAFHV8YTEAAAAAOJnDI1rHjx/XhAkTtGHDBqWkpCgrK8tu+4kTJ5wWHAAAAAAURQ6PaPXv319r165VeHi4Xn75Zc2cOdNuAQA4R2RkpCwWi93i7+9vt7127dry9PRU2bJldffdd+vrr7++Ypu7d+9W9+7dFRwcLIvFotjY2Bx1oqOj1aRJE3l7e8vX11cPPPCA9u3b5+zTAwCgWHN4ROvLL7/Ul19+qVtuuaUg4gEAXKZu3bpat26dbb1kyZK2/9esWVOzZs1StWrVdO7cOc2cOVMdOnTQTz/9pIoVK+baXnp6uqpVq6aePXtq9OjRudZJSEjQ8OHD1aRJE126dEnjx49Xhw4dtGfPHnl6ejr3BAEAKKYcTrRq166tc+fOFUQsAIC/cXFxsRvFulzfvn3t1mfMmKF58+bpu+++01133ZXrPk2aNFGTJk0kSePGjcu1zurVq+3W4+Li5Ovrq+3bt+uOO+5w9BQAAPhHcvjWwdmzZ2v8+PFKSEjQ8ePHlZaWZrcAAJznwIEDCgwMVEhIiHr37q2ff/4513oXLlzQG2+8IR8fH6ffcZCamipJKleunFPbBQCgOHN4RKtMmTJKTU3VnXfeaVdujJHFYlFmZqbTggOAf7KmTZtq4cKFqlmzpn777TdNmTJFLVq00O7du1W+fHlJ0scff6zevXsrPT1dAQEBWrt2rSpUqOC0GIwxGjNmjFq1aqV69eo5rV0AAIo7hxOtfv36qVSpUoqPj5efn58sFktBxAUA/3idO3e2/b9+/fpq3ry5qlevrgULFmjMmDGSpHbt2mnnzp36448/NHfuXPXq1Utff/21fH19nRLD448/ru+++05ffvmlU9oDAOCfwuFE64cfftCOHTtUq1atgogHAJAHT09P1a9fXwcOHLArq1GjhmrUqKFmzZopNDRU8+bNU0RExHUfb8SIEVq5cqW++OILVa5c+brbAwDgn8ThZ7QaN26sI0eOFEQsAIAryMjI0N69exUQEJBnHWOMMjIyrus4xhg9/vjjWrZsmdavX6+QkJDrag8AgH8ih0e0RowYoSeeeEJPPfWU6tevL1dXV7vtDRo0cFpwAPBPNnbsWHXt2lVVq1ZVSkqKpkyZorS0NIWHh+vs2bOaOnWq7rvvPgUEBOj48eOaPXu2fvnlF/Xs2dPWxsCBA1WpUiVFR0dL+nPSjD179tj+/+uvv2rnzp3y8vJSjRo1JEnDhw9XfHy8PvzwQ3l7eys5OVmS5OPjI3d39xvcCwAAFE0WY4xxZIcSJXIOglkslpt2Moy0tDT5+PgoNTVVpUuXLuxwZJlUvJ5pMxMdunxwGa4FSFe5Dt6XdFhSuiRPSZUltZPkK+mipA8k/fq/7e6SKkm643//ZouTVEbSv/63flLSK7kcK0jSQ//7f2Qe8dwvqdGVzobrALhefDYgG9dCwbiRuYHDI1qJiYkFEQcA4O96XmGbq6Te+Wjjob+tl1XeiVS2q20HAABX5VCidfHiRbVr104ff/yxwsLCCiomAAAAACjSHJoMw9XVVRkZGUzpDgAAAABX4PCsgyNGjNC0adN06dKlgogHAAAAAIo8hxOtr7/+WsuWLVPVqlXVsWNHdevWzW4BAAAFKzIyUhaLxW7x9/e3bTfGKDIyUoGBgXJ3d1fbtm21e/fuq7b7wQcfKCwsTFarVWFhYVq+fHlBngYAFGsOJ1plypRR9+7d1bFjRwUGBsrHx8duAQAABa9u3bo6duyYbfn+++9t22JiYjRjxgzNmjVLW7dulb+/v9q3b6/Tp0/n2d7mzZv14IMPasCAAdq1a5cGDBigXr166euvv74RpwMAxY7Dsw7GxcUVRBwAAMABLi4udqNY2Ywxio2N1fjx4213mixYsEB+fn6Kj4/XkCFDcm0vNjZW7du3V0REhCQpIiJCCQkJio2N1eLFiwvuRACgmHJ4RCvb77//ri+//FJfffWVfv/9d2fGBAAAruLAgQMKDAxUSEiIevfurZ9//lnSn1/DkpycrA4dOtjqWq1WtWnTRps2bcqzvc2bN9vtI0kdO3a84j4AgLw5nGidPXtWgwcPVkBAgO644w61bt1agYGBevjhh5Wenl4QMQIAgMs0bdpUCxcu1Geffaa5c+cqOTlZLVq00PHjx5WcnCxJ8vPzs9vHz8/Pti03ycnJDu8DAMibw4nWmDFjlJCQoI8++kinTp3SqVOn9OGHHyohIUFPPvmkQ20V1MO8AAAUZ507d1b37t1Vv3593X333Vq1apWkP28RzPb3r2Ixxlz161muZR8AQO4cTrQ++OADzZs3T507d1bp0qVVunRp3XPPPZo7d66WLl3qcADOfpgXAIB/Gk9PT9WvX18HDhyw/cHy7yNRKSkpOUasLufv7+/wPgCAvDmcaKWnp+f6puvr63tNtw5mP8ybvVSsWFFSzod569WrpwULFig9PV3x8fEOHwcAgOIqIyNDe/fuVUBAgEJCQuTv76+1a9fatl+4cEEJCQlq0aJFnm00b97cbh9JWrNmzRX3AQDkzeFEq3nz5po4caLOnz9vKzt37pwmTZqk5s2bOxyAsx/mzcjIUFpamt0CAEBxMnbsWCUkJCgxMVFff/21evToobS0NIWHh8tisWjUqFGKiorS8uXL9cMPP2jQoEHy8PBQ3759bW0MHDjQNsOgJD3xxBNas2aNpk2bph9//FHTpk3TunXrNGrUqEI4QwAo+hye3j02NladO3dW5cqVdcstt8hisWjnzp1yc3PTZ5995lBb2Q/z1qxZU7/99pumTJmiFi1aaPfu3Vd8mPfw4cN5thkdHa1JkyY5eloAABQqyyQHnoVaLU3/z3QpXZKnpMqSBkjB84P/3G4kNZS6Dewmnfvf9gek0jNK/9XGF5LKSC+6vfhXWTdp3EvjNO7ZcVK5P9ebrW4mrXb8fMxE4/hOAFCMOJxoZd8DvmjRIv34448yxqh3797q16+f3N3dHWqrc+fOdu02b95c1atX14IFC9SsWTNJjj+YGxERoTFjxtjW09LSVKVKFYfiAgDgptbzKtstktr9b8nLQ7mU1f3fAgC4bvlKtG699VZ9/vnnKlu2rCZPnqyxY8fq0UcfdXowlz/M+8ADD0j682HegIAAW52rPZhrtVpltVqdHhsAAAAA5Fe+ntHau3evzp49K0maNGmSzpw5UyDBOONhXgAAAAAobPka0WrYsKEeeughtWrVSsYYvfzyy/Ly8sq17oQJE/J98LFjx6pr166qWrWqUlJSNGXKlFwf5g0NDVVoaKiioqJyPMwLAAAAADebfCVa8+fP18SJE/Xxxx/LYrHo008/lYtLzl0tFotDidYvv/yiPn366I8//lDFihXVrFkzbdmyRUFBQZKkp59+WufOndOwYcN08uRJNW3aVGvWrJG3t3e+jwEAAAAAN1q+Eq1atWrp3XfflSSVKFFCn3/+uXx9fa/74Nlt5sVisSgyMlKRkZHXfSwAAAAAuFEc+h6tixcvauDAgQX2jBYAAAAAFAcOJVqurq768MMPCyoWAAAAACgWHEq0JOmBBx7QihUrCiAUAAAAACgeHP7C4ho1auiFF17Qpk2bdNttt8nT09Nu+8iRI50WHAAAAAAURQ4nWm+++abKlCmj7du3a/v27XbbLBYLiRYAAACAfzyHE63ExMSCiAMAAAAAig2Hn9HKduHCBe3bt0+XLl1yZjwAAAAAUOQ5nGilp6fr4YcfloeHh+rWraukpCRJfz6b9eKLLzo9QAAAAAAoahxOtCIiIrRr1y5t3LhRbm5utvK7775bS5YscWpwAAAAAFAUOfyM1ooVK7RkyRI1a9ZMFovFVh4WFqaDBw86NTgAAAAAKIocHtH6/fff5evrm6P87NmzdokXAAAAAPxTOZxoNWnSRKtWrbKtZydXc+fOVfPmzZ0XGQAAAAAUUQ7fOhgdHa1OnTppz549unTpkl555RXt3r1bmzdvVkJCQkHECAAAAABFisMjWi1atNBXX32l9PR0Va9eXWvWrJGfn582b96s2267rSBiBAAAAIAixeERLUmqX7++FixY4OxYAAAAAKBYuKZEKzMzU8uXL9fevXtlsVhUp04d3X///XJxuabmAAAAAKBYcTgz+uGHH3T//fcrOTlZtWrVkiTt379fFStW1MqVK1W/fn2nBwkAAAAARYnDz2g98sgjqlu3rn755Rd9++23+vbbb3XkyBE1aNBA//73vwsiRgAAAAAoUhwe0dq1a5e2bdumsmXL2srKli2rqVOnqkmTJk4NDgAAAACKIodHtGrVqqXffvstR3lKSopq1KjhlKAAAAAAoChzONGKiorSyJEjtXTpUv3yyy/65ZdftHTpUo0aNUrTpk1TWlqabQEAAACAfyKHbx289957JUm9evWSxWKRJBljJEldu3a1rVssFmVmZjorTgAAAAAoMhxOtDZs2FAQcQAAAABAseFwotWmTZuCiAMAAAAAig2Hn9ECAAAAAFwZiRYAAAAAOBmJFgAAAAA4GYkWAAAAADiZw4lWZGSkDh8+XBCxAAAAAECx4HCi9dFHH6l69eq66667FB8fr/PnzxdEXAAAAABQZDmcaG3fvl3ffvutGjRooNGjRysgIEBDhw7V1q1bCyI+AAAAAChyrukZrQYNGmjmzJn69ddf9dZbb+nXX39Vy5YtVb9+fb3yyitKTU11dpwAAAAAUGRc12QYWVlZunDhgjIyMmSMUbly5TRnzhxVqVJFS5YscVaMAAAAAFCkXFOitX37dj3++OMKCAjQ6NGj1ahRI+3du1cJCQn68ccfNXHiRI0cOdLZsQIAAABAkeBwotWgQQM1a9ZMiYmJmjdvno4cOaIXX3xRNWrUsNUZOHCgfv/9d4fajY6OlsVi0ahRo2xlxhhFRkYqMDBQ7u7uatu2rXbv3u1oyAAAAABwQzmcaPXs2VOHDh3SqlWr9MADD6hkyZI56lSsWFFZWVn5bnPr1q1644031KBBA7vymJgYzZgxQ7NmzdLWrVvl7++v9u3b6/Tp046GDQAAAAA3jMOJ1vPPP69KlSo5LYAzZ86oX79+mjt3rsqWLWsrN8YoNjZW48ePV7du3VSvXj0tWLBA6enpio+Pd9rxAQAAAMDZHE60evTooRdffDFH+UsvvaSePXs6HMDw4cPVpUsX3X333XbliYmJSk5OVocOHWxlVqtVbdq00aZNmxw+DgAAAADcKA4nWgkJCerSpUuO8k6dOumLL75wqK13331X3377raKjo3NsS05OliT5+fnZlfv5+dm25SYjI0NpaWl2CwAAAADcSA4nWmfOnFGpUqVylLu6ujqU1Bw5ckRPPPGEFi1aJDc3tzzrWSwWu3VjTI6yy0VHR8vHx8e2VKlSJd8xAQAAAIAzOJxo1atXL9fvyHr33XcVFhaW73a2b9+ulJQU3XbbbXJxcZGLi4sSEhL06quvysXFxTaS9ffRq5SUlByjXJeLiIhQamqqbTly5Ei+YwIAAAAAZ3BxdIfnn39e3bt318GDB3XnnXdKkj7//HMtXrxY77//fr7bueuuu/T999/blT300EOqXbu2nnnmGVWrVk3+/v5au3atGjVqJEm6cOGCEhISNG3atDzbtVqtslqtjp4WAAAAADiNw4nWfffdpxUrVigqKkpLly6Vu7u7GjRooHXr1qlNmzb5bsfb21v16tWzK/P09FT58uVt5aNGjVJUVJRCQ0MVGhqqqKgoeXh4qG/fvo6GDQAAAAA3jMOJliR16dIl1wkxnO3pp5/WuXPnNGzYMJ08eVJNmzbVmjVr5O3tXeDHBgAAAIBrdU2JVkHZuHGj3brFYlFkZKQiIyMLJR4AAAAAuBYOJ1qZmZmaOXOm3nvvPSUlJenChQt220+cOOG04AAAAACgKHJ41sFJkyZpxowZ6tWrl1JTUzVmzBh169ZNJUqUYOQJAAAAAHQNidY777yjuXPnauzYsXJxcVGfPn305ptvasKECdqyZUtBxAgAAAAARYrDiVZycrLq168vSfLy8lJqaqok6d5779WqVaucGx0AAAAAFEEOJ1qVK1fWsWPHJEk1atTQmjVrJElbt27l+6sAAAAAQNeQaP3rX//S559/Lkl64okn9Pzzzys0NFQDBw7U4MGDnR4gAAAAABQ1Ds86+OKLL9r+36NHD1WpUkVfffWVatSoofvuu8+pwQEAAABAUeRQonXx4kX9+9//1vPPP69q1apJkpo2baqmTZsWSHAAAAAAUBQ5dOugq6urli9fXlCxAAAAAECxcE3PaK1YsaIAQgEAAACA4sHhZ7Rq1KihF154QZs2bdJtt90mT09Pu+0jR450WnAAAAAAUBQ5nGi9+eabKlOmjLZv367t27fbbbNYLCRaAAAAAP7xHE60EhMTCyIOAAAAACg2HH5GCwAAAABwZQ6PaF3tS4nfeuutaw4GAAAAAIoDhxOtkydP2q1fvHhRP/zwg06dOqU777zTaYEBAAAAQFHlcKKV2/doZWVladiwYbYvMQYAAACAfzKnPKNVokQJjR49WjNnznRGcwAAAABQpDltMoyDBw/q0qVLzmoOAAAAAIosh28dHDNmjN26MUbHjh3TqlWrFB4e7rTAAAAAAKCocjjR2rFjh916iRIlVLFiRU2fPv2qMxICAAAAwD+Bw4nWhg0bCiIOAAAAACg2HH5GKzExUQcOHMhRfuDAAR06dMgZMQEAAABAkeZwojVo0CBt2rQpR/nXX3+tQYMGOSMmAAAAACjSHE60duzYoZYtW+Yob9asmXbu3OmMmAAAAACgSHM40bJYLDp9+nSO8tTUVGVmZjolKAAAAAAoyhxOtFq3bq3o6Gi7pCozM1PR0dFq1aqVU4MDAAAAgKLI4VkHY2JidMcdd6hWrVpq3bq1JOm///2v0tLStH79eqcHCAAAAABFjcMjWmFhYfruu+/Uq1cvpaSk6PTp0xo4cKB+/PFH1atXryBiBAAAAIAixeERLUkKDAxUVFSUs2MBAAAAgGLB4RGtuLg4vf/++znK33//fS1YsMApQQEAAABAUeZwovXiiy+qQoUKOcp9fX0Z5QIAAAAAXUOidfjwYYWEhOQoDwoKUlJSklOCAgAAAICizOFEy9fXV999912O8l27dql8+fJOCQoAAAAAijKHE63evXtr5MiR2rBhgzIzM5WZman169friSeeUO/evR1qa86cOWrQoIFKly6t0qVLq3nz5vr0009t240xioyMVGBgoNzd3dW2bVvt3r3b0ZABAAAA4IZyONGaMmWKmjZtqrvuukvu7u5yd3dXhw4ddOedd2rq1KkOtVW5cmW9+OKL2rZtm7Zt26Y777xT999/vy2ZiomJ0YwZMzRr1ixt3bpV/v7+at++vU6fPu1o2AAAAABwwzg8vXupUqW0ZMkSTZkyRTt37pS7u7vq16+voKAghw/etWtXu/WpU6dqzpw52rJli8LCwhQbG6vx48erW7dukqQFCxbIz89P8fHxGjJkiMPHAwAAAIAbweERrWyhoaHq2bOn7r33XpUuXVqvvfaaGjZseM2BZGZm6t1339XZs2fVvHlzJSYmKjk5WR06dLDVsVqtatOmjTZt2nTNxwEAAACAgnZNX1icbd26dZo3b55WrFihChUq2EaeHPH999+refPmOn/+vLy8vLR8+XKFhYXZkik/Pz+7+n5+fjp8+HCe7WVkZCgjI8O2npaW5nBMAAAAAHA9HE60kpKSFBcXp7i4OJ05c0YnT57Ue++9p+7du19TALVq1dLOnTt16tQpffDBBwoPD1dCQoJtu8VisatvjMlRdrno6GhNmjTpmmIBAAAAAGfI962D7733njp06KA6derohx9+0CuvvKKjR4+qRIkSqlOnzjUHUKpUKdWoUUONGzdWdHS0brnlFr3yyivy9/eXJCUnJ9vVT0lJyTHKdbmIiAilpqbaliNHjlxzbAAAAABwLfKdaPXt21eNGzdWcnKy3n//fd1///0qVaqU0wMyxigjI0MhISHy9/fX2rVrbdsuXLighIQEtWjRIs/9rVarbbr47AUAAAAAbqR83zo4ePBgzZ49WwkJCRowYIAefPBBlS1b9roO/uyzz6pz586qUqWKTp8+rXfffVcbN27U6tWrZbFYNGrUKEVFRSk0NFShoaGKioqSh4eH+vbte13HBQAAAICClO9E64033tArr7yi9957T2+99ZZGjRqljh07yhijrKysazr4b7/9pgEDBujYsWPy8fFRgwYNtHr1arVv316S9PTTT+vcuXMaNmyYTp48qaZNm2rNmjXy9va+puMBAAAAwI3g0GQY7u7uCg8PV3h4uA4cOKC33npL27ZtU8uWLdWlSxf16NHDoZkH582bd8XtFotFkZGRioyMdCRMAAAAAChU1/U9WtHR0Tpy5IgWLVqk9PR09enTx5mxAQAAAECRdF3foyVJJUqUUNeuXdW1a1elpKQ4IyYAAAAAKNKueUQrN76+vs5sDgAAAACKJKcmWgAAAAAAEi0AAAAAcDoSLQAAAABwsmueDOP06dMyxtjWS5QoIS8vL6cEBQAAAABFWb5HtHbu3KkuXbrY1gMDA1W2bFnbUqZMGW3durVAggQAAACAoiTfI1qvvfaaWrVqZVf29ttvq1KlSjLG6K233tKrr76qt99+2+lBAgAAAEBRku9E66uvvtKgQYPsypo1a6Zq1apJktzd3dWrVy+nBgcAAAAARVG+bx08cuSIqlatalufPHmyKlSoYFsPCAjQb7/95tzoAAAAAKAIyneiZbVa9csvv9jWR48erdKlS9vWjxw5Ig8PD+dGBwAAAABFUL4TrUaNGmnFihV5bl+2bJkaNWrkjJgAAAAAoEjL9zNaw4YNU+/evRUcHKyhQ4eqRIk/c7TMzEzNnj1br732muLj4wssUAAAAAAoKvKdaHXv3l1jxozRiBEj9Oyzz6patWqyWCw6ePCgzpw5ozFjxqhHjx4FGSsAAAAAFAkOfWHxtGnT9K9//UuLFy/WgQMHJEmtW7dWnz591KxZswIJEAAAAACKGocSLenPKd1zS6qOHz+ut99+W6NGjXJGXAAAAABQZOV7MozcGGP02WefqVevXgoMDNTUqVOdFRcAAAAAFFnXlGgdOnRIEyZMUFBQkO655x5ZrVatWrVKycnJzo4PAAAAAIqcfCdaGRkZWrx4se666y7VqVNHP/zwg2bMmKESJUooIiJCd999t0qWLFmQsQIAAABAkZDvZ7QqVaqksLAw9e/fX0uXLlXZsmUlSX369Cmw4AAAAACgKMr3iFZmZqYsFossFgsjVwAAAABwBflOtI4dO6Z///vfWrx4sfz9/dW9e3ctX75cFoulIOMDAAAAgCIn34mWm5ub+vXrp/Xr1+v7779XnTp1NHLkSF26dElTp07V2rVrlZmZWZCxAgAAAECRcE2zDlavXl1TpkzR4cOHtWrVKmVkZOjee++Vr6+vs+MDAAAAgCLH4S8svlyJEiXUuXNnde7cWX/88YfmzJnjrLgAAAAAoMi6ri8szpacnKzJkycrKirKGc0BAAAAQJGW70Tr1KlT6tevnypWrKjAwEC9+uqrysrK0oQJE1StWjVt3rxZb731VkHGCgAAAABFQr5vHXz22Wf1xRdfKDw8XKtXr9bo0aO1evVqnT9/Xp9++qnatGlTkHECAAAAQJGR70Rr1apViouL0913361hw4apRo0aqlmzpmJjYwswPAAAAAAoevJ96+DRo0cVFhYmSapWrZrc3Nz0yCOPFFhgAAAAAFBU5TvRysrKkqurq229ZMmS8vT0LJCgAAAAAKAoy/etg8YYDRo0SFarVZJ0/vx5PfbYYzmSrWXLljk3QgAAAAAoYvKdaIWHh9ut9+/f3+nBAAAAAEBxkO9EKy4uriDjAAAAAIBiwylfWHytoqOj1aRJE3l7e8vX11cPPPCA9u3bZ1fHGKPIyEgFBgbK3d1dbdu21e7duwspYgAAAAC4ukJNtBISEjR8+HBt2bJFa9eu1aVLl9ShQwedPXvWVicmJkYzZszQrFmztHXrVvn7+6t9+/Y6ffp0IUYOAAAAAHnL962DBWH16tV263FxcfL19dX27dt1xx13yBij2NhYjR8/Xt26dZMkLViwQH5+foqPj9eQIUMKI2wAAAAAuKJCHdH6u9TUVElSuXLlJEmJiYlKTk5Whw4dbHWsVqvatGmjTZs25dpGRkaG0tLS7BYAAAAAuJFumkTLGKMxY8aoVatWqlevniQpOTlZkuTn52dX18/Pz7bt76Kjo+Xj42NbqlSpUrCBAwAAAMDf3DSJ1uOPP67vvvtOixcvzrHNYrHYrRtjcpRli4iIUGpqqm05cuRIgcQLAAAAAHkp1Ge0so0YMUIrV67UF198ocqVK9vK/f39Jf05shUQEGArT0lJyTHKlc1qtdq+VBkAAAAACkOhjmgZY/T4449r2bJlWr9+vUJCQuy2h4SEyN/fX2vXrrWVXbhwQQkJCWrRosWNDhcAAAAA8qVQR7SGDx+u+Ph4ffjhh/L29rY9d+Xj4yN3d3dZLBaNGjVKUVFRCg0NVWhoqKKiouTh4aG+ffsWZugAAAAAkKdCTbTmzJkjSWrbtq1deVxcnAYNGiRJevrpp3Xu3DkNGzZMJ0+eVNOmTbVmzRp5e3vf4GgBAAAAIH8KNdEyxly1jsViUWRkpCIjIws+IAAAAABwgptm1kEAAAAAKC5ItAAAAADAyUi0AAAAAMDJSLQAAAAAwMlItAAAAADAyUi0AAAAAMDJSLQAAAAAwMlItAAAAADAyUi0AAAAAMDJSLQAAAAAwMlItAAAAADAyUi0AAAAAMDJSLQAAAAAwMlItAAAAADAyUi0AAAAAMDJSLQAAAAAwMlItAAAAADAyUi0AAAAAMDJSLQAAAAAwMlItAAAAADAyUi0AAAAAMDJSLQAAAAAwMlItAAAAADAyUi0AAAAAMDJSLQAAAAAwMlItAAAAADAyUi0AAAAAMDJSLQAAAAAwMlItAAAAADAyUi0AAAAAMDJSLQAAAAAwMlItAAAAADAyUi0AAAAAMDJSLQAAAAAwMkKNdH64osv1LVrVwUGBspisWjFihV2240xioyMVGBgoNzd3dW2bVvt3r27cIIFAAAAgHwq1ETr7NmzuuWWWzRr1qxct8fExGjGjBmaNWuWtm7dKn9/f7Vv316nT5++wZECAAAAQP65FObBO3furM6dO+e6zRij2NhYjR8/Xt26dZMkLViwQH5+foqPj9eQIUNuZKgAAAAAkG837TNaiYmJSk5OVocOHWxlVqtVbdq00aZNm/LcLyMjQ2lpaXYLAAAAANxIN22ilZycLEny8/OzK/fz87Nty010dLR8fHxsS5UqVQo0TgAAAAD4u5s20cpmsVjs1o0xOcouFxERodTUVNty5MiRgg4RAAAAAOwU6jNaV+Lv7y/pz5GtgIAAW3lKSkqOUa7LWa1WWa3WAo8PAAAAAPJy045ohYSEyN/fX2vXrrWVXbhwQQkJCWrRokUhRgYAAAAAV1aoI1pnzpzRTz/9ZFtPTEzUzp07Va5cOVWtWlWjRo1SVFSUQkNDFRoaqqioKHl4eKhv376FGDUAAAAAXFmhJlrbtm1Tu3btbOtjxoyRJIWHh2v+/Pl6+umnde7cOQ0bNkwnT55U06ZNtWbNGnl7exdWyAAAAABwVYWaaLVt21bGmDy3WywWRUZGKjIy8sYFBQAAAADX6aZ9RgsAAAAAiioSLQAAAABwMhItAAAAAHAyEi0AAAAAcDISLQAAAABwMhItAAAAAHAyEi0AAAAAcDISLQAAAABwMhItAAAAAHAyEi0AAAAAcDISLQAAAABwMhItAAAAAHAyEi0AAAAAcDISLQAAAABwMhItAAAAAHAyEi0AAAAAcDISLQAAAABwMhItAAAAAHAyEi0AAAAAcDISLQAAAABwMhItAAAAAHAyEi0AAAAAcDISLQAAAABwMhItAAAAAHAyEi0AAAAAcDISLQAAAABwMhItAAAAAHAyEi0AAAAAcDISLQAAAABwMhItAAAAAHAyEi0AAAAAcDISLQAAAABwMhItAAAAAHAyEi0AAAAAcLIikWjNnj1bISEhcnNz02233ab//ve/hR0SAAAAAOTppk+0lixZolGjRmn8+PHasWOHWrdurc6dOyspKamwQwMAAACAXN30idaMGTP08MMP65FHHlGdOnUUGxurKlWqaM6cOYUdGgAAAADkyqWwA7iSCxcuaPv27Ro3bpxdeYcOHbRp06Zc98nIyFBGRoZtPTU1VZKUlpZWcIE64nxhB+BcN02/FkVcC5C4DvAXrgVIXAf4C9dCgciOwxhT4Me6qROtP/74Q5mZmfLz87Mr9/PzU3Jycq77REdHa9KkSTnKq1SpUiAx/tP5vOhT2CHgJsG1AInrAH/hWoDEdYC/3GzXwunTp+XjU7Ax3dSJVjaLxWK3bozJUZYtIiJCY8aMsa1nZWXpxIkTKl++fJ77FDdpaWmqUqWKjhw5otKlSxd2OChEXAuQuA7wF64FSFwH+Ms/8Vowxuj06dMKDAws8GPd1IlWhQoVVLJkyRyjVykpKTlGubJZrVZZrVa7sjJlyhRUiDe10qVL/2N+aHBlXAuQuA7wF64FSFwH+Ms/7Voo6JGsbDf1ZBilSpXSbbfdprVr19qVr127Vi1atCikqAAAAADgym7qES1JGjNmjAYMGKDGjRurefPmeuONN5SUlKTHHnussEMDAAAAgFzd9InWgw8+qOPHj2vy5Mk6duyY6tWrp08++URBQUGFHdpNy2q1auLEiTluocQ/D9cCJK4D/IVrARLXAf7CtVCwLOZGzG0IAAAAAP8gN/UzWgAAAABQFJFoAQAAAICTkWgBAAAAgJORaOGKIiMj1bBhQ9v6oEGD9MADDxRaPP8U9Lu9guiPjRs3ymKx6NSpU9fVDoDCd+jQIVksFu3cuVOS836+g4ODFRsbe93xFTV/f8+9kf7Jn3f0u3PcTO8HJFpOMmjQIFksFlksFrm4uKhq1aoaOnSoTp48aVfv3LlzKlu2rMqVK6dz587l2tYHH3ygO++8U2XLlpWHh4dq1aqlwYMHa8eOHfmKZf78+Xl+SbPFYtGKFSvyfV5jx47V559/nu/6Nxr97jwbNmzQPffco/Lly8vDw0NhYWF68skn9euvv97QOHLDdZj/6zAzM1PR0dGqXbu23N3dVa5cOTVr1kxxcXHXfZ7Odr0ffvT7tbnWfk9OTtaIESNUrVo1Wa1WValSRV27dr0pfjarVKlim5n4ZnEzXZ/z58+XxWJRnTp1cmx77733ZLFYFBwcbCtz5D23MJOD3NDvNwbvB/lDouVEnTp10rFjx3To0CG9+eab+uijjzRs2DC7Oh988IHq1aunsLAwLVu2LEcbzzzzjB588EE1bNhQK1eu1O7du/XGG2+oevXqevbZZ2/Uqdh4eXmpfPnyN/y4jqDfr99//vMf3X333fL399cHH3ygPXv26PXXX1dqaqqmT59+w+LIC9dh/q/DyMhIxcbG6oUXXtCePXu0YcMGPfroozl+ySgu6Pcb49ChQ7rtttu0fv16xcTE6Pvvv9fq1avVrl07DR8+vLDDU8mSJeXv7y8Xl5vrW2tulutTkjw9PZWSkqLNmzfblb/11luqWrWqXVlBvOdevHjRqe1dCf3+l4Lod94PHGDgFOHh4eb++++3KxszZowpV66cXVnbtm3N66+/bubMmWPatWtnt23z5s1GknnllVdyPUZWVla+YomLizM+Pj65bpNkli9fblt/+umnTWhoqHF3dzchISHmueeeMxcuXLBtnzhxornlllts638/z23btpmKFSuaKVOm5Nq+Mcb4+PiYuLi4fMXuKPr9+vv9yJEjplSpUmbUqFG5bj958qTt/0uXLjVhYWGmVKlSJigoyLz88st2dYOCgswLL7xgBgwYYDw9PU3VqlXNihUrTEpKirnvvvuMp6enqVevntm6dattn+x+W758uQkNDTVWq9XcfffdJikpKd/9kZWVZaZNm2ZCQkKMm5ubadCggXn//fftYlu1apUJDQ01bm5upm3btiYuLs5Isju/a3UzXYe33HKLiYyMvGKd8+fPmxEjRpiKFSsaq9VqWrZsab755hvb9g0bNhhJZt26dea2224z7u7upnnz5ubHH3+01cl+TRYuXGiCgoJM6dKlzYMPPmjS0tLsYs7rdUlMTDSS7Jbw8PB8nWM2+v3G9Xvnzp1NpUqVzJkzZ3Jsu/xn6PDhw7afdW9vb9OzZ0+TnJycI/558+aZKlWqGE9PT/PYY4+ZS5cumWnTphk/Pz+797Zskszs2bNNp06djJubmwkODjbvvfeebXv2ee3YscOuLy+P7auvvjKtW7c2bm5upnLlymbEiBF25/Pbb7+Ze++919b+okWLTFBQkJk5c+ZV+yc3N9P1mf0++/jjj5tHHnnEVn7kyBFjtVrNuHHjTFBQkK387++5GzZsME2aNDEeHh7Gx8fHtGjRwhw6dMj2Pnr5kv25I8nMmTPH3HfffcbDw8NMmDDBXLp0yQwePNgEBwcbNzc3U7NmTRMbG3vVfnME/V7w/c77Qf6RaDnJ3y/QgwcPmrCwMOPn52cr++mnn4zVajUnTpwwx48fN1ar1Rw8eNC2feTIkcbLy8tcvHjxumJx5Bf+F154wXz11VcmMTHRrFy50vj5+Zlp06bZtl/pF9wNGzYYHx8fM3v27DzbN+bGJlr0+1/y2+8zZswwkszRo0evWG/btm2mRIkSZvLkyWbfvn0mLi7OuLu72x0jKCjIlCtXzrz++utm//79ZujQocbb29t06tTJvPfee2bfvn3mgQceMHXq1LF9UMXFxRlXV1fTuHFjs2nTJrNt2zZz++23mxYtWuSrP4wx5tlnnzW1a9c2q1evNgcPHjRxcXHGarWajRs3GmOMSUpKMlar1TzxxBPmxx9/NIsWLTJ+fn4FlmgV5nXYsWNHc8cdd5iUlJQ864wcOdIEBgaaTz75xOzevduEh4ebsmXLmuPHjxtj/vpQatq0qdm4caPZvXu3ad26dY7XxMvLy3Tr1s18//335osvvjD+/v7m2WeftdW50uty6dIl88EHHxhJZt++febYsWPm1KlTDp0r/X5j+v348ePGYrGYqKioK9bLysoyjRo1Mq1atTLbtm0zW7ZsMbfeeqtp06ZNjvh79Ohhdu/ebVauXGlKlSplOnbsaEaMGGF+/PFH89ZbbxlJZvPmzbb9JJny5cubuXPnmn379pnnnnvOlCxZ0uzZs8cYc/VfrL777jvj5eVlZs6cafbv32+++uor06hRIzNo0CDbMTp37mzq1atnex9q0aKFcXd3d1qidTN8Pu3YscN4e3ubs2fPGmP+/Cy6//77zcyZM/P8hf/ixYvGx8fHjB071vz0009mz549Zv78+ebw4cMmPT3dPPnkk6Zu3brm2LFj5tixYyY9Pd0Y8+dr5uvra+bNm2cOHjxoDh06ZC5cuGAmTJhgvvnmG/Pzzz+bRYsWGQ8PD7NkyZI8+81R9HvB9jvvBzOv2keXI9FykvDwcFOyZEnj6elp3NzcbH9hmDFjhq3Os88+ax544AHb+v3332/Gjx9vW+/UqZNp0KCBXbvTp083np6etiU/v4hk/6Xj8v2yl9x+Ib9cTEyMue2222zref2Cu2LFCuPt7W3i4+Pt9i+MRIt+v75+Hzp0qClduvRV6/Xt29e0b9/eruypp54yYWFhtvWgoCDTv39/2/qxY8eMJPP888/byrL/Unjs2DFjzF/9tmXLFludvXv3Gknm66+/NsZcOdE6c+aMcXNzM5s2bbKL7eGHHzZ9+vQxxhgTERFhl9wZY8wzzzzj1ETrZrkOd+/eberUqWNKlChh6tevb4YMGWI++eQT2/YzZ84YV1dX884779jKLly4YAIDA01MTIwxxn5kJduqVauMJHPu3DljzJ+viYeHh91IylNPPWWaNm1qO87VXpfc/sroCPr9TwXd719//bWRZJYtW3bFemvWrDElS5a0G43evXu3kWQbucst/o4dO5rg4GCTmZlpK6tVq5aJjo62rUsyjz32mN3xmjZtaoYOHWqMufovVgMGDDD//ve/7fb/73//a0qUKGHOnTtn9u3bl+f70PUkWjfL9Xn5HwIbNmxoFixYYLKyskz16tXNhx9+eMVf+I8fP24k2f5w9Xd/f3/OJinPOyUuN2zYMNO9e3fbujMSLfq94Pqd94OZV+khezyj5UTt2rXTzp079fXXX2vEiBHq2LGjRowYIenPB6UXLFig/v372+r3799fCxYsUGZmpq3MYrHYtTl48GDt3LlT//nPf3T27Fn9eX1dnbe3t3bu3Jlj+bulS5eqVatW8vf3l5eXl55//nklJSVdse2vv/5a3bt314IFC9SnT598xVOQ6PfrY4zJcf652bt3r1q2bGlX1rJlSx04cMCuLxs0aGD7v5+fnySpfv36OcpSUlJsZS4uLmrcuLFtvXbt2ipTpoz27t171bj27Nmj8+fPq3379vLy8rItCxcu1MGDB22xN2vWzO48mzdvftW2HXGzXIdhYWH64YcftGXLFj300EP67bff1LVrVz3yyCOSpIMHD+rixYt2r6Wrq6tuv/32HP19+WsZEBAgyf51Cw4Olre3t12d7O35eV2cgX4v+H7PPv+rvU/s3btXVapUUZUqVWxlYWFhOX6W/x6/n5+fwsLCVKJECbuyy89Zyvkz27x583y9R0jS9u3bNX/+fLs+6dixo7KyspSYmKi9e/fm+T50PW6W6/Pv+8fFxSkhIUFnzpzRPffcc8X65cqV06BBg9SxY0d17dpVr7zyio4dO5avY13en9lef/11NW7cWBUrVpSXl5fmzp171c8/R9HvBdfvvB84hkTLiTw9PVWjRg01aNBAr776qjIyMjRp0iRJ0meffaZff/1VDz74oFxcXOTi4qLevXvrl19+0Zo1ayRJoaGhtg/jbGXKlFGNGjVUqVIlh2IpUaKEatSokWO53JYtW9S7d2917txZH3/8sXbs2KHx48frwoULV2y7evXqql27tt56660cdS0WS443n4J+AJZ+v75+r1mzplJTU6/6Bp5bQpbbB42rq6tdXHmVZWVl2e2X25t2fhLA7HZWrVpll9zu2bNHS5cuzTNOZ7vZrsMmTZpo9OjRWr58uebPn6958+YpMTExzw/J3F7fq71ul2/PrpO9PT+vizPQ7wXf76GhobJYLFf9JSavP9r8vTy3+K90TleSn/cI6c9+GTJkiF2f7Nq1SwcOHFD16tXz/cujo26m6zNbv379tGXLFkVGRmrgwIH5mjAgLi5OmzdvVosWLbRkyRLVrFlTW7Zsydf5X+69997T6NGjNXjwYK1Zs0Y7d+7UQw89dNXPP0fR7wXX77wfOIZEqwBNnDhRL7/8so4ePap58+apd+/eOUY6+vXrp3nz5kmS+vTpozNnzmj27Nk3JL6vvvpKQUFBGj9+vBo3bqzQ0FAdPnz4qvtVqFBB69ev18GDB/Xggw/avRFVrFjR7hf2AwcOKD09vUDizwv97li/9+jRQ6VKlVJMTEyu27OngA4LC9OXX35pt23Tpk2qWbOmSpYsma9j5eXSpUvatm2bbX3fvn06deqUateufdV9w8LCZLValZSUlCPBzf5LWlhYWI4Pp/x8WF2Pm+k6DAsLkySdPXtWNWrUUKlSpexey4sXL2rbtm25TkF8Pce82utSqlQpSbL7K/L1ot+d3+/lypVTx44d9X//9386e/Zsju2Xv0ckJSXpyJEjtm179uxRamqqU84xt5/h/LxHSNKtt96q3bt35/qHsFKlSqlOnTp5vg85081wfZYrV0733XefEhISNHjw4Hzv16hRI0VERGjTpk2qV6+e4uPjJf15PeX3Wvrvf/+rFi1aaNiwYWrUqJFq1Kjh1BHuvNDvzut33g8ccxPMe1h8tW3bVnXr1tXUqVP10UcfaeXKlTnm9A8PD1eXLl30+++/q3nz5nryySf15JNP6vDhw+rWrZvtuwDmzZsni8ViN5R6vWrUqKGkpCS9++67atKkiVatWqXly5fna19fX1+tX79e7dq1U58+ffTuu+/KxcVFd955p2bNmqVmzZopKytLzzzzTI6/TBQ0+t2xfq9SpYpmzpypxx9/XGlpaRo4cKCCg4P1yy+/aOHChfLy8tL06dP15JNPqkmTJnrhhRf04IMPavPmzZo1a5ZTPohcXV01YsQIvfrqq3J1ddXjjz+uZs2a6fbbb7/qvt7e3ho7dqxGjx6trKwstWrVSmlpadq0aZO8vLwUHh6uxx57TNOnT9eYMWM0ZMgQ220DBamwrsMePXqoZcuWatGihfz9/ZWYmKiIiAjVrFlTtWvXlouLi4YOHaqnnnpK5cqVU9WqVRUTE6P09HQ9/PDDTjv//LwuQUFBslgs+vjjj3XPPffI3d1dXl5e13Vc+r1g+n327Nlq0aKFbr/9dk2ePFkNGjTQpUuXtHbtWs2ZM0d79+7V3XffrQYNGqhfv36KjY3VpUuXNGzYMLVp0ybXW5kc9f7776tx48Zq1aqV3nnnHX3zzTe2X4yv5plnnlGzZs00fPhwPfroo/L09NTevXu1du1avfbaa6pVq5Y6deqkRx99VG+88YZcXFw0atQoubu7X3fcl7tZPp/mz5+v2bNn52sq8cTERL3xxhu67777FBgYqH379mn//v0aOHCgpD9v/UpMTNTOnTtVuXJleXt7y2q15tpWjRo1tHDhQn322WcKCQnR22+/ra1btyokJMThc3AE/e7cfuf9wAEOPdGFPOX1EOE777xjXFxcjCS76buzXbx40ZQrV85Mnz7dVrZkyRLTtm1b4+PjY1xdXU3lypVN37597R7KuxJHZr976qmnTPny5Y2Xl5d58MEHzcyZM+32vdpsb0ePHjU1a9Y0vXr1MpcuXTK//vqr6dChg/H09DShoaHmk08+ueHTuxtDv19Lv69du9Z07NjRlC1b1ri5uZnatWubsWPH2s1GmD29u6urq6latap56aWX7NrIberTv5/73x9Sze63Dz74wFSrVs2UKlXK3HnnnebQoUP57o+srCzzyiuvmFq1ahlXV1dTsWJF07FjR5OQkGCr89FHH5kaNWoYq9VqWrdubZvJqKCmdzemcK7DN954w7Rr185UrFjRlCpVylStWtUMGjTIrj/PnTtnRowYYSpUqHDFacYv75sdO3YYSSYxMdEYk/uD2H9/sDs/r8vkyZONv7+/sVgsTpne3Rj6vaD6/ejRo2b48OEmKCjIlCpVylSqVMncd999ZsOGDbY6+Z3O+XK5vY5t2rQxTzzxhG1dkvm///s/0759e2O1Wk1QUJBZvHixbXt+pnP+5ptvTPv27Y2Xl5fx9PQ0DRo0MFOnTrVtP3bsmOnSpYuxWq2matWqtin0nTm9uzE33+eTMTmvoctfp+TkZPPAAw+YgIAA21d7TJgwwTZZwfnz50337t1NmTJlckwz/vdJms6fP28GDRpkfHx8TJkyZczQoUPNuHHjrvj+7ij6/cb0O+8H+WP5X8AAUCjmz5+vUaNGOf0WHQDFh8Vi0fLly/XAAw8UdigACllRej/gGS0AAAAAcDISrSKobt26dlNSXr688847hR1esVVU+z0qKirPuDt37lzY4cFBRfU6LOqKc78nJSXleW5eXl5On3obzlecr8+bWXHsd94PnItbB4ugw4cP5zl1t5+fn933EcB5imq/nzhxQidOnMh1m7u7+zVPVYvCUVSvw6KuOPf7pUuXdOjQoTy3BwcH52sqahSe4nx93syKY7/zfuBcJFoAAAAA4GTcOggAAAAATkaiBQAAAABORqIFAAAAAE5GogUAAAAATkaiBQAAAABORqIFAAAAAE5GogUAAAAATkaiBQAAAABO9v92/7Fcfsd6xwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_type = ['RAG_Haiku','RAG_Haiku_Compiled','RAG_Sonnet','RAG_Sonnet_Compiled','RAG_Mistral','RAG_Mistral_Compiled']\n",
    "class_count = [raw_scores[0],compiled_scores[0],raw_scores[1],compiled_scores[1],raw_scores[2],compiled_scores[2]]\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "\n",
    "# creating the bar plot\n",
    "plt.bar(class_type, class_count, color ='green', width = 0.4)\n",
    "\n",
    "for i in range(len(class_type)):\n",
    "        plt.text(i,class_count[i],class_count[i], ha = 'center')\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"RAG Accuracy performance \")\n",
    "plt.title(\"RAG performance across models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e208c-06f3-4f46-a4ac-bcce66cc2af7",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
