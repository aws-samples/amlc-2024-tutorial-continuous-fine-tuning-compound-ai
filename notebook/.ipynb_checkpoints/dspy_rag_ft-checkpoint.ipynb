{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb3e157e",
   "metadata": {},
   "source": [
    "# Fine-tuned model and evaluation in dspy\n",
    "\n",
    "In this notebook, we use DSPy Evaluate module to benchmark results from standard RAG, RAG compiled with prompt automation, and fine-tuned LLM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ecaec9-7ea9-4267-bdc7-009f7f7c41c1",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d452ee1a",
   "metadata": {},
   "source": [
    "Uncomment the following lines if the packages are not installed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dc0ed97-09fe-4601-ab64-a0ef356021cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install langchain\n",
    "!pip3 install -U langchain-community\n",
    "!pip3 install pypdf\n",
    "!pip3 install chromadb\n",
    "!pip3 install dspy-ai[faiss-cpu]\n",
    "!pip3 install sentence_transformers\n",
    "!pip3 install continuous_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a20d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dspy\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json, os, shutil\n",
    "import boto3, re, os, shutil\n",
    "import sentence_transformers, continuous_eval\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d7251d2-0678-4fbf-8aef-5aadf93b0722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "boto_session = boto3.session.Session()\n",
    "region_name = boto_session.region_name\n",
    "print(region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a3539",
   "metadata": {},
   "source": [
    "### RAG generator model fine-tuned by SFT, DPO and ORPO    \n",
    "   \n",
    "DSPy does not yet support LLM fine-tuning through Instruction Tuning, Reinforcement Learning and Preference Alignment. Therefore, we conducted the llama 3 8B model fine-tuning separately, and generated the following results for benchmarking across multiple methods using the same dataset for the RAG inference in the notebook dapy_rag_compile.ipynb. \n",
    "\n",
    "If you are interested in how to fine-tune LLM using those methodologies, please refer to the code samples [here]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a00e8",
   "metadata": {},
   "source": [
    "SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2caf99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ref_answer</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is The name of the contract?</td>\n",
       "      <td>STRATEGIC ALLIANCE AGREEMENT</td>\n",
       "      <td>STRATEGIC ALLIANCE AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is The two or more parties who signed the...</td>\n",
       "      <td>Dialog Semiconductor (UK) Ltd., DIALOG, Energo...</td>\n",
       "      <td>DIALOG SEMICONDUCTOR (PENANG) SDN BHD, DIALOG ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is The date of the contract?</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>October 1, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is The date when the contract is effective?</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>November 6, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On what date will the contract's initial term ...</td>\n",
       "      <td>Unless earlier terminated as provided herein, ...</td>\n",
       "      <td>Unless earlier terminated as provided herein, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                  What is The name of the contract?   \n",
       "1  What is The two or more parties who signed the...   \n",
       "2                  What is The date of the contract?   \n",
       "3   What is The date when the contract is effective?   \n",
       "4  On what date will the contract's initial term ...   \n",
       "\n",
       "                                          ref_answer  \\\n",
       "0                       STRATEGIC ALLIANCE AGREEMENT   \n",
       "1  Dialog Semiconductor (UK) Ltd., DIALOG, Energo...   \n",
       "2                                   November 6, 2016   \n",
       "3                                   November 6, 2016   \n",
       "4  Unless earlier terminated as provided herein, ...   \n",
       "\n",
       "                                            response  \n",
       "0                       STRATEGIC ALLIANCE AGREEMENT  \n",
       "1  DIALOG SEMICONDUCTOR (PENANG) SDN BHD, DIALOG ...  \n",
       "2                                    October 1, 2016  \n",
       "3                                   November 6, 2016  \n",
       "4  Unless earlier terminated as provided herein, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SFT_RESULTS = 'sft_trn_full_result.csv'\n",
    "df_sft_data = pd.read_csv(SFT_RESULTS)\n",
    "df_sft_data[:][[\"question\", \"ref_answer\", \"response\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f6138f",
   "metadata": {},
   "source": [
    "DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a83b631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ref_answer</th>\n",
       "      <th>response</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>token_overlap_recall</th>\n",
       "      <th>rouge_l_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is The name of the contract?</td>\n",
       "      <td>STRATEGIC ALLIANCE AGREEMENT</td>\n",
       "      <td>STRATEGIC ALLIANCE AGREEMENT</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is The two or more parties who signed the...</td>\n",
       "      <td>Dialog Semiconductor (UK) Ltd., DIALOG, Energo...</td>\n",
       "      <td>Dialog Semiconductor (UK) Ltd., DIALOG, Energo...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is The date of the contract?</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>2016, October 1</td>\n",
       "      <td>0.267889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is The date when the contract is effective?</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>May 6, 2016</td>\n",
       "      <td>0.306074</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On what date will the contract's initial term ...</td>\n",
       "      <td>Unless earlier terminated as provided herein, ...</td>\n",
       "      <td>7 years after the Effective Date, and thereaft...</td>\n",
       "      <td>0.629246</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.370370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                  What is The name of the contract?   \n",
       "1  What is The two or more parties who signed the...   \n",
       "2                  What is The date of the contract?   \n",
       "3   What is The date when the contract is effective?   \n",
       "4  On what date will the contract's initial term ...   \n",
       "\n",
       "                                          ref_answer  \\\n",
       "0                       STRATEGIC ALLIANCE AGREEMENT   \n",
       "1  Dialog Semiconductor (UK) Ltd., DIALOG, Energo...   \n",
       "2                                   November 6, 2016   \n",
       "3                                   November 6, 2016   \n",
       "4  Unless earlier terminated as provided herein, ...   \n",
       "\n",
       "                                            response  semantic_similarity  \\\n",
       "0                       STRATEGIC ALLIANCE AGREEMENT             1.000000   \n",
       "1  Dialog Semiconductor (UK) Ltd., DIALOG, Energo...             1.000000   \n",
       "2                                    2016, October 1             0.267889   \n",
       "3                                        May 6, 2016             0.306074   \n",
       "4  7 years after the Effective Date, and thereaft...             0.629246   \n",
       "\n",
       "   token_overlap_recall  rouge_l_recall  \n",
       "0              1.000000        1.000000  \n",
       "1              0.750000        1.000000  \n",
       "2              0.333333        0.000000  \n",
       "3              0.666667        0.666667  \n",
       "4              0.450000        0.370370  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DPO_RESULTS = 'dpo_trn_full_result.csv'\n",
    "df_dpo_data = pd.read_csv(DPO_RESULTS)\n",
    "df_dpo_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148827ed",
   "metadata": {},
   "source": [
    "ORPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a650ac78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ref_answer</th>\n",
       "      <th>response</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>token_overlap_recall</th>\n",
       "      <th>rouge_l_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is The name of the contract?</td>\n",
       "      <td>STRATEGIC ALLIANCE AGREEMENT</td>\n",
       "      <td>STRATEGIC ALLIANCE AGREEMENT</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is The two or more parties who signed the...</td>\n",
       "      <td>Dialog Semiconductor (UK) Ltd., DIALOG, Energo...</td>\n",
       "      <td>Dialog Semiconductor (UK) Ltd., DIALOG, Energo...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is The date of the contract?</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>2016, October 1</td>\n",
       "      <td>0.267889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is The date when the contract is effective?</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>May 6, 2016</td>\n",
       "      <td>0.306074</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On what date will the contract's initial term ...</td>\n",
       "      <td>Unless earlier terminated as provided herein, ...</td>\n",
       "      <td>7 years after the Effective Date, and thereaft...</td>\n",
       "      <td>0.629246</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.370370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                  What is The name of the contract?   \n",
       "1  What is The two or more parties who signed the...   \n",
       "2                  What is The date of the contract?   \n",
       "3   What is The date when the contract is effective?   \n",
       "4  On what date will the contract's initial term ...   \n",
       "\n",
       "                                          ref_answer  \\\n",
       "0                       STRATEGIC ALLIANCE AGREEMENT   \n",
       "1  Dialog Semiconductor (UK) Ltd., DIALOG, Energo...   \n",
       "2                                   November 6, 2016   \n",
       "3                                   November 6, 2016   \n",
       "4  Unless earlier terminated as provided herein, ...   \n",
       "\n",
       "                                            response  semantic_similarity  \\\n",
       "0                       STRATEGIC ALLIANCE AGREEMENT             1.000000   \n",
       "1  Dialog Semiconductor (UK) Ltd., DIALOG, Energo...             1.000000   \n",
       "2                                    2016, October 1             0.267889   \n",
       "3                                        May 6, 2016             0.306074   \n",
       "4  7 years after the Effective Date, and thereaft...             0.629246   \n",
       "\n",
       "   token_overlap_recall  rouge_l_recall  \n",
       "0              1.000000        1.000000  \n",
       "1              0.750000        1.000000  \n",
       "2              0.333333        0.000000  \n",
       "3              0.666667        0.666667  \n",
       "4              0.450000        0.370370  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ORPO_RESULTS = 'orpo_trn_full_result.csv'\n",
    "df_orpo_data = pd.read_csv(ORPO_RESULTS)\n",
    "df_orpo_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af185395",
   "metadata": {},
   "source": [
    "### RAG generator model by foundation models on Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9297c4bb",
   "metadata": {},
   "source": [
    "RAG with Claude Haiku for generator model (generated from the notebook dspy_rag_compile.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89b826ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ref_answer</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is The name of the contract?</td>\n",
       "      <td>STRATEGIC ALLIANCE AGREEMENT</td>\n",
       "      <td>The name of the contract is not provided in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is The two or more parties who signed the...</td>\n",
       "      <td>Dialog Semiconductor (UK) Ltd., DIALOG, Energo...</td>\n",
       "      <td>The two parties who signed the contract are En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is The date of the contract?</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>The date of the contract is not explicitly sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is The date when the contract is effective?</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>The Effective Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On what date will the contract's initial term ...</td>\n",
       "      <td>Unless earlier terminated as provided herein, ...</td>\n",
       "      <td>7 years</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                  What is The name of the contract?   \n",
       "1  What is The two or more parties who signed the...   \n",
       "2                  What is The date of the contract?   \n",
       "3   What is The date when the contract is effective?   \n",
       "4  On what date will the contract's initial term ...   \n",
       "\n",
       "                                          ref_answer  \\\n",
       "0                       STRATEGIC ALLIANCE AGREEMENT   \n",
       "1  Dialog Semiconductor (UK) Ltd., DIALOG, Energo...   \n",
       "2                                   November 6, 2016   \n",
       "3                                   November 6, 2016   \n",
       "4  Unless earlier terminated as provided herein, ...   \n",
       "\n",
       "                                            response  \n",
       "0  The name of the contract is not provided in th...  \n",
       "1  The two parties who signed the contract are En...  \n",
       "2  The date of the contract is not explicitly sta...  \n",
       "3                                 The Effective Date  \n",
       "4                                            7 years  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAG_HAIKU_RESULTS = 'rag_haiku_results_2.csv'\n",
    "df_rag_haiku_data = pd.read_csv(RAG_HAIKU_RESULTS)\n",
    "df_rag_haiku_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318193ed",
   "metadata": {},
   "source": [
    "RAG with Claude 3 Haiku for generator model, optimize by DSPy (generated from the notebook dspy_rag_compile.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ce27f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ref_answer</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is The name of the contract?</td>\n",
       "      <td>STRATEGIC ALLIANCE AGREEMENT</td>\n",
       "      <td>The context does not explicitly state the name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is The two or more parties who signed the...</td>\n",
       "      <td>Dialog Semiconductor (UK) Ltd., DIALOG, Energo...</td>\n",
       "      <td>The two parties who signed the contract are:\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is The date of the contract?</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>The effective date of the contract is November...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is The date when the contract is effective?</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>The effective date of the contract is November...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On what date will the contract's initial term ...</td>\n",
       "      <td>Unless earlier terminated as provided herein, ...</td>\n",
       "      <td>The initial term of the contract will expire 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                  What is The name of the contract?   \n",
       "1  What is The two or more parties who signed the...   \n",
       "2                  What is The date of the contract?   \n",
       "3   What is The date when the contract is effective?   \n",
       "4  On what date will the contract's initial term ...   \n",
       "\n",
       "                                          ref_answer  \\\n",
       "0                       STRATEGIC ALLIANCE AGREEMENT   \n",
       "1  Dialog Semiconductor (UK) Ltd., DIALOG, Energo...   \n",
       "2                                   November 6, 2016   \n",
       "3                                   November 6, 2016   \n",
       "4  Unless earlier terminated as provided herein, ...   \n",
       "\n",
       "                                            response  \n",
       "0  The context does not explicitly state the name...  \n",
       "1  The two parties who signed the contract are:\\n...  \n",
       "2  The effective date of the contract is November...  \n",
       "3  The effective date of the contract is November...  \n",
       "4  The initial term of the contract will expire 7...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAG_HAIKU_COMPILED_RESULTS = 'ragc_haiku_results_2.csv'\n",
    "df_ragc_haiku_data = pd.read_csv(RAG_HAIKU_COMPILED_RESULTS)\n",
    "df_ragc_haiku_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237ac589",
   "metadata": {},
   "source": [
    "RAG with Claude 3 Sonnet for generator model (generated from the notebook dspy_rag_compile.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "880ee83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ref_answer</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is The name of the contract?</td>\n",
       "      <td>STRATEGIC ALLIANCE AGREEMENT</td>\n",
       "      <td>This appears to be an agreement between Energo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is The two or more parties who signed the...</td>\n",
       "      <td>Dialog Semiconductor (UK) Ltd., DIALOG, Energo...</td>\n",
       "      <td>Energous Corporation, Dialog Semiconductor (UK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is The date of the contract?</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>The exact date of the contract is not provided...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is The date when the contract is effective?</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>The Effective Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On what date will the contract's initial term ...</td>\n",
       "      <td>Unless earlier terminated as provided herein, ...</td>\n",
       "      <td>7 years</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                  What is The name of the contract?   \n",
       "1  What is The two or more parties who signed the...   \n",
       "2                  What is The date of the contract?   \n",
       "3   What is The date when the contract is effective?   \n",
       "4  On what date will the contract's initial term ...   \n",
       "\n",
       "                                          ref_answer  \\\n",
       "0                       STRATEGIC ALLIANCE AGREEMENT   \n",
       "1  Dialog Semiconductor (UK) Ltd., DIALOG, Energo...   \n",
       "2                                   November 6, 2016   \n",
       "3                                   November 6, 2016   \n",
       "4  Unless earlier terminated as provided herein, ...   \n",
       "\n",
       "                                            response  \n",
       "0  This appears to be an agreement between Energo...  \n",
       "1  Energous Corporation, Dialog Semiconductor (UK...  \n",
       "2  The exact date of the contract is not provided...  \n",
       "3                                 The Effective Date  \n",
       "4                                            7 years  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAG_SONNET_RESULTS = 'rag_sonnet_results_2.csv'\n",
    "df_rag_sonnet_data = pd.read_csv(RAG_SONNET_RESULTS)\n",
    "df_rag_sonnet_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9323a332",
   "metadata": {},
   "source": [
    "RAG with Claude 3 Sonnet for generator model, optimize by DSPy (generated from the notebook dspy_rag_compile.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af4556d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ref_answer</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is The name of the contract?</td>\n",
       "      <td>STRATEGIC ALLIANCE AGREEMENT</td>\n",
       "      <td>Unfortunately, the name or title of the contra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is The two or more parties who signed the...</td>\n",
       "      <td>Dialog Semiconductor (UK) Ltd., DIALOG, Energo...</td>\n",
       "      <td>The two parties who signed the contract are:\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is The date of the contract?</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>Unfortunately, the specific date of the contra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is The date when the contract is effective?</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>Unfortunately, the effective date of the contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On what date will the contract's initial term ...</td>\n",
       "      <td>Unless earlier terminated as provided herein, ...</td>\n",
       "      <td>The contract does not explicitly state the sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                  What is The name of the contract?   \n",
       "1  What is The two or more parties who signed the...   \n",
       "2                  What is The date of the contract?   \n",
       "3   What is The date when the contract is effective?   \n",
       "4  On what date will the contract's initial term ...   \n",
       "\n",
       "                                          ref_answer  \\\n",
       "0                       STRATEGIC ALLIANCE AGREEMENT   \n",
       "1  Dialog Semiconductor (UK) Ltd., DIALOG, Energo...   \n",
       "2                                   November 6, 2016   \n",
       "3                                   November 6, 2016   \n",
       "4  Unless earlier terminated as provided herein, ...   \n",
       "\n",
       "                                            response  \n",
       "0  Unfortunately, the name or title of the contra...  \n",
       "1  The two parties who signed the contract are:\\n...  \n",
       "2  Unfortunately, the specific date of the contra...  \n",
       "3  Unfortunately, the effective date of the contr...  \n",
       "4  The contract does not explicitly state the sta...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAG_SONNET_COMPILED_RESULTS = 'ragc_sonnet_results_2.csv'\n",
    "df_ragc_sonnet_data = pd.read_csv(RAG_SONNET_COMPILED_RESULTS)\n",
    "df_ragc_sonnet_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9823156f",
   "metadata": {},
   "source": [
    "### Evaluation method 1: LLM-as-a-judge with True/False as score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6055310",
   "metadata": {},
   "source": [
    "Setup Claude and Meta models on Bedrock for LLM-as-a-judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c00e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp_bedrock = dspy.Bedrock(region_name=region_name)\n",
    "\n",
    "claude_sonnet_model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "clade_haiku_model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "llama_model_id = \"us.meta.llama3-2-90b-instruct-v1:0\"\n",
    "\n",
    "bedrock_sonnet = dspy.AWSAnthropic(aws_provider=dsp_bedrock,\n",
    "                                  model=claude_sonnet_model_id,\n",
    "                                  max_new_tokens=4096,\n",
    "                                  max_tokens=4096)\n",
    "\n",
    "bedrock_haiku = dspy.AWSAnthropic(aws_provider=dsp_bedrock,\n",
    "                                 model=clade_haiku_model_id,\n",
    "                                 max_new_tokens=4096,\n",
    "                                 max_tokens=4096)\n",
    "\n",
    "bedrock_llama = dspy.AWSMeta(aws_provider=dsp_bedrock, \n",
    "                             model=llama_model_id, \n",
    "                             max_new_tokens=2048,\n",
    "                             max_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a15d2962",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(lm=bedrock_sonnet, temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf51e80-b959-4f50-afb2-be015203db56",
   "metadata": {},
   "source": [
    "Define the LLM judge class: eval = True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c66cde85-90bd-460d-83d4-948e784241ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FactualityJudge_0(dspy.Signature):\n",
    "    \"\"\"Judge if the predicted answer is factually correct and similar to the groundtruth answer. Only provide 'True' or 'False' in the response.\"\"\"\n",
    "\n",
    "    groundtruth_answer = dspy.InputField(desc=\"groundtruth answer\", format=str)\n",
    "    predicted_answer = dspy.InputField(desc=\"predicted answer\", format=str)\n",
    "    factually_correct = dspy.OutputField(desc=\"Is the predicted answer factually correct and semantically similar to the groundtruth answer?\", format=str) #, prefix=\"Factual[True/False]:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27bd330c-3dca-466a-a36f-156dbd596c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "factualityJudge_0 = dspy.ChainOfThought(FactualityJudge_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0059ef73-7255-4385-a3fb-6e067801dce2",
   "metadata": {},
   "source": [
    "Define the factuality metric for DSPy evaluate to run through LLM response/answer, and use LLM judge to generate evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f43b823e-fda3-46aa-bee0-61d1703a46d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def factuality_metric_0(gt_answer, pred_answer):\n",
    "    #print(f\" type(gt_answer) :: {type(gt_answer)}\")\n",
    "    pred_answer = gt_answer.pred_answer\n",
    "    gt_answer = gt_answer.gt_answer\n",
    "        \n",
    "        \n",
    "    factual_metrc = factualityJudge_0(groundtruth_answer=gt_answer, predicted_answer=pred_answer), \n",
    "    '''\n",
    "    #debug\n",
    "    print(f\"\\n factual LLM judge  >>>>>>>> {factual_metrc}\")\n",
    "    print(f\"\\n factual LLM judge  >>>>>>>> {factual_metrc[0].factually_correct}\")\n",
    "    print(f\"\\n gt_answer  >>>>>>>  {gt_answer}\")\n",
    "    print(f\"\\n pred_answer  >>>>>>> {pred_answer}\")\n",
    "    '''\n",
    "    llm_judge_ans = bool(\"Factual[True]\" in factual_metrc[0].factually_correct or factual_metrc[0].factually_correct=='True') #or \"correct\" in factual.factually_correct.lower()\n",
    "    print(f\"llm_judge_ans = {llm_judge_ans}\")\n",
    "    return llm_judge_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e7bc537-deb9-4241-8e7a-26ed43a56255",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_LLM_0 = factuality_metric_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e51145-bb7b-45a7-b380-b25a2142ea13",
   "metadata": {},
   "source": [
    "LLM Judge class to generate the answer and factual consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88774a1b-4b63-4a67-8f53-eac416b31b66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LLMJudge_0(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.ChainOfThought(FactualityJudge_0)\n",
    "    \n",
    "    def forward(self, gt_answer, pred_answer):\n",
    "        '''\n",
    "        print(f\"LLMJudge_0 gt_answer ----- {gt_answer}\")\n",
    "        print(f\"LLMJudge_0 pred_answer ----- {pred_answer}\")\n",
    "        '''\n",
    "        factual = self.generate_answer(groundtruth_answer=gt_answer, predicted_answer=pred_answer)\n",
    "        #gprint(f\"LLMJudge_0 factual ----- {factual}\")\n",
    "        #llm_judge_ans = factual.factually_correct\n",
    "        \n",
    "        llm_judge_ans = bool(\"Factual[True]\" in factual.factually_correct \n",
    "                         or '100% True' in factual.factually_correct\n",
    "                         or '100% factually correct' in factual.factually_correct\n",
    "                         or 'True' in factual.factually_correct    \n",
    "                         or factual.factually_correct=='True') #or \"correct\" in factual.factually_correct.lower()\n",
    "        return llm_judge_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11f03a93-17b2-4f1b-8c4b-0cd8700adbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_judge_0 = LLMJudge_0()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fef38f6",
   "metadata": {},
   "source": [
    "Convert dataset into dspy format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5f40fce-3c99-43f8-aad8-2f2346dca023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dspy_example_dataset(df):\n",
    "    dataset_dspy_data = []\n",
    "\n",
    "    for question, gt_answer, pred_answer in df[:][[\"question\", \"ref_answer\", \"response\"]].values:\n",
    "        '''\n",
    "        print(f\"question >>>>>>> {question}\")\n",
    "        print(f\"gt_answer >>>>>>> {gt_answer}\")\n",
    "        print(f\"pred_answer >>>>>>> {pred_answer}\")\n",
    "        '''\n",
    "        dataset_dspy_data.append(dspy.Example(gt_answer=gt_answer, pred_answer=pred_answer).with_inputs(\"gt_answer\", \"pred_answer\"))\n",
    "\n",
    "    return dataset_dspy_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ae6e9a",
   "metadata": {},
   "source": [
    "Batch evaluation using LLM-Judge class for dataset in dataframe format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5c8f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_judge_scores_0(test_data):\n",
    "    scores = []\n",
    "\n",
    "    for index, row in test_data.iterrows():\n",
    "        #print(\"=== \",index,\" ===\")\n",
    "        #print(f\"---------------\")\n",
    "        #print(f\"row['ref_answer'] >>>  {row['ref_answer']}\")\n",
    "        #print(f\"row['response'] {row['response']}\")\n",
    "        llm_judge_ans = float(llm_judge_0(row['ref_answer'], row['response']))\n",
    "        #print(f\"llm_judge_ans :: {llm_judge_ans}\")\n",
    "        scores.append(llm_judge_ans)\n",
    "        print(index,':',llm_judge_ans, end='|')\n",
    "\n",
    "    accuracy_score = (sum(bool(score) for score in scores))/len(scores)\n",
    "    \n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6094ae6d-0f35-4556-8285-b400d7530cc9",
   "metadata": {},
   "source": [
    "#### LLM judge metrics by dspy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136a2d1e-ee91-4aec-8b42-9bfc17d53f2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Evaluation scores for SFT results by LLM-judge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6efc3d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated, underperform, and are about to be deleted. ***\n",
      " \t\tYou are using the client AWSAnthropic, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 1.0|1 : 0.0|2 : 0.0|3 : 1.0|4 : 1.0|5 : 1.0|6 : 1.0|7 : 1.0|8 : 0.0|9 : 0.0|10 : 0.0|11 : 0.0|12 : 0.0|13 : 0.0|14 : 0.0|15 : 0.0|16 : 1.0|17 : 0.0|18 : 0.0|19 : 0.0|20 : 1.0|21 : 0.0|22 : 1.0|23 : 0.0|24 : 1.0|25 : 0.0|26 : 0.0|27 : 0.0|28 : 1.0|29 : 0.0|30 : 0.0|31 : 0.0|"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34375"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_score_0 = get_judge_scores_0(df_sft_data)\n",
    "sft_score_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96246d4d",
   "metadata": {},
   "source": [
    "Evaluation scores for SFT results by dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d25d88a9-53d5-469e-8c5d-9a6834e2cdcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = True\n",
      "Average Metric: 1.00 / 32 (3.1%):   3%|▎         | 1/32 [00:01<00:47,  1.54s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):   6%|▋         | 2/32 [00:06<01:41,  3.37s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):   9%|▉         | 3/32 [00:07<01:08,  2.36s/it]llm_judge_ans = True\n",
      "Average Metric: 2.00 / 32 (6.2%):  12%|█▎        | 4/32 [00:10<01:12,  2.57s/it]llm_judge_ans = True\n",
      "Average Metric: 3.00 / 32 (9.4%):  16%|█▌        | 5/32 [00:12<01:07,  2.51s/it]llm_judge_ans = True\n",
      "Average Metric: 4.00 / 32 (12.5%):  19%|█▉        | 6/32 [00:14<00:55,  2.15s/it]llm_judge_ans = True\n",
      "Average Metric: 5.00 / 32 (15.6%):  22%|██▏       | 7/32 [00:15<00:50,  2.03s/it]llm_judge_ans = True\n",
      "Average Metric: 6.00 / 32 (18.8%):  25%|██▌       | 8/32 [00:17<00:47,  2.00s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  28%|██▊       | 9/32 [00:19<00:45,  2.00s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  31%|███▏      | 10/32 [00:24<01:00,  2.73s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  34%|███▍      | 11/32 [00:26<00:51,  2.47s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  38%|███▊      | 12/32 [00:28<00:46,  2.33s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  41%|████      | 13/32 [00:30<00:44,  2.32s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  44%|████▍     | 14/32 [00:31<00:37,  2.07s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  47%|████▋     | 15/32 [00:35<00:41,  2.47s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  50%|█████     | 16/32 [00:37<00:39,  2.49s/it]llm_judge_ans = True\n",
      "Average Metric: 7.00 / 32 (21.9%):  53%|█████▎    | 17/32 [00:39<00:34,  2.27s/it]llm_judge_ans = False\n",
      "Average Metric: 7.00 / 32 (21.9%):  56%|█████▋    | 18/32 [00:41<00:29,  2.10s/it]llm_judge_ans = False\n",
      "Average Metric: 7.00 / 32 (21.9%):  59%|█████▉    | 19/32 [00:43<00:26,  2.03s/it]llm_judge_ans = False\n",
      "Average Metric: 7.00 / 32 (21.9%):  62%|██████▎   | 20/32 [00:45<00:24,  2.05s/it]llm_judge_ans = True\n",
      "Average Metric: 8.00 / 32 (25.0%):  66%|██████▌   | 21/32 [00:47<00:24,  2.26s/it]llm_judge_ans = False\n",
      "Average Metric: 8.00 / 32 (25.0%):  69%|██████▉   | 22/32 [00:50<00:24,  2.48s/it]llm_judge_ans = True\n",
      "Average Metric: 9.00 / 32 (28.1%):  72%|███████▏  | 23/32 [00:53<00:22,  2.45s/it]llm_judge_ans = False\n",
      "Average Metric: 9.00 / 32 (28.1%):  75%|███████▌  | 24/32 [00:55<00:20,  2.52s/it]llm_judge_ans = True\n",
      "Average Metric: 10.00 / 32 (31.2%):  78%|███████▊  | 25/32 [00:57<00:16,  2.30s/it]llm_judge_ans = False\n",
      "Average Metric: 10.00 / 32 (31.2%):  81%|████████▏ | 26/32 [01:00<00:14,  2.35s/it]llm_judge_ans = False\n",
      "Average Metric: 10.00 / 32 (31.2%):  84%|████████▍ | 27/32 [01:06<00:18,  3.62s/it]llm_judge_ans = False\n",
      "Average Metric: 10.00 / 32 (31.2%):  88%|████████▊ | 28/32 [01:08<00:12,  3.12s/it]llm_judge_ans = True\n",
      "Average Metric: 11.00 / 32 (34.4%):  91%|█████████ | 29/32 [01:10<00:08,  2.75s/it]llm_judge_ans = False\n",
      "Average Metric: 11.00 / 32 (34.4%):  94%|█████████▍| 30/32 [01:15<00:07,  3.51s/it]llm_judge_ans = False\n",
      "Average Metric: 11.00 / 32 (34.4%):  97%|█████████▋| 31/32 [01:18<00:03,  3.23s/it]llm_judge_ans = False\n",
      "Average Metric: 11.00 / 32 (34.4%): 100%|██████████| 32/32 [01:21<00:00,  2.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 02:38:47 INFO dspy.evaluate.evaluate: Average Metric: 11 / 32 (34.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Final DSPy Evaluation score :::: 34.38 ---------\n"
     ]
    }
   ],
   "source": [
    "evaluate_llm_judge = Evaluate(devset=generate_dspy_example_dataset(df_sft_data), \n",
    "                              metric=metric_LLM_0, \n",
    "                              num_threads=1, \n",
    "                              display_progress=True, \n",
    "                              display_table=0, \n",
    "                              provide_traceback=True)\n",
    "\n",
    "eval_score = evaluate_llm_judge(llm_judge_0, num_threads=1)\n",
    "print(f\"------------- Final DSPy Evaluation score :::: {eval_score} ---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2340ce59-1d4f-4797-a63a-bc76dc083a05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34380000000000005"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_score_0 = eval_score/100\n",
    "sft_score_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de846386-639b-4c5e-b4a2-ebea89261477",
   "metadata": {},
   "source": [
    "Evaluation scores for DPO results by LLM-judge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63c23f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 1.0|1 : 1.0|2 : 0.0|3 : 0.0|4 : 1.0|5 : 1.0|6 : 0.0|7 : 1.0|8 : 0.0|9 : 0.0|10 : 1.0|11 : 1.0|12 : 1.0|13 : 0.0|14 : 1.0|15 : 1.0|16 : 1.0|17 : 0.0|18 : 0.0|19 : 0.0|20 : 1.0|21 : 0.0|22 : 1.0|23 : 1.0|24 : 1.0|25 : 0.0|26 : 0.0|27 : 0.0|28 : 1.0|29 : 1.0|30 : 1.0|31 : 1.0|"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.59375"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_score_0 = get_judge_scores_0(df_dpo_data)\n",
    "dpo_score_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f727bc",
   "metadata": {},
   "source": [
    "Evaluation scores for DPO results by dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c6ecbd6-7dc4-4e83-9b0b-b9487de60763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = True\n",
      "Average Metric: 1.00 / 32 (3.1%):   3%|▎         | 1/32 [00:02<01:04,  2.07s/it]llm_judge_ans = True\n",
      "Average Metric: 2.00 / 32 (6.2%):   6%|▋         | 2/32 [00:03<00:48,  1.62s/it]llm_judge_ans = False\n",
      "Average Metric: 2.00 / 32 (6.2%):   9%|▉         | 3/32 [00:04<00:45,  1.59s/it]llm_judge_ans = False\n",
      "Average Metric: 2.00 / 32 (6.2%):  12%|█▎        | 4/32 [00:06<00:47,  1.70s/it]llm_judge_ans = True\n",
      "Average Metric: 3.00 / 32 (9.4%):  16%|█▌        | 5/32 [00:09<00:53,  1.98s/it]llm_judge_ans = True\n",
      "Average Metric: 4.00 / 32 (12.5%):  19%|█▉        | 6/32 [00:10<00:47,  1.82s/it]llm_judge_ans = False\n",
      "Average Metric: 4.00 / 32 (12.5%):  22%|██▏       | 7/32 [00:14<01:03,  2.56s/it]llm_judge_ans = True\n",
      "Average Metric: 5.00 / 32 (15.6%):  25%|██▌       | 8/32 [00:17<00:59,  2.49s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%):  28%|██▊       | 9/32 [00:19<00:53,  2.34s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%):  31%|███▏      | 10/32 [00:21<00:54,  2.46s/it]llm_judge_ans = True\n",
      "Average Metric: 6.00 / 32 (18.8%):  34%|███▍      | 11/32 [00:23<00:47,  2.28s/it]llm_judge_ans = True\n",
      "Average Metric: 7.00 / 32 (21.9%):  38%|███▊      | 12/32 [00:26<00:46,  2.33s/it]llm_judge_ans = True\n",
      "Average Metric: 8.00 / 32 (25.0%):  41%|████      | 13/32 [00:29<00:51,  2.69s/it]llm_judge_ans = False\n",
      "Average Metric: 8.00 / 32 (25.0%):  44%|████▍     | 14/32 [00:38<01:20,  4.48s/it]llm_judge_ans = True\n",
      "Average Metric: 9.00 / 32 (28.1%):  47%|████▋     | 15/32 [00:41<01:11,  4.21s/it]llm_judge_ans = True\n",
      "Average Metric: 10.00 / 32 (31.2%):  50%|█████     | 16/32 [00:47<01:14,  4.64s/it]llm_judge_ans = True\n",
      "Average Metric: 11.00 / 32 (34.4%):  53%|█████▎    | 17/32 [00:50<01:00,  4.04s/it]llm_judge_ans = False\n",
      "Average Metric: 11.00 / 32 (34.4%):  56%|█████▋    | 18/32 [00:53<00:52,  3.75s/it]llm_judge_ans = False\n",
      "Average Metric: 11.00 / 32 (34.4%):  59%|█████▉    | 19/32 [01:02<01:09,  5.37s/it]llm_judge_ans = False\n",
      "Average Metric: 11.00 / 32 (34.4%):  62%|██████▎   | 20/32 [01:04<00:52,  4.37s/it]llm_judge_ans = True\n",
      "Average Metric: 12.00 / 32 (37.5%):  66%|██████▌   | 21/32 [01:07<00:44,  4.01s/it]llm_judge_ans = False\n",
      "Average Metric: 12.00 / 32 (37.5%):  69%|██████▉   | 22/32 [01:15<00:50,  5.00s/it]llm_judge_ans = True\n",
      "Average Metric: 13.00 / 32 (40.6%):  72%|███████▏  | 23/32 [01:17<00:38,  4.27s/it]llm_judge_ans = True\n",
      "Average Metric: 14.00 / 32 (43.8%):  75%|███████▌  | 24/32 [01:19<00:28,  3.50s/it]llm_judge_ans = True\n",
      "Average Metric: 15.00 / 32 (46.9%):  78%|███████▊  | 25/32 [01:21<00:22,  3.20s/it]llm_judge_ans = False\n",
      "Average Metric: 15.00 / 32 (46.9%):  81%|████████▏ | 26/32 [01:29<00:26,  4.42s/it]llm_judge_ans = False\n",
      "Average Metric: 15.00 / 32 (46.9%):  84%|████████▍ | 27/32 [01:32<00:20,  4.19s/it]llm_judge_ans = False\n",
      "Average Metric: 15.00 / 32 (46.9%):  88%|████████▊ | 28/32 [01:35<00:15,  3.86s/it]llm_judge_ans = True\n",
      "Average Metric: 16.00 / 32 (50.0%):  91%|█████████ | 29/32 [01:40<00:12,  4.08s/it]llm_judge_ans = True\n",
      "Average Metric: 17.00 / 32 (53.1%):  94%|█████████▍| 30/32 [01:43<00:07,  3.67s/it]llm_judge_ans = True\n",
      "Average Metric: 18.00 / 32 (56.2%):  97%|█████████▋| 31/32 [01:45<00:03,  3.16s/it]llm_judge_ans = True\n",
      "Average Metric: 19.00 / 32 (59.4%): 100%|██████████| 32/32 [01:48<00:00,  3.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 02:41:25 INFO dspy.evaluate.evaluate: Average Metric: 19 / 32 (59.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Final DSPy Evaluation score :::: 59.38 ---------\n"
     ]
    }
   ],
   "source": [
    "evaluate_llm_judge = Evaluate(devset=generate_dspy_example_dataset(df_dpo_data), \n",
    "                              metric=metric_LLM_0, \n",
    "                              num_threads=1, \n",
    "                              display_progress=True, display_table=0, provide_traceback=True)\n",
    "\n",
    "eval_score = evaluate_llm_judge(llm_judge_0, num_threads=1)\n",
    "print(f\"------------- Final DSPy Evaluation score :::: {eval_score} ---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3eed68fe-0d9d-4ab3-982c-7e6e9fa2956a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5938"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_score_0 = eval_score/100\n",
    "dpo_score_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c8498c-c950-4c18-8413-81665b66abbc",
   "metadata": {},
   "source": [
    "Evaluation scores for ORPO results by LLM-judge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a37e3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 1.0|1 : 1.0|2 : 0.0|3 : 0.0|4 : 1.0|5 : 1.0|6 : 0.0|7 : 1.0|8 : 0.0|9 : 0.0|10 : 1.0|11 : 1.0|12 : 0.0|13 : 0.0|14 : 1.0|15 : 1.0|16 : 1.0|17 : 0.0|18 : 0.0|19 : 0.0|20 : 1.0|21 : 0.0|22 : 1.0|23 : 1.0|24 : 1.0|25 : 0.0|26 : 0.0|27 : 0.0|28 : 1.0|29 : 1.0|30 : 1.0|31 : 1.0|"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orpo_score_0 = get_judge_scores_0(df_orpo_data)\n",
    "orpo_score_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43cacda",
   "metadata": {},
   "source": [
    "Evaluation scores for ORPO results by dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9989d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = True\n",
      "Average Metric: 1.00 / 32 (3.1%):   3%|▎         | 1/32 [00:02<01:11,  2.30s/it]llm_judge_ans = True\n",
      "Average Metric: 2.00 / 32 (6.2%):   6%|▋         | 2/32 [00:04<01:08,  2.29s/it]llm_judge_ans = False\n",
      "Average Metric: 2.00 / 32 (6.2%):   9%|▉         | 3/32 [00:06<01:07,  2.33s/it]llm_judge_ans = False\n",
      "Average Metric: 2.00 / 32 (6.2%):  12%|█▎        | 4/32 [00:09<01:03,  2.25s/it]llm_judge_ans = True\n",
      "Average Metric: 3.00 / 32 (9.4%):  16%|█▌        | 5/32 [00:11<01:02,  2.32s/it]llm_judge_ans = True\n",
      "Average Metric: 4.00 / 32 (12.5%):  19%|█▉        | 6/32 [00:15<01:19,  3.04s/it]llm_judge_ans = False\n",
      "Average Metric: 4.00 / 32 (12.5%):  22%|██▏       | 7/32 [00:21<01:32,  3.71s/it]llm_judge_ans = True\n",
      "Average Metric: 5.00 / 32 (15.6%):  25%|██▌       | 8/32 [00:23<01:19,  3.33s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%):  28%|██▊       | 9/32 [00:44<03:23,  8.85s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%):  31%|███▏      | 10/32 [00:47<02:36,  7.12s/it]llm_judge_ans = True\n",
      "Average Metric: 6.00 / 32 (18.8%):  34%|███▍      | 11/32 [00:50<02:02,  5.81s/it]llm_judge_ans = True\n",
      "Average Metric: 7.00 / 32 (21.9%):  38%|███▊      | 12/32 [00:53<01:40,  5.01s/it]llm_judge_ans = False\n",
      "Average Metric: 7.00 / 32 (21.9%):  41%|████      | 13/32 [00:59<01:36,  5.06s/it]llm_judge_ans = False\n",
      "Average Metric: 7.00 / 32 (21.9%):  44%|████▍     | 14/32 [01:02<01:24,  4.67s/it]llm_judge_ans = True\n",
      "Average Metric: 8.00 / 32 (25.0%):  47%|████▋     | 15/32 [01:09<01:29,  5.27s/it]llm_judge_ans = True\n",
      "Average Metric: 9.00 / 32 (28.1%):  50%|█████     | 16/32 [01:14<01:21,  5.11s/it]llm_judge_ans = True\n",
      "Average Metric: 10.00 / 32 (31.2%):  53%|█████▎    | 17/32 [01:17<01:08,  4.55s/it]llm_judge_ans = False\n",
      "Average Metric: 10.00 / 32 (31.2%):  56%|█████▋    | 18/32 [01:21<01:01,  4.41s/it]llm_judge_ans = False\n",
      "Average Metric: 10.00 / 32 (31.2%):  59%|█████▉    | 19/32 [01:33<01:27,  6.75s/it]llm_judge_ans = False\n",
      "Average Metric: 10.00 / 32 (31.2%):  62%|██████▎   | 20/32 [01:35<01:03,  5.26s/it]llm_judge_ans = True\n",
      "Average Metric: 11.00 / 32 (34.4%):  66%|██████▌   | 21/32 [01:39<00:52,  4.79s/it]llm_judge_ans = False\n",
      "Average Metric: 11.00 / 32 (34.4%):  69%|██████▉   | 22/32 [01:48<01:00,  6.04s/it]llm_judge_ans = True\n",
      "Average Metric: 12.00 / 32 (37.5%):  72%|███████▏  | 23/32 [01:50<00:45,  5.06s/it]llm_judge_ans = True\n",
      "Average Metric: 13.00 / 32 (40.6%):  75%|███████▌  | 24/32 [01:53<00:35,  4.39s/it]llm_judge_ans = True\n",
      "Average Metric: 14.00 / 32 (43.8%):  78%|███████▊  | 25/32 [01:57<00:29,  4.20s/it]llm_judge_ans = False\n",
      "Average Metric: 14.00 / 32 (43.8%):  81%|████████▏ | 26/32 [02:08<00:37,  6.32s/it]llm_judge_ans = False\n",
      "Average Metric: 14.00 / 32 (43.8%):  84%|████████▍ | 27/32 [02:12<00:28,  5.67s/it]llm_judge_ans = False\n",
      "Average Metric: 14.00 / 32 (43.8%):  88%|████████▊ | 28/32 [02:16<00:20,  5.13s/it]llm_judge_ans = True\n",
      "Average Metric: 15.00 / 32 (46.9%):  91%|█████████ | 29/32 [02:20<00:14,  4.81s/it]llm_judge_ans = True\n",
      "Average Metric: 16.00 / 32 (50.0%):  94%|█████████▍| 30/32 [02:24<00:08,  4.38s/it]llm_judge_ans = True\n",
      "Average Metric: 17.00 / 32 (53.1%):  97%|█████████▋| 31/32 [02:26<00:03,  3.75s/it]llm_judge_ans = True\n",
      "Average Metric: 18.00 / 32 (56.2%): 100%|██████████| 32/32 [02:29<00:00,  4.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 02:45:04 INFO dspy.evaluate.evaluate: Average Metric: 18 / 32 (56.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Final DSPy Evaluation score :::: 56.25 ---------\n"
     ]
    }
   ],
   "source": [
    "evaluate_llm_judge = Evaluate(devset=generate_dspy_example_dataset(df_orpo_data), \n",
    "                              metric=metric_LLM_0, \n",
    "                              num_threads=1, \n",
    "                              display_progress=True, \n",
    "                              display_table=0, \n",
    "                              provide_traceback=True)\n",
    "\n",
    "eval_score = evaluate_llm_judge(llm_judge_0, num_threads=1)\n",
    "print(f\"------------- Final DSPy Evaluation score :::: {eval_score} ---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "294a77c7-1b74-4d5b-83ad-6946bf7acce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orpo_score_0 = eval_score/100\n",
    "orpo_score_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c73f353-661d-43ec-9a7f-0359457738a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Evaluation scores for RAG HAIKU results by LLM-judge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c74f687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.0|1 : 0.0|2 : 0.0|3 : 0.0|4 : 0.0|5 : 1.0|6 : 0.0|7 : 1.0|8 : 0.0|9 : 0.0|10 : 0.0|11 : 0.0|12 : 1.0|13 : 0.0|14 : 0.0|15 : 1.0|16 : 1.0|17 : 0.0|18 : 0.0|19 : 0.0|20 : 0.0|21 : 0.0|22 : 0.0|23 : 0.0|24 : 1.0|25 : 0.0|26 : 0.0|27 : 0.0|28 : 0.0|29 : 0.0|30 : 0.0|31 : 0.0|"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1875"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_haiku_score_0 = get_judge_scores_0(df_rag_haiku_data)\n",
    "rag_haiku_score_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48578ae",
   "metadata": {},
   "source": [
    "Evaluation scores for RAG HAIKU results by dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c1fee8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):   3%|▎         | 1/32 [00:03<02:00,  3.89s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):   6%|▋         | 2/32 [00:09<02:23,  4.78s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):   9%|▉         | 3/32 [00:10<01:36,  3.34s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  12%|█▎        | 4/32 [00:13<01:22,  2.93s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  16%|█▌        | 5/32 [00:15<01:08,  2.54s/it]llm_judge_ans = True\n",
      "Average Metric: 1.00 / 32 (3.1%):  19%|█▉        | 6/32 [00:17<01:01,  2.35s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):  22%|██▏       | 7/32 [00:18<00:50,  2.02s/it]llm_judge_ans = True\n",
      "Average Metric: 2.00 / 32 (6.2%):  25%|██▌       | 8/32 [00:20<00:45,  1.89s/it]llm_judge_ans = False\n",
      "Average Metric: 2.00 / 32 (6.2%):  28%|██▊       | 9/32 [00:25<01:08,  2.97s/it]llm_judge_ans = False\n",
      "Average Metric: 2.00 / 32 (6.2%):  31%|███▏      | 10/32 [00:31<01:26,  3.95s/it]llm_judge_ans = False\n",
      "Average Metric: 2.00 / 32 (6.2%):  34%|███▍      | 11/32 [00:40<01:55,  5.52s/it]llm_judge_ans = False\n",
      "Average Metric: 2.00 / 32 (6.2%):  38%|███▊      | 12/32 [00:46<01:53,  5.70s/it]llm_judge_ans = True\n",
      "Average Metric: 3.00 / 32 (9.4%):  41%|████      | 13/32 [00:49<01:32,  4.89s/it]llm_judge_ans = False\n",
      "Average Metric: 3.00 / 32 (9.4%):  44%|████▍     | 14/32 [00:56<01:38,  5.46s/it]llm_judge_ans = False\n",
      "Average Metric: 3.00 / 32 (9.4%):  47%|████▋     | 15/32 [01:03<01:39,  5.87s/it]llm_judge_ans = True\n",
      "Average Metric: 4.00 / 32 (12.5%):  50%|█████     | 16/32 [01:05<01:16,  4.81s/it]llm_judge_ans = False\n",
      "Average Metric: 4.00 / 32 (12.5%):  53%|█████▎    | 17/32 [01:08<01:01,  4.10s/it]llm_judge_ans = False\n",
      "Average Metric: 4.00 / 32 (12.5%):  56%|█████▋    | 18/32 [01:13<01:01,  4.39s/it]llm_judge_ans = False\n",
      "Average Metric: 4.00 / 32 (12.5%):  59%|█████▉    | 19/32 [01:15<00:48,  3.77s/it]llm_judge_ans = False\n",
      "Average Metric: 4.00 / 32 (12.5%):  62%|██████▎   | 20/32 [01:21<00:54,  4.55s/it]llm_judge_ans = False\n",
      "Average Metric: 4.00 / 32 (12.5%):  66%|██████▌   | 21/32 [01:28<00:56,  5.17s/it]llm_judge_ans = False\n",
      "Average Metric: 4.00 / 32 (12.5%):  69%|██████▉   | 22/32 [01:34<00:55,  5.53s/it]llm_judge_ans = False\n",
      "Average Metric: 4.00 / 32 (12.5%):  72%|███████▏  | 23/32 [01:40<00:50,  5.62s/it]llm_judge_ans = False\n",
      "Average Metric: 4.00 / 32 (12.5%):  75%|███████▌  | 24/32 [01:46<00:44,  5.53s/it]llm_judge_ans = True\n",
      "Average Metric: 5.00 / 32 (15.6%):  78%|███████▊  | 25/32 [01:48<00:32,  4.63s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%):  81%|████████▏ | 26/32 [01:56<00:33,  5.57s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%):  84%|████████▍ | 27/32 [02:01<00:27,  5.56s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%):  88%|████████▊ | 28/32 [02:05<00:20,  5.13s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%):  91%|█████████ | 29/32 [02:13<00:17,  5.97s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%):  94%|█████████▍| 30/32 [02:21<00:12,  6.41s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%):  97%|█████████▋| 31/32 [02:22<00:04,  4.98s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%): 100%|██████████| 32/32 [02:27<00:00,  4.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 02:48:55 INFO dspy.evaluate.evaluate: Average Metric: 5 / 32 (15.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Final DSPy Evaluation score :::: 15.62 ---------\n"
     ]
    }
   ],
   "source": [
    "evaluate_llm_judge = Evaluate(devset=generate_dspy_example_dataset(df_rag_haiku_data), \n",
    "                              metric=metric_LLM_0, \n",
    "                              num_threads=1, \n",
    "                              display_progress=True, \n",
    "                              display_table=0, \n",
    "                              provide_traceback=True)\n",
    "\n",
    "eval_score = evaluate_llm_judge(llm_judge_0, num_threads=1)\n",
    "print(f\"------------- Final DSPy Evaluation score :::: {eval_score} ---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b8f8964-5c65-40eb-b267-d5669f882501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1562"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_haiku_score_0 = eval_score/100\n",
    "rag_haiku_score_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f2303b-f5d8-4879-a4bb-5f9ba42b7139",
   "metadata": {},
   "source": [
    "Evaluation scores for RAG compiled HAIKU results by LLM-judge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bfc0b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.0|1 : 1.0|2 : 1.0|3 : 1.0|4 : 0.0|5 : 1.0|6 : 1.0|7 : 1.0|8 : 0.0|9 : 0.0|10 : 0.0|11 : 0.0|12 : 0.0|13 : 1.0|14 : 0.0|15 : 0.0|16 : 0.0|17 : 1.0|18 : 0.0|19 : 0.0|20 : 1.0|21 : 0.0|22 : 0.0|23 : 0.0|24 : 1.0|25 : 1.0|26 : 0.0|27 : 0.0|28 : 1.0|29 : 0.0|30 : 0.0|31 : 1.0|"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40625"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragc_haiku_score_0 = get_judge_scores_0(df_ragc_haiku_data)\n",
    "ragc_haiku_score_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dca8b5",
   "metadata": {},
   "source": [
    "Evaluation scores for RAG compiled HAIKU results by dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37f87c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):   3%|▎         | 1/32 [00:03<01:35,  3.07s/it]llm_judge_ans = True\n",
      "Average Metric: 1.00 / 32 (3.1%):   6%|▋         | 2/32 [00:04<01:09,  2.32s/it]llm_judge_ans = True\n",
      "Average Metric: 2.00 / 32 (6.2%):   9%|▉         | 3/32 [00:06<00:57,  1.98s/it]llm_judge_ans = True\n",
      "Average Metric: 3.00 / 32 (9.4%):  12%|█▎        | 4/32 [00:08<00:56,  2.03s/it]llm_judge_ans = False\n",
      "Average Metric: 3.00 / 32 (9.4%):  16%|█▌        | 5/32 [00:10<00:51,  1.90s/it]llm_judge_ans = True\n",
      "Average Metric: 4.00 / 32 (12.5%):  19%|█▉        | 6/32 [00:12<00:50,  1.95s/it]llm_judge_ans = True\n",
      "Average Metric: 5.00 / 32 (15.6%):  22%|██▏       | 7/32 [00:14<00:53,  2.13s/it]llm_judge_ans = True\n",
      "Average Metric: 6.00 / 32 (18.8%):  25%|██▌       | 8/32 [00:16<00:47,  1.99s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  28%|██▊       | 9/32 [00:20<00:58,  2.55s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  31%|███▏      | 10/32 [00:24<01:07,  3.06s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  34%|███▍      | 11/32 [00:27<01:06,  3.19s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  38%|███▊      | 12/32 [00:30<00:58,  2.91s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  41%|████      | 13/32 [00:36<01:16,  4.04s/it]llm_judge_ans = True\n",
      "Average Metric: 7.00 / 32 (21.9%):  44%|████▍     | 14/32 [00:38<01:01,  3.39s/it]llm_judge_ans = False\n",
      "Average Metric: 7.00 / 32 (21.9%):  47%|████▋     | 15/32 [00:43<01:06,  3.93s/it]llm_judge_ans = False\n",
      "Average Metric: 7.00 / 32 (21.9%):  50%|█████     | 16/32 [00:48<01:06,  4.14s/it]llm_judge_ans = False\n",
      "Average Metric: 7.00 / 32 (21.9%):  53%|█████▎    | 17/32 [00:53<01:05,  4.34s/it]llm_judge_ans = False\n",
      "Average Metric: 7.00 / 32 (21.9%):  56%|█████▋    | 18/32 [00:54<00:48,  3.49s/it]llm_judge_ans = False\n",
      "Average Metric: 7.00 / 32 (21.9%):  59%|█████▉    | 19/32 [00:56<00:38,  2.98s/it]llm_judge_ans = False\n",
      "Average Metric: 7.00 / 32 (21.9%):  62%|██████▎   | 20/32 [01:03<00:49,  4.08s/it]llm_judge_ans = True\n",
      "Average Metric: 8.00 / 32 (25.0%):  66%|██████▌   | 21/32 [01:05<00:37,  3.40s/it]llm_judge_ans = False\n",
      "Average Metric: 8.00 / 32 (25.0%):  69%|██████▉   | 22/32 [01:16<00:58,  5.86s/it]llm_judge_ans = False\n",
      "Average Metric: 8.00 / 32 (25.0%):  72%|███████▏  | 23/32 [01:22<00:53,  5.94s/it]llm_judge_ans = False\n",
      "Average Metric: 8.00 / 32 (25.0%):  75%|███████▌  | 24/32 [01:27<00:43,  5.44s/it]llm_judge_ans = True\n",
      "Average Metric: 9.00 / 32 (28.1%):  78%|███████▊  | 25/32 [01:30<00:32,  4.70s/it]llm_judge_ans = False\n",
      "Average Metric: 9.00 / 32 (28.1%):  81%|████████▏ | 26/32 [01:34<00:28,  4.72s/it]llm_judge_ans = False\n",
      "Average Metric: 9.00 / 32 (28.1%):  84%|████████▍ | 27/32 [01:38<00:22,  4.45s/it]llm_judge_ans = False\n",
      "Average Metric: 9.00 / 32 (28.1%):  88%|████████▊ | 28/32 [01:40<00:14,  3.72s/it]llm_judge_ans = False\n",
      "Average Metric: 9.00 / 32 (28.1%):  91%|█████████ | 29/32 [01:43<00:10,  3.36s/it]llm_judge_ans = False\n",
      "Average Metric: 9.00 / 32 (28.1%):  94%|█████████▍| 30/32 [01:48<00:07,  3.88s/it]llm_judge_ans = False\n",
      "Average Metric: 9.00 / 32 (28.1%):  97%|█████████▋| 31/32 [01:49<00:03,  3.16s/it]llm_judge_ans = True\n",
      "Average Metric: 10.00 / 32 (31.2%): 100%|██████████| 32/32 [01:52<00:00,  3.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 02:51:45 INFO dspy.evaluate.evaluate: Average Metric: 10 / 32 (31.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Final DSPy Evaluation score :::: 31.25 ---------\n"
     ]
    }
   ],
   "source": [
    "evaluate_llm_judge = Evaluate(devset=generate_dspy_example_dataset(df_ragc_haiku_data), \n",
    "                              metric=metric_LLM_0, \n",
    "                              num_threads=1, \n",
    "                              display_progress=True, \n",
    "                              display_table=0, \n",
    "                              provide_traceback=True)\n",
    "\n",
    "eval_score = evaluate_llm_judge(llm_judge_0, num_threads=1)\n",
    "print(f\"------------- Final DSPy Evaluation score :::: {eval_score} ---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7364fd9-2ab2-45ee-8b20-dcd43032a385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3125"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragc_haiku_score_0 = eval_score/100\n",
    "ragc_haiku_score_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db4de9b-a064-45c5-9cb3-b6f9c271d695",
   "metadata": {},
   "source": [
    "Evaluation scores for RAG Sonnet results by LLM-judge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ab2c756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.0|1 : 0.0|2 : 0.0|3 : 0.0|4 : 0.0|5 : 0.0|6 : 0.0|7 : 0.0|8 : 0.0|9 : 0.0|10 : 0.0|11 : 0.0|12 : 0.0|13 : 0.0|14 : 0.0|15 : 0.0|16 : 0.0|17 : 0.0|18 : 0.0|19 : 0.0|20 : 0.0|21 : 0.0|22 : 0.0|23 : 0.0|24 : 0.0|25 : 0.0|26 : 0.0|27 : 0.0|28 : 0.0|29 : 0.0|30 : 0.0|31 : 0.0|"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_sonnet_score_0 = get_judge_scores_0(df_rag_sonnet_data)\n",
    "rag_sonnet_score_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d4e606",
   "metadata": {},
   "source": [
    "Evaluation scores for RAG Sonnet results by dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03ff9c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):   3%|▎         | 1/32 [00:03<02:03,  3.99s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):   6%|▋         | 2/32 [00:10<02:52,  5.74s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):   9%|▉         | 3/32 [00:12<01:54,  3.96s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  12%|█▎        | 4/32 [00:14<01:26,  3.09s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  16%|█▌        | 5/32 [00:16<01:11,  2.65s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  19%|█▉        | 6/32 [00:17<00:58,  2.25s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  22%|██▏       | 7/32 [00:20<01:00,  2.41s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  25%|██▌       | 8/32 [00:24<01:09,  2.91s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  28%|██▊       | 9/32 [00:30<01:25,  3.70s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  31%|███▏      | 10/32 [00:37<01:47,  4.87s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  34%|███▍      | 11/32 [00:39<01:24,  4.00s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  38%|███▊      | 12/32 [00:41<01:07,  3.38s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  41%|████      | 13/32 [00:47<01:21,  4.27s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  44%|████▍     | 14/32 [00:54<01:31,  5.08s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  47%|████▋     | 15/32 [01:04<01:49,  6.44s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  50%|█████     | 16/32 [01:07<01:25,  5.35s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  53%|█████▎    | 17/32 [01:15<01:32,  6.15s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  56%|█████▋    | 18/32 [01:21<01:28,  6.31s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  59%|█████▉    | 19/32 [01:25<01:09,  5.35s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  62%|██████▎   | 20/32 [01:31<01:07,  5.60s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  66%|██████▌   | 21/32 [01:41<01:16,  6.94s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  69%|██████▉   | 22/32 [01:57<01:37,  9.72s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  72%|███████▏  | 23/32 [02:11<01:39, 11.08s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  75%|███████▌  | 24/32 [02:19<01:21, 10.16s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  78%|███████▊  | 25/32 [02:26<01:05,  9.29s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  81%|████████▏ | 26/32 [02:41<01:05, 10.84s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  84%|████████▍ | 27/32 [02:54<00:58, 11.63s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  88%|████████▊ | 28/32 [03:03<00:43, 10.85s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  91%|█████████ | 29/32 [03:11<00:29,  9.87s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  94%|█████████▍| 30/32 [03:22<00:20, 10.15s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):  97%|█████████▋| 31/32 [03:25<00:08,  8.02s/it]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%): 100%|██████████| 32/32 [03:36<00:00,  6.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 02:56:48 INFO dspy.evaluate.evaluate: Average Metric: 0 / 32 (0.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Final DSPy Evaluation score :::: 0.0 ---------\n"
     ]
    }
   ],
   "source": [
    "evaluate_llm_judge = Evaluate(devset=generate_dspy_example_dataset(df_rag_sonnet_data), \n",
    "                              metric=metric_LLM_0, \n",
    "                              num_threads=1, \n",
    "                              display_progress=True, \n",
    "                              display_table=0, \n",
    "                              provide_traceback=True)\n",
    "\n",
    "eval_score = evaluate_llm_judge(llm_judge_0, num_threads=1)\n",
    "print(f\"------------- Final DSPy Evaluation score :::: {eval_score} ---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "184e16f3-c06e-47fb-8d90-00581138c37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_sonnet_score_0 = eval_score/100\n",
    "rag_sonnet_score_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534865e2-6d33-45e4-8aec-49dbe8ec40a1",
   "metadata": {},
   "source": [
    "Evaluation scores for RAG compiled Sonnet results by LLM-judge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d82bfaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.0|1 : 1.0|2 : 0.0|3 : 0.0|4 : 1.0|5 : 1.0|6 : 1.0|7 : 1.0|8 : 0.0|9 : 0.0|10 : 0.0|11 : 0.0|12 : 0.0|13 : 1.0|14 : 0.0|15 : 0.0|16 : 1.0|17 : 1.0|18 : 1.0|19 : 0.0|20 : 1.0|21 : 0.0|22 : 1.0|23 : 0.0|24 : 1.0|25 : 1.0|26 : 0.0|27 : 0.0|28 : 1.0|29 : 0.0|30 : 1.0|31 : 1.0|"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragc_sonnet_score_0 = get_judge_scores_0(df_ragc_sonnet_data)\n",
    "ragc_sonnet_score_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d195000",
   "metadata": {},
   "source": [
    "Evaluation scores for RAG compiled Sonnet results by dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a70597ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = False\n",
      "Average Metric: 0.00 / 32 (0.0%):   3%|▎         | 1/32 [00:11<05:52, 11.37s/it]llm_judge_ans = True\n",
      "Average Metric: 1.00 / 32 (3.1%):   6%|▋         | 2/32 [00:12<02:47,  5.59s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):   9%|▉         | 3/32 [00:15<02:03,  4.27s/it]llm_judge_ans = False\n",
      "Average Metric: 1.00 / 32 (3.1%):  12%|█▎        | 4/32 [00:19<01:51,  3.99s/it]llm_judge_ans = True\n",
      "Average Metric: 2.00 / 32 (6.2%):  16%|█▌        | 5/32 [00:22<01:38,  3.65s/it]llm_judge_ans = True\n",
      "Average Metric: 3.00 / 32 (9.4%):  19%|█▉        | 6/32 [00:24<01:26,  3.31s/it]llm_judge_ans = True\n",
      "Average Metric: 4.00 / 32 (12.5%):  22%|██▏       | 7/32 [00:28<01:28,  3.56s/it]llm_judge_ans = True\n",
      "Average Metric: 5.00 / 32 (15.6%):  25%|██▌       | 8/32 [00:32<01:23,  3.49s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%):  28%|██▊       | 9/32 [00:39<01:49,  4.77s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%):  31%|███▏      | 10/32 [01:04<04:02, 11.01s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%):  34%|███▍      | 11/32 [01:10<03:15,  9.33s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%):  38%|███▊      | 12/32 [01:13<02:26,  7.34s/it]llm_judge_ans = False\n",
      "Average Metric: 5.00 / 32 (15.6%):  41%|████      | 13/32 [01:25<02:49,  8.93s/it]llm_judge_ans = True\n",
      "Average Metric: 6.00 / 32 (18.8%):  44%|████▍     | 14/32 [01:27<02:02,  6.78s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  47%|████▋     | 15/32 [01:32<01:48,  6.36s/it]llm_judge_ans = False\n",
      "Average Metric: 6.00 / 32 (18.8%):  50%|█████     | 16/32 [01:36<01:29,  5.61s/it]llm_judge_ans = True\n",
      "Average Metric: 7.00 / 32 (21.9%):  53%|█████▎    | 17/32 [01:38<01:06,  4.46s/it]llm_judge_ans = True\n",
      "Average Metric: 8.00 / 32 (25.0%):  56%|█████▋    | 18/32 [01:41<00:54,  3.89s/it]llm_judge_ans = True\n",
      "Average Metric: 9.00 / 32 (28.1%):  59%|█████▉    | 19/32 [01:42<00:41,  3.22s/it]llm_judge_ans = False\n",
      "Average Metric: 9.00 / 32 (28.1%):  62%|██████▎   | 20/32 [01:47<00:45,  3.76s/it]llm_judge_ans = True\n",
      "Average Metric: 10.00 / 32 (31.2%):  66%|██████▌   | 21/32 [01:50<00:37,  3.38s/it]llm_judge_ans = False\n",
      "Average Metric: 10.00 / 32 (31.2%):  69%|██████▉   | 22/32 [01:57<00:44,  4.45s/it]llm_judge_ans = False\n",
      "Average Metric: 10.00 / 32 (31.2%):  72%|███████▏  | 23/32 [02:02<00:43,  4.79s/it]llm_judge_ans = False\n",
      "Average Metric: 10.00 / 32 (31.2%):  75%|███████▌  | 24/32 [02:10<00:46,  5.79s/it]llm_judge_ans = True\n",
      "Average Metric: 11.00 / 32 (34.4%):  78%|███████▊  | 25/32 [02:13<00:32,  4.69s/it]llm_judge_ans = True\n",
      "Average Metric: 12.00 / 32 (37.5%):  81%|████████▏ | 26/32 [02:16<00:25,  4.32s/it]llm_judge_ans = False\n",
      "Average Metric: 12.00 / 32 (37.5%):  84%|████████▍ | 27/32 [02:23<00:25,  5.07s/it]llm_judge_ans = False\n",
      "Average Metric: 12.00 / 32 (37.5%):  88%|████████▊ | 28/32 [02:28<00:20,  5.09s/it]llm_judge_ans = True\n",
      "Average Metric: 13.00 / 32 (40.6%):  91%|█████████ | 29/32 [02:30<00:12,  4.22s/it]llm_judge_ans = False\n",
      "Average Metric: 13.00 / 32 (40.6%):  94%|█████████▍| 30/32 [02:35<00:09,  4.50s/it]llm_judge_ans = True\n",
      "Average Metric: 14.00 / 32 (43.8%):  97%|█████████▋| 31/32 [02:38<00:03,  3.84s/it]llm_judge_ans = True\n",
      "Average Metric: 15.00 / 32 (46.9%): 100%|██████████| 32/32 [02:40<00:00,  5.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 03:01:11 INFO dspy.evaluate.evaluate: Average Metric: 15 / 32 (46.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Final DSPy Evaluation score :::: 46.88 ---------\n"
     ]
    }
   ],
   "source": [
    "evaluate_llm_judge = Evaluate(devset=generate_dspy_example_dataset(df_ragc_sonnet_data), \n",
    "                              metric=metric_LLM_0, \n",
    "                              num_threads=1, \n",
    "                              display_progress=True, \n",
    "                              display_table=0, \n",
    "                              provide_traceback=True)\n",
    "\n",
    "eval_score = evaluate_llm_judge(llm_judge_0, num_threads=1)\n",
    "print(f\"------------- Final DSPy Evaluation score :::: {eval_score} ---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32055e45-0567-45dd-9618-828ea456f685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46880000000000005"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragc_sonnet_score_0 = eval_score/100\n",
    "ragc_sonnet_score_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967d4aaf-caf0-4ffa-addb-8b05f413a6d3",
   "metadata": {},
   "source": [
    "#### Benchmarking the performance across RAG with foundation models and fine-tuned models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "135d7f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_class_type = ['RAG_Haiku','RAG_Haiku_Compiled','SFT(Llama3-8B)','DPO(Llama3-8B)','ORPO(Llama3-8B)']\n",
    "train_class_count = [rag_haiku_score_0,ragc_haiku_score_0,sft_score_0,dpo_score_0,orpo_score_0,]\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "\n",
    "# creating the bar plot\n",
    "plt.bar(train_class_type, train_class_count, color ='green', width = 0.4)\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy by LLM-as-a-judge (True/False)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986b5364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9aae777",
   "metadata": {},
   "source": [
    "### Evaluation Method 2: LLM-as-a-judge with a 0-1 score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06de0054",
   "metadata": {},
   "source": [
    "Setup Claude and Meta models on Bedrock for LLM-as-a-judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4f1022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp_bedrock = dspy.Bedrock(region_name=region_name)\n",
    "\n",
    "claude_sonnet_model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "clade_haiku_model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "llama_model_id = \"us.meta.llama3-2-90b-instruct-v1:0\"\n",
    "\n",
    "\n",
    "bedrock_sonnet = dspy.AWSAnthropic(aws_provider=dsp_bedrock,\n",
    "                                  model=claude_sonnet_model_id,\n",
    "                                  max_new_tokens=4096,\n",
    "                                  max_tokens=4096)\n",
    "\n",
    "bedrock_haiku = dspy.AWSAnthropic(aws_provider=dsp_bedrock,\n",
    "                                 model=clade_haiku_model_id,\n",
    "                                 max_new_tokens=4096,\n",
    "                                 max_tokens=4096)\n",
    "\n",
    "bedrock_llama = dspy.AWSMeta(aws_provider=dsp_bedrock, \n",
    "                             model=llama_model_id, \n",
    "                             max_new_tokens=2048,\n",
    "                             max_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3559defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(lm=bedrock_sonnet, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533e00d8",
   "metadata": {},
   "source": [
    "Define the LLM judge class: eval = 0-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d5b9423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FactualityJudge_1(dspy.Signature):\n",
    "    \"\"\"Judge if the predicted answer is semantically match the groundtruth answer. Provide a score between 0 and 1, 0 means completely mismatch and 1 means perfectly match. In the response, only present the score, DO NOT add any premables.\"\"\"\n",
    "\n",
    "    groundtruth_answer = dspy.InputField(desc=\"groundtruth answer\")\n",
    "    predicted_answer = dspy.InputField(desc=\"predicted answer\")\n",
    "    factually_correct = dspy.OutputField(desc=\"Is the predicted answer factually correct and semantically similar to the groundtruth answer?\") #, prefix=\"Factual[True/False]:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fffc6568",
   "metadata": {},
   "outputs": [],
   "source": [
    "factualityJudge_1 = dspy.ChainOfThought(FactualityJudge_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d6c653",
   "metadata": {},
   "source": [
    "Define the factuality metric for DSPy evaluate to run through LLM response/answer, and use LLM judge to generate evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa760a37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def factuality_metric_1(gt_answer, pred_answer):\n",
    "    #print(f\" type(gt_answer) :: {type(gt_answer)}\")\n",
    "    #if type(gt_answer) == \"<class 'dspy.primitives.example.Example'>\":\n",
    "    pred_answer = gt_answer.pred_answer\n",
    "    gt_answer = gt_answer.gt_answer\n",
    "        \n",
    "        \n",
    "    factual_metrc = factualityJudge_1(groundtruth_answer=gt_answer, predicted_answer=pred_answer), \n",
    "    '''\n",
    "    #debug\n",
    "    print(f\"\\n factual LLM judge  >>>>>>>> {factual_metrc}\")\n",
    "    print(f\"\\n factual LLM judge  >>>>>>>> {factual_metrc[0].factually_correct}\")\n",
    "    print(f\"\\n gt_answer  >>>>>>>  {gt_answer}\")\n",
    "    print(f\"\\n pred_answer  >>>>>>> {pred_answer}\")\n",
    "    '''\n",
    "    llm_judge_ans = float(factual_metrc[0].factually_correct)\n",
    "    print(f\"llm_judge_ans = {llm_judge_ans}\")\n",
    "    return llm_judge_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "823c7641",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_LLM_1 = factuality_metric_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99caf85c",
   "metadata": {},
   "source": [
    "LLM Judge class to generate the answer and factual consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a123c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMJudge_1(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.ChainOfThought(FactualityJudge_1)\n",
    "    \n",
    "    def forward(self, gt_answer, pred_answer):\n",
    "        factual = self.generate_answer(groundtruth_answer=gt_answer, predicted_answer=pred_answer)\n",
    "        #print(f\"factual LLM judge reasoning {factual}\")\n",
    "        llm_judge_ans = factual.factually_correct\n",
    "        \n",
    "        return llm_judge_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4253430-4b57-4047-805c-4d5cae669bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_judge_1 = LLMJudge_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ea6902",
   "metadata": {},
   "source": [
    "Batch evaluation using LLM-Judge class for dataset in dataframe format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "82942678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_judge_score_1(test_data):\n",
    "    scores = []\n",
    "\n",
    "    for index, row in test_data.iterrows():\n",
    "        #print(\"=== \",index,\" ===\")\n",
    "        #print(f\"---------------\")\n",
    "        #print(f\"row['ref_answer'] >>>  {row['ref_answer']}\")\n",
    "        #print(f\"row['response'] {row['response']}\")\n",
    "        llm_judge_ans = float(llm_judge_1(row['ref_answer'], row['response']))\n",
    "        #print(f\"llm_judge_ans :: {llm_judge_ans}\")\n",
    "        scores.append(llm_judge_ans)\n",
    "        print(index,':',llm_judge_ans, end='|')\n",
    "\n",
    "    accuracy_score = sum(scores)/len(scores)\n",
    "    \n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3d80b2",
   "metadata": {},
   "source": [
    "### LLM judge metrics by dspy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f1d213",
   "metadata": {},
   "source": [
    "Evaluation scores for SFT results by LLM-judge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec4fabb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 1.0|1 : 0.3|2 : 0.2|3 : 1.0|4 : 1.0|5 : 1.0|6 : 1.0|7 : 0.9|8 : 0.0|9 : 0.0|10 : 0.2|11 : 0.2|12 : 0.7|13 : 0.2|14 : 0.0|15 : 0.0|16 : 1.0|17 : 0.0|18 : 0.1|19 : 0.2|20 : 0.9|21 : 0.3|22 : 0.9|23 : 0.2|24 : 1.0|25 : 0.1|26 : 0.0|27 : 0.3|28 : 1.0|29 : 0.8|30 : 0.1|31 : 0.9|"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48437500000000006"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_score_1 = get_judge_score_1(df_sft_data)\n",
    "sft_score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd843654",
   "metadata": {},
   "source": [
    "Evaluation scores for SFT results by dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "998d96e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = 1.0\n",
      "Average Metric: 1.00 / 32 (3.1%):   3%|▎         | 1/32 [00:01<00:54,  1.75s/it]llm_judge_ans = 0.3\n",
      "Average Metric: 1.30 / 32 (4.1%):   6%|▋         | 2/32 [00:04<01:17,  2.60s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 1.50 / 32 (4.7%):   9%|▉         | 3/32 [00:07<01:13,  2.53s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 2.50 / 32 (7.8%):  12%|█▎        | 4/32 [00:08<01:00,  2.16s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 3.50 / 32 (10.9%):  16%|█▌        | 5/32 [00:11<00:57,  2.15s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 4.50 / 32 (14.1%):  19%|█▉        | 6/32 [00:13<01:01,  2.35s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 5.50 / 32 (17.2%):  22%|██▏       | 7/32 [00:16<00:57,  2.31s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 6.40 / 32 (20.0%):  25%|██▌       | 8/32 [00:17<00:49,  2.07s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 6.40 / 32 (20.0%):  28%|██▊       | 9/32 [00:20<00:56,  2.45s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 6.40 / 32 (20.0%):  31%|███▏      | 10/32 [00:22<00:48,  2.20s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 6.60 / 32 (20.6%):  34%|███▍      | 11/32 [00:24<00:44,  2.13s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 6.80 / 32 (21.3%):  38%|███▊      | 12/32 [00:26<00:40,  2.03s/it]llm_judge_ans = 0.6\n",
      "Average Metric: 7.40 / 32 (23.1%):  41%|████      | 13/32 [00:28<00:36,  1.93s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 7.60 / 32 (23.8%):  44%|████▍     | 14/32 [00:29<00:32,  1.80s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 7.60 / 32 (23.8%):  47%|████▋     | 15/32 [00:31<00:30,  1.82s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 7.60 / 32 (23.8%):  50%|█████     | 16/32 [00:34<00:36,  2.28s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 8.60 / 32 (26.9%):  53%|█████▎    | 17/32 [00:36<00:31,  2.09s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 8.60 / 32 (26.9%):  56%|█████▋    | 18/32 [00:38<00:28,  2.04s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 8.70 / 32 (27.2%):  59%|█████▉    | 19/32 [00:40<00:28,  2.18s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 8.90 / 32 (27.8%):  62%|██████▎   | 20/32 [00:43<00:29,  2.46s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 9.80 / 32 (30.6%):  66%|██████▌   | 21/32 [00:48<00:33,  3.04s/it]llm_judge_ans = 0.3\n",
      "Average Metric: 10.10 / 32 (31.6%):  69%|██████▉   | 22/32 [00:50<00:29,  2.92s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 11.00 / 32 (34.4%):  72%|███████▏  | 23/32 [00:53<00:25,  2.84s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 11.20 / 32 (35.0%):  75%|███████▌  | 24/32 [00:55<00:20,  2.56s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 12.20 / 32 (38.1%):  78%|███████▊  | 25/32 [00:57<00:16,  2.32s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 12.30 / 32 (38.4%):  81%|████████▏ | 26/32 [00:59<00:14,  2.40s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 12.30 / 32 (38.4%):  84%|████████▍ | 27/32 [01:03<00:13,  2.70s/it]llm_judge_ans = 0.3\n",
      "Average Metric: 12.60 / 32 (39.4%):  88%|████████▊ | 28/32 [01:05<00:10,  2.53s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 13.60 / 32 (42.5%):  91%|█████████ | 29/32 [01:08<00:07,  2.58s/it]llm_judge_ans = 0.8\n",
      "Average Metric: 14.40 / 32 (45.0%):  94%|█████████▍| 30/32 [01:12<00:06,  3.03s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 14.50 / 32 (45.3%):  97%|█████████▋| 31/32 [01:14<00:02,  2.92s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 15.40 / 32 (48.1%): 100%|██████████| 32/32 [01:17<00:00,  2.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 03:03:04 INFO dspy.evaluate.evaluate: Average Metric: 15.400000000000002 / 32 (48.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Final DSPy Evaluation score :::: 48.13 ---------\n"
     ]
    }
   ],
   "source": [
    "evaluate_llm_judge = Evaluate(devset=generate_dspy_example_dataset(df_sft_data), \n",
    "                              metric=metric_LLM_1, \n",
    "                              num_threads=1, \n",
    "                              display_progress=True, \n",
    "                              display_table=0, \n",
    "                              provide_traceback=True)\n",
    "\n",
    "eval_score = evaluate_llm_judge(llm_judge_1, num_threads=1)\n",
    "print(f\"------------- Final DSPy Evaluation score :::: {eval_score} ---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c18106c-7d4a-45ed-a8cc-3c93e786bed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4813"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_score_1 = eval_score/100\n",
    "sft_score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eab3061",
   "metadata": {},
   "source": [
    "Evaluation scores for DPO results by LLM-judge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a24ece8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 1.0|1 : 1.0|2 : 0.2|3 : 0.2|4 : 0.9|5 : 1.0|6 : 0.2|7 : 1.0|8 : 0.2|9 : 0.2|10 : 1.0|11 : 1.0|12 : 1.0|13 : 0.2|14 : 1.0|15 : 1.0|16 : 1.0|17 : 0.0|18 : 0.1|19 : 0.1|20 : 1.0|21 : 0.9|22 : 0.9|23 : 1.0|24 : 1.0|25 : 0.3|26 : 0.1|27 : 0.2|28 : 1.0|29 : 0.9|30 : 1.0|31 : 1.0|"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.675"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_score_1 = get_judge_score_1(df_dpo_data)\n",
    "dpo_score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd98ee77",
   "metadata": {},
   "source": [
    "Evaluation scores for DPO results by LLM-judge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "861bd7ca-1da2-4aed-b84a-667721fc695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = 1.0\n",
      "Average Metric: 1.00 / 32 (3.1%):   3%|▎         | 1/32 [00:01<00:42,  1.38s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 2.00 / 32 (6.2%):   6%|▋         | 2/32 [00:02<00:42,  1.40s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 2.20 / 32 (6.9%):   9%|▉         | 3/32 [00:04<00:42,  1.46s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 2.40 / 32 (7.5%):  12%|█▎        | 4/32 [00:05<00:38,  1.38s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 3.30 / 32 (10.3%):  16%|█▌        | 5/32 [00:09<01:00,  2.24s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 4.30 / 32 (13.4%):  19%|█▉        | 6/32 [00:11<01:01,  2.38s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 4.50 / 32 (14.1%):  22%|██▏       | 7/32 [00:13<00:52,  2.09s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 5.50 / 32 (17.2%):  25%|██▌       | 8/32 [00:15<00:51,  2.14s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 5.70 / 32 (17.8%):  28%|██▊       | 9/32 [00:18<00:52,  2.30s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 5.90 / 32 (18.4%):  31%|███▏      | 10/32 [00:21<00:53,  2.44s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 6.90 / 32 (21.6%):  34%|███▍      | 11/32 [00:23<00:47,  2.28s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 7.90 / 32 (24.7%):  38%|███▊      | 12/32 [00:25<00:49,  2.47s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 8.90 / 32 (27.8%):  41%|████      | 13/32 [00:28<00:50,  2.63s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 9.10 / 32 (28.4%):  44%|████▍     | 14/32 [00:30<00:42,  2.33s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 10.10 / 32 (31.6%):  47%|████▋     | 15/32 [00:32<00:39,  2.31s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 11.00 / 32 (34.4%):  50%|█████     | 16/32 [00:35<00:38,  2.39s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 12.00 / 32 (37.5%):  53%|█████▎    | 17/32 [00:37<00:32,  2.16s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 12.00 / 32 (37.5%):  56%|█████▋    | 18/32 [00:39<00:32,  2.29s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 12.10 / 32 (37.8%):  59%|█████▉    | 19/32 [00:41<00:28,  2.19s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 12.20 / 32 (38.1%):  62%|██████▎   | 20/32 [00:44<00:27,  2.30s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 13.20 / 32 (41.2%):  66%|██████▌   | 21/32 [00:46<00:26,  2.38s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 14.10 / 32 (44.1%):  69%|██████▉   | 22/32 [00:49<00:25,  2.55s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 15.00 / 32 (46.9%):  72%|███████▏  | 23/32 [00:52<00:23,  2.66s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 16.00 / 32 (50.0%):  75%|███████▌  | 24/32 [00:55<00:22,  2.77s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 17.00 / 32 (53.1%):  78%|███████▊  | 25/32 [00:57<00:16,  2.42s/it]llm_judge_ans = 0.3\n",
      "Average Metric: 17.30 / 32 (54.1%):  81%|████████▏ | 26/32 [00:59<00:15,  2.50s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 17.40 / 32 (54.4%):  84%|████████▍ | 27/32 [01:02<00:12,  2.58s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 17.60 / 32 (55.0%):  88%|████████▊ | 28/32 [01:05<00:09,  2.49s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 18.60 / 32 (58.1%):  91%|█████████ | 29/32 [01:08<00:08,  2.73s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 19.50 / 32 (60.9%):  94%|█████████▍| 30/32 [01:10<00:04,  2.48s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 20.50 / 32 (64.1%):  97%|█████████▋| 31/32 [01:11<00:02,  2.20s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 21.50 / 32 (67.2%): 100%|██████████| 32/32 [01:13<00:00,  2.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 03:05:04 INFO dspy.evaluate.evaluate: Average Metric: 21.5 / 32 (67.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Final DSPy Evaluation score :::: 67.19 ---------\n"
     ]
    }
   ],
   "source": [
    "evaluate_llm_judge = Evaluate(devset=generate_dspy_example_dataset(df_dpo_data), \n",
    "                              metric=metric_LLM_1, \n",
    "                              num_threads=1, \n",
    "                              display_progress=True, \n",
    "                              display_table=0, \n",
    "                              provide_traceback=True)\n",
    "\n",
    "eval_score = evaluate_llm_judge(llm_judge_1, num_threads=1)\n",
    "print(f\"------------- Final DSPy Evaluation score :::: {eval_score} ---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "875a7e9c-18b5-44db-9f0a-f2a3151a98e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6718999999999999"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_score_1 = eval_score/100\n",
    "dpo_score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae572ca6",
   "metadata": {},
   "source": [
    "Evaluation scores for ORPO results by LLM-judge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8dd84a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 1.0|1 : 1.0|2 : 0.2|3 : 0.2|4 : 0.9|5 : 1.0|6 : 0.2|7 : 1.0|8 : 0.2|9 : 0.2|10 : 1.0|11 : 1.0|12 : 0.9|13 : 0.2|14 : 1.0|15 : 0.9|16 : 1.0|17 : 0.0|18 : 0.1|19 : 0.1|20 : 1.0|21 : 0.9|22 : 0.9|23 : 1.0|24 : 1.0|25 : 0.8|26 : 0.0|27 : 0.2|28 : 1.0|29 : 0.9|30 : 1.0|31 : 1.0|"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6812499999999999"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orpo_score_1 = get_judge_score_1(df_orpo_data)\n",
    "orpo_score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a51dcf",
   "metadata": {},
   "source": [
    "Evaluation scores for ORPO results by dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f40dbfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = 1.0\n",
      "Average Metric: 1.00 / 32 (3.1%):   3%|▎         | 1/32 [00:02<01:07,  2.17s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 2.00 / 32 (6.2%):   6%|▋         | 2/32 [00:04<01:04,  2.13s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 2.20 / 32 (6.9%):   9%|▉         | 3/32 [00:06<00:56,  1.95s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 2.40 / 32 (7.5%):  12%|█▎        | 4/32 [00:07<00:45,  1.64s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 3.30 / 32 (10.3%):  16%|█▌        | 5/32 [00:08<00:45,  1.68s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 4.30 / 32 (13.4%):  19%|█▉        | 6/32 [00:10<00:44,  1.70s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 4.50 / 32 (14.1%):  22%|██▏       | 7/32 [00:12<00:41,  1.68s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 5.50 / 32 (17.2%):  25%|██▌       | 8/32 [00:14<00:40,  1.69s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 5.70 / 32 (17.8%):  28%|██▊       | 9/32 [00:16<00:47,  2.06s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 5.90 / 32 (18.4%):  31%|███▏      | 10/32 [00:20<00:54,  2.48s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 6.90 / 32 (21.6%):  34%|███▍      | 11/32 [00:22<00:50,  2.39s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 7.90 / 32 (24.7%):  38%|███▊      | 12/32 [00:25<00:49,  2.48s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 8.80 / 32 (27.5%):  41%|████      | 13/32 [00:27<00:46,  2.42s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 9.00 / 32 (28.1%):  44%|████▍     | 14/32 [00:29<00:40,  2.27s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 10.00 / 32 (31.2%):  47%|████▋     | 15/32 [00:32<00:45,  2.66s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 10.90 / 32 (34.1%):  50%|█████     | 16/32 [00:36<00:44,  2.78s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 11.90 / 32 (37.2%):  53%|█████▎    | 17/32 [00:37<00:37,  2.49s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 11.90 / 32 (37.2%):  56%|█████▋    | 18/32 [00:39<00:31,  2.24s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 12.00 / 32 (37.5%):  59%|█████▉    | 19/32 [00:41<00:29,  2.25s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 12.10 / 32 (37.8%):  62%|██████▎   | 20/32 [00:44<00:28,  2.34s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 13.10 / 32 (40.9%):  66%|██████▌   | 21/32 [00:46<00:25,  2.36s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 14.00 / 32 (43.8%):  69%|██████▉   | 22/32 [00:48<00:22,  2.22s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 14.90 / 32 (46.6%):  72%|███████▏  | 23/32 [00:51<00:21,  2.35s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 15.90 / 32 (49.7%):  75%|███████▌  | 24/32 [00:53<00:19,  2.41s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 16.90 / 32 (52.8%):  78%|███████▊  | 25/32 [00:55<00:15,  2.25s/it]llm_judge_ans = 0.8\n",
      "Average Metric: 17.70 / 32 (55.3%):  81%|████████▏ | 26/32 [00:59<00:16,  2.67s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 17.70 / 32 (55.3%):  84%|████████▍ | 27/32 [01:02<00:13,  2.71s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 17.90 / 32 (55.9%):  88%|████████▊ | 28/32 [01:03<00:09,  2.40s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 18.90 / 32 (59.1%):  91%|█████████ | 29/32 [01:06<00:07,  2.44s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 19.80 / 32 (61.9%):  94%|█████████▍| 30/32 [01:09<00:05,  2.58s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 20.80 / 32 (65.0%):  97%|█████████▋| 31/32 [01:11<00:02,  2.51s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 21.80 / 32 (68.1%): 100%|██████████| 32/32 [01:13<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 03:06:56 INFO dspy.evaluate.evaluate: Average Metric: 21.799999999999997 / 32 (68.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Final DSPy Evaluation score :::: 68.12 ---------\n"
     ]
    }
   ],
   "source": [
    "evaluate_llm_judge = Evaluate(devset=generate_dspy_example_dataset(df_orpo_data), \n",
    "                              metric=metric_LLM_1, \n",
    "                              num_threads=1, \n",
    "                              display_progress=True, \n",
    "                              display_table=0, \n",
    "                              provide_traceback=True)\n",
    "\n",
    "eval_score = evaluate_llm_judge(llm_judge_1, num_threads=1)\n",
    "print(f\"------------- Final DSPy Evaluation score :::: {eval_score} ---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fd5db4ef-0941-4985-afe7-07d81b3f219e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6812"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orpo_score_1 = eval_score/100\n",
    "orpo_score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba86b22b",
   "metadata": {},
   "source": [
    "Evaluation scores for RAG HAIKU results by LLM-judge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa00992a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.1|1 : 1.0|2 : 0.1|3 : 0.1|4 : 0.5|5 : 0.9|6 : 0.2|7 : 1.0|8 : 0.3|9 : 0.3|10 : 0.1|11 : 0.1|12 : 0.9|13 : 0.0|14 : 0.2|15 : 0.9|16 : 0.9|17 : 0.5|18 : 0.1|19 : 0.1|20 : 0.2|21 : 0.4|22 : 0.1|23 : 0.6|24 : 0.7|25 : 0.8|26 : 0.3|27 : 0.1|28 : 0.6|29 : 0.5|30 : 0.2|31 : 0.0|"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39999999999999997"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_haiku_score_1 = get_judge_score_1(df_rag_haiku_data)\n",
    "rag_haiku_score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b8b4f3",
   "metadata": {},
   "source": [
    "Evaluation scores for RAG HAIKU results by dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bab1f187-d865-47e1-bc83-0fb439a65d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = 0.1\n",
      "Average Metric: 0.10 / 32 (0.3%):   3%|▎         | 1/32 [00:03<01:54,  3.70s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 1.10 / 32 (3.4%):   6%|▋         | 2/32 [00:07<01:46,  3.55s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 1.20 / 32 (3.8%):   9%|▉         | 3/32 [00:09<01:21,  2.81s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 1.30 / 32 (4.1%):  12%|█▎        | 4/32 [00:11<01:17,  2.76s/it]llm_judge_ans = 0.5\n",
      "Average Metric: 1.80 / 32 (5.6%):  16%|█▌        | 5/32 [00:14<01:12,  2.67s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 2.70 / 32 (8.4%):  19%|█▉        | 6/32 [00:16<01:07,  2.60s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 2.90 / 32 (9.1%):  22%|██▏       | 7/32 [00:20<01:13,  2.92s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 3.90 / 32 (12.2%):  25%|██▌       | 8/32 [00:23<01:09,  2.89s/it]llm_judge_ans = 0.3\n",
      "Average Metric: 4.20 / 32 (13.1%):  28%|██▊       | 9/32 [00:26<01:10,  3.05s/it]llm_judge_ans = 0.3\n",
      "Average Metric: 4.50 / 32 (14.1%):  31%|███▏      | 10/32 [00:29<01:03,  2.89s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 4.60 / 32 (14.4%):  34%|███▍      | 11/32 [00:31<00:55,  2.66s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 4.70 / 32 (14.7%):  38%|███▊      | 12/32 [00:34<00:54,  2.73s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 5.60 / 32 (17.5%):  41%|████      | 13/32 [00:37<00:53,  2.84s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 5.60 / 32 (17.5%):  44%|████▍     | 14/32 [00:39<00:45,  2.53s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 5.80 / 32 (18.1%):  47%|████▋     | 15/32 [00:41<00:45,  2.65s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 6.70 / 32 (20.9%):  50%|█████     | 16/32 [00:44<00:43,  2.72s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 7.60 / 32 (23.8%):  53%|█████▎    | 17/32 [00:46<00:38,  2.56s/it]llm_judge_ans = 0.5\n",
      "Average Metric: 8.10 / 32 (25.3%):  56%|█████▋    | 18/32 [00:48<00:30,  2.21s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 8.20 / 32 (25.6%):  59%|█████▉    | 19/32 [00:50<00:29,  2.26s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 8.30 / 32 (25.9%):  62%|██████▎   | 20/32 [00:53<00:27,  2.26s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 8.50 / 32 (26.6%):  66%|██████▌   | 21/32 [00:56<00:27,  2.50s/it]llm_judge_ans = 0.4\n",
      "Average Metric: 8.90 / 32 (27.8%):  69%|██████▉   | 22/32 [01:00<00:29,  2.93s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 9.00 / 32 (28.1%):  72%|███████▏  | 23/32 [01:03<00:27,  3.04s/it]llm_judge_ans = 0.6\n",
      "Average Metric: 9.60 / 32 (30.0%):  75%|███████▌  | 24/32 [01:06<00:23,  2.99s/it]llm_judge_ans = 0.7\n",
      "Average Metric: 10.30 / 32 (32.2%):  78%|███████▊  | 25/32 [01:09<00:20,  2.97s/it]llm_judge_ans = 0.8\n",
      "Average Metric: 11.10 / 32 (34.7%):  81%|████████▏ | 26/32 [01:11<00:16,  2.79s/it]llm_judge_ans = 0.3\n",
      "Average Metric: 11.40 / 32 (35.6%):  84%|████████▍ | 27/32 [01:14<00:14,  2.82s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 11.50 / 32 (35.9%):  88%|████████▊ | 28/32 [01:16<00:10,  2.61s/it]llm_judge_ans = 0.8\n",
      "Average Metric: 12.30 / 32 (38.4%):  91%|█████████ | 29/32 [01:19<00:08,  2.74s/it]llm_judge_ans = 0.6\n",
      "Average Metric: 12.90 / 32 (40.3%):  94%|█████████▍| 30/32 [01:22<00:05,  2.66s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 13.10 / 32 (40.9%):  97%|█████████▋| 31/32 [01:23<00:02,  2.41s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 13.10 / 32 (40.9%): 100%|██████████| 32/32 [01:26<00:00,  2.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 03:09:02 INFO dspy.evaluate.evaluate: Average Metric: 13.1 / 32 (40.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Final DSPy Evaluation score :::: 40.94 ---------\n"
     ]
    }
   ],
   "source": [
    "evaluate_llm_judge = Evaluate(devset=generate_dspy_example_dataset(df_rag_haiku_data), \n",
    "                              metric=metric_LLM_1, \n",
    "                              num_threads=1, \n",
    "                              display_progress=True, \n",
    "                              display_table=0, \n",
    "                              provide_traceback=True)\n",
    "\n",
    "eval_score = evaluate_llm_judge(llm_judge_1, num_threads=1)\n",
    "print(f\"------------- Final DSPy Evaluation score :::: {eval_score} ---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea3942dd-8a2e-4948-a4ee-ad17cb4c530f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4094"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_haiku_score_1 = eval_score/100\n",
    "rag_haiku_score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81bf4ad",
   "metadata": {},
   "source": [
    "Evaluation scores for RAG compiled HAIKU results by LLM-judge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "acc77eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.2|1 : 1.0|2 : 1.0|3 : 1.0|4 : 0.5|5 : 0.9|6 : 0.9|7 : 0.9|8 : 0.8|9 : 0.6|10 : 0.1|11 : 0.2|12 : 0.9|13 : 1.0|14 : 0.2|15 : 0.8|16 : 0.8|17 : 0.9|18 : 0.0|19 : 0.2|20 : 0.9|21 : 0.3|22 : 0.9|23 : 0.5|24 : 0.9|25 : 0.8|26 : 0.7|27 : 0.0|28 : 0.8|29 : 0.8|30 : 0.9|31 : 0.9|"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.665625"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragc_haiku_score_1 = get_judge_score_1(df_ragc_haiku_data)\n",
    "ragc_haiku_score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fcf4c2",
   "metadata": {},
   "source": [
    "Evaluation scores for RAG compiled HAIKU results by dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d0edbc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = 0.2\n",
      "Average Metric: 0.20 / 32 (0.6%):   3%|▎         | 1/32 [00:01<00:46,  1.50s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 1.20 / 32 (3.8%):   6%|▋         | 2/32 [00:03<00:50,  1.68s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 2.20 / 32 (6.9%):   9%|▉         | 3/32 [00:04<00:41,  1.43s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 3.20 / 32 (10.0%):  12%|█▎        | 4/32 [00:06<00:42,  1.53s/it]llm_judge_ans = 0.5\n",
      "Average Metric: 3.70 / 32 (11.6%):  16%|█▌        | 5/32 [00:08<00:46,  1.73s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 4.60 / 32 (14.4%):  19%|█▉        | 6/32 [00:10<00:50,  1.94s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 5.50 / 32 (17.2%):  22%|██▏       | 7/32 [00:13<00:52,  2.12s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 6.40 / 32 (20.0%):  25%|██▌       | 8/32 [00:15<00:50,  2.11s/it]llm_judge_ans = 0.8\n",
      "Average Metric: 7.20 / 32 (22.5%):  28%|██▊       | 9/32 [00:18<00:58,  2.53s/it]llm_judge_ans = 0.6\n",
      "Average Metric: 7.80 / 32 (24.4%):  31%|███▏      | 10/32 [00:20<00:49,  2.25s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 7.90 / 32 (24.7%):  34%|███▍      | 11/32 [00:22<00:47,  2.26s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 8.10 / 32 (25.3%):  38%|███▊      | 12/32 [00:24<00:43,  2.17s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 9.00 / 32 (28.1%):  41%|████      | 13/32 [00:26<00:42,  2.26s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 10.00 / 32 (31.2%):  44%|████▍     | 14/32 [00:29<00:41,  2.32s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 10.20 / 32 (31.9%):  47%|████▋     | 15/32 [00:31<00:39,  2.31s/it]llm_judge_ans = 0.8\n",
      "Average Metric: 11.00 / 32 (34.4%):  50%|█████     | 16/32 [00:34<00:41,  2.57s/it]llm_judge_ans = 0.8\n",
      "Average Metric: 11.80 / 32 (36.9%):  53%|█████▎    | 17/32 [00:37<00:37,  2.53s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 12.70 / 32 (39.7%):  56%|█████▋    | 18/32 [00:38<00:31,  2.27s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 12.70 / 32 (39.7%):  59%|█████▉    | 19/32 [00:40<00:27,  2.08s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 12.90 / 32 (40.3%):  62%|██████▎   | 20/32 [00:42<00:23,  1.99s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 13.80 / 32 (43.1%):  66%|██████▌   | 21/32 [00:45<00:26,  2.39s/it]llm_judge_ans = 0.3\n",
      "Average Metric: 14.10 / 32 (44.1%):  69%|██████▉   | 22/32 [00:47<00:22,  2.27s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 15.00 / 32 (46.9%):  72%|███████▏  | 23/32 [00:50<00:22,  2.48s/it]llm_judge_ans = 0.5\n",
      "Average Metric: 15.50 / 32 (48.4%):  75%|███████▌  | 24/32 [00:51<00:17,  2.14s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 16.40 / 32 (51.3%):  78%|███████▊  | 25/32 [00:55<00:17,  2.49s/it]llm_judge_ans = 0.8\n",
      "Average Metric: 17.20 / 32 (53.8%):  81%|████████▏ | 26/32 [00:57<00:14,  2.38s/it]llm_judge_ans = 0.7\n",
      "Average Metric: 17.90 / 32 (55.9%):  84%|████████▍ | 27/32 [00:59<00:12,  2.42s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 17.90 / 32 (55.9%):  88%|████████▊ | 28/32 [01:02<00:09,  2.46s/it]llm_judge_ans = 0.8\n",
      "Average Metric: 18.70 / 32 (58.4%):  91%|█████████ | 29/32 [01:03<00:06,  2.18s/it]llm_judge_ans = 0.8\n",
      "Average Metric: 19.50 / 32 (60.9%):  94%|█████████▍| 30/32 [01:06<00:04,  2.19s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 20.40 / 32 (63.8%):  97%|█████████▋| 31/32 [01:07<00:01,  1.92s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 21.30 / 32 (66.6%): 100%|██████████| 32/32 [01:10<00:00,  2.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 03:10:48 INFO dspy.evaluate.evaluate: Average Metric: 21.3 / 32 (66.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Final DSPy Evaluation score :::: 66.56 ---------\n"
     ]
    }
   ],
   "source": [
    "evaluate_llm_judge = Evaluate(devset=generate_dspy_example_dataset(df_ragc_haiku_data), \n",
    "                              metric=metric_LLM_1, \n",
    "                              num_threads=1, \n",
    "                              display_progress=True, \n",
    "                              display_table=0, \n",
    "                              provide_traceback=True)\n",
    "\n",
    "eval_score = evaluate_llm_judge(llm_judge_1, num_threads=1)\n",
    "print(f\"------------- Final DSPy Evaluation score :::: {eval_score} ---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f473a6c-bce7-4b50-922a-536a94a283b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6656"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragc_haiku_score_1 = eval_score/100\n",
    "ragc_haiku_score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b404713c",
   "metadata": {},
   "source": [
    "Evaluation scores for RAG Sonnet results by LLM-judge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec0181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.2|1 : 0.9|2 : 0.2|3 : 0.1|4 : 0.5|5 : 0.2|6 : 0.2|7 : 0.9|8 : 0.2|9 : 0.5|10 : 0.0|11 : 0.2|12 : 0.0|13 : 0.5|14 : 0.2|15 : 0.2|16 : 0.8|17 : 0.0|18 : 0.0|19 : 0.2|20 : 0.2|21 : 0.5|22 : 0.1|23 : 0.2|24 : 0.2|25 : 0.2|26 : 0.8|27 : 0.0|28 : 0.2|29 : 0.2|30 : 1.0|31 : 0.2|"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30624999999999997"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_sonnet_score_1 = get_judge_score_1(df_rag_sonnet_data)\n",
    "rag_sonnet_score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709d3d0",
   "metadata": {},
   "source": [
    "Evaluation scores for RAG Sonnet results by dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0d417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = 0.2\n",
      "Average Metric: 0.20 / 32 (0.6%):   3%|▎         | 1/32 [00:02<01:03,  2.04s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 1.10 / 32 (3.4%):   6%|▋         | 2/32 [00:03<00:54,  1.82s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 1.30 / 32 (4.1%):   9%|▉         | 3/32 [00:05<00:50,  1.75s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 1.40 / 32 (4.4%):  12%|█▎        | 4/32 [00:06<00:45,  1.61s/it]llm_judge_ans = 0.5\n",
      "Average Metric: 1.90 / 32 (5.9%):  16%|█▌        | 5/32 [00:08<00:43,  1.61s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 2.10 / 32 (6.6%):  19%|█▉        | 6/32 [00:10<00:43,  1.67s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 2.30 / 32 (7.2%):  22%|██▏       | 7/32 [00:11<00:40,  1.62s/it]llm_judge_ans = 0.8\n",
      "Average Metric: 3.10 / 32 (9.7%):  25%|██▌       | 8/32 [00:13<00:38,  1.60s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 3.30 / 32 (10.3%):  28%|██▊       | 9/32 [00:15<00:42,  1.83s/it]llm_judge_ans = 0.5\n",
      "Average Metric: 3.80 / 32 (11.9%):  31%|███▏      | 10/32 [00:18<00:45,  2.06s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 3.80 / 32 (11.9%):  34%|███▍      | 11/32 [00:22<00:56,  2.68s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 4.00 / 32 (12.5%):  38%|███▊      | 12/32 [00:26<01:03,  3.16s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 4.00 / 32 (12.5%):  41%|████      | 13/32 [00:29<00:58,  3.05s/it]llm_judge_ans = 0.5\n",
      "Average Metric: 4.50 / 32 (14.1%):  44%|████▍     | 14/32 [00:31<00:50,  2.81s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 4.70 / 32 (14.7%):  47%|████▋     | 15/32 [00:33<00:42,  2.48s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 4.90 / 32 (15.3%):  50%|█████     | 16/32 [00:36<00:41,  2.62s/it]llm_judge_ans = 0.8\n",
      "Average Metric: 5.70 / 32 (17.8%):  53%|█████▎    | 17/32 [00:38<00:36,  2.40s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 5.70 / 32 (17.8%):  56%|█████▋    | 18/32 [00:39<00:29,  2.12s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 5.70 / 32 (17.8%):  59%|█████▉    | 19/32 [00:42<00:29,  2.25s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 5.90 / 32 (18.4%):  62%|██████▎   | 20/32 [00:43<00:25,  2.09s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 6.10 / 32 (19.1%):  66%|██████▌   | 21/32 [00:47<00:28,  2.55s/it]llm_judge_ans = 0.5\n",
      "Average Metric: 6.60 / 32 (20.6%):  69%|██████▉   | 22/32 [00:51<00:28,  2.88s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 6.70 / 32 (20.9%):  72%|███████▏  | 23/32 [00:53<00:23,  2.66s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 6.90 / 32 (21.6%):  75%|███████▌  | 24/32 [00:55<00:20,  2.56s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 7.10 / 32 (22.2%):  78%|███████▊  | 25/32 [00:57<00:16,  2.36s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 7.30 / 32 (22.8%):  81%|████████▏ | 26/32 [01:00<00:15,  2.57s/it]llm_judge_ans = 0.8\n",
      "Average Metric: 8.10 / 32 (25.3%):  84%|████████▍ | 27/32 [01:03<00:12,  2.55s/it]llm_judge_ans = 0.0\n",
      "Average Metric: 8.10 / 32 (25.3%):  88%|████████▊ | 28/32 [01:04<00:09,  2.36s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 8.30 / 32 (25.9%):  91%|█████████ | 29/32 [01:06<00:06,  2.16s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 8.50 / 32 (26.6%):  94%|█████████▍| 30/32 [01:08<00:04,  2.14s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 9.50 / 32 (29.7%):  97%|█████████▋| 31/32 [01:10<00:01,  1.89s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 9.70 / 32 (30.3%): 100%|██████████| 32/32 [01:11<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 03:12:33 INFO dspy.evaluate.evaluate: Average Metric: 9.7 / 32 (30.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Final DSPy Evaluation score :::: 30.31 ---------\n"
     ]
    }
   ],
   "source": [
    "evaluate_llm_judge = Evaluate(devset=generate_dspy_example_dataset(df_rag_sonnet_data), \n",
    "                              metric=metric_LLM_1, \n",
    "                              num_threads=1, \n",
    "                              display_progress=True, \n",
    "                              display_table=0, \n",
    "                              provide_traceback=True)\n",
    "\n",
    "eval_score = evaluate_llm_judge(llm_judge_1, num_threads=1)\n",
    "print(f\"------------- Final DSPy Evaluation score :::: {eval_score} ---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d496d6b6-0c23-4924-9ff1-b29dc781a69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3031"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_sonnet_score_1 = eval_score/100\n",
    "rag_sonnet_score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4a1e7e",
   "metadata": {},
   "source": [
    "Evaluation scores for RAG compiled Sonnet results by LLM-judge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935028e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.1|1 : 1.0|2 : 0.1|3 : 0.1|4 : 0.7|5 : 0.9|6 : 0.9|7 : 0.9|8 : 0.3|9 : 0.5|10 : 0.1|11 : 0.1|12 : 0.9|13 : 1.0|14 : 0.2|15 : 0.8|16 : 0.9|17 : 0.9|18 : 0.8|19 : 0.3|20 : 0.9|21 : 0.4|22 : 0.8|23 : 0.9|24 : 0.9|25 : 0.9|26 : 0.4|27 : 0.1|28 : 0.9|29 : 0.9|30 : 0.9|31 : 0.9|"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6375"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragc_sonnet_score_1 = get_judge_score_1(df_ragc_sonnet_data)\n",
    "ragc_sonnet_score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d0a7b4",
   "metadata": {},
   "source": [
    "Evaluation scores for RAG compiled Sonnet results by dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7846b646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]llm_judge_ans = 0.1\n",
      "Average Metric: 0.10 / 32 (0.3%):   3%|▎         | 1/32 [00:02<01:13,  2.38s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 1.10 / 32 (3.4%):   6%|▋         | 2/32 [00:04<00:59,  1.99s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 1.20 / 32 (3.8%):   9%|▉         | 3/32 [00:05<00:49,  1.69s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 1.30 / 32 (4.1%):  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]llm_judge_ans = 0.7\n",
      "Average Metric: 2.00 / 32 (6.2%):  16%|█▌        | 5/32 [00:10<00:58,  2.16s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 2.90 / 32 (9.1%):  19%|█▉        | 6/32 [00:12<01:00,  2.33s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 3.80 / 32 (11.9%):  22%|██▏       | 7/32 [00:15<00:56,  2.26s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 4.70 / 32 (14.7%):  25%|██▌       | 8/32 [00:17<00:54,  2.29s/it]llm_judge_ans = 0.3\n",
      "Average Metric: 5.00 / 32 (15.6%):  28%|██▊       | 9/32 [00:20<00:56,  2.44s/it]llm_judge_ans = 0.5\n",
      "Average Metric: 5.50 / 32 (17.2%):  31%|███▏      | 10/32 [00:22<00:55,  2.53s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 5.60 / 32 (17.5%):  34%|███▍      | 11/32 [00:25<00:56,  2.68s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 5.70 / 32 (17.8%):  38%|███▊      | 12/32 [00:29<00:57,  2.90s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 6.60 / 32 (20.6%):  41%|████      | 13/32 [00:31<00:48,  2.57s/it]llm_judge_ans = 1.0\n",
      "Average Metric: 7.60 / 32 (23.8%):  44%|████▍     | 14/32 [00:34<00:48,  2.70s/it]llm_judge_ans = 0.2\n",
      "Average Metric: 7.80 / 32 (24.4%):  47%|████▋     | 15/32 [00:36<00:45,  2.70s/it]llm_judge_ans = 0.8\n",
      "Average Metric: 8.60 / 32 (26.9%):  50%|█████     | 16/32 [00:40<00:49,  3.08s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 9.50 / 32 (29.7%):  53%|█████▎    | 17/32 [00:43<00:43,  2.90s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 10.40 / 32 (32.5%):  56%|█████▋    | 18/32 [00:46<00:40,  2.87s/it]llm_judge_ans = 0.8\n",
      "Average Metric: 11.20 / 32 (35.0%):  59%|█████▉    | 19/32 [00:49<00:39,  3.06s/it]llm_judge_ans = 0.3\n",
      "Average Metric: 11.50 / 32 (35.9%):  62%|██████▎   | 20/32 [00:51<00:34,  2.85s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 12.40 / 32 (38.8%):  66%|██████▌   | 21/32 [00:55<00:33,  3.03s/it]llm_judge_ans = 0.4\n",
      "Average Metric: 12.80 / 32 (40.0%):  69%|██████▉   | 22/32 [01:01<00:38,  3.84s/it]llm_judge_ans = 0.8\n",
      "Average Metric: 13.60 / 32 (42.5%):  72%|███████▏  | 23/32 [01:05<00:35,  3.89s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 14.50 / 32 (45.3%):  75%|███████▌  | 24/32 [01:08<00:29,  3.63s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 15.40 / 32 (48.1%):  78%|███████▊  | 25/32 [01:11<00:24,  3.53s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 16.30 / 32 (50.9%):  81%|████████▏ | 26/32 [01:14<00:19,  3.30s/it]llm_judge_ans = 0.4\n",
      "Average Metric: 16.70 / 32 (52.2%):  84%|████████▍ | 27/32 [01:19<00:19,  3.84s/it]llm_judge_ans = 0.1\n",
      "Average Metric: 16.80 / 32 (52.5%):  88%|████████▊ | 28/32 [01:22<00:14,  3.71s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 17.70 / 32 (55.3%):  91%|█████████ | 29/32 [01:25<00:10,  3.58s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 18.60 / 32 (58.1%):  94%|█████████▍| 30/32 [01:30<00:07,  3.75s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 19.50 / 32 (60.9%):  97%|█████████▋| 31/32 [01:32<00:03,  3.46s/it]llm_judge_ans = 0.9\n",
      "Average Metric: 20.40 / 32 (63.7%): 100%|██████████| 32/32 [01:35<00:00,  2.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 03:14:44 INFO dspy.evaluate.evaluate: Average Metric: 20.4 / 32 (63.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Final DSPy Evaluation score :::: 63.75 ---------\n"
     ]
    }
   ],
   "source": [
    "evaluate_llm_judge = Evaluate(devset=generate_dspy_example_dataset(df_ragc_sonnet_data), \n",
    "                              metric=metric_LLM_1, \n",
    "                              num_threads=1, \n",
    "                              display_progress=True, \n",
    "                              display_table=0, \n",
    "                              provide_traceback=True)\n",
    "\n",
    "eval_score = evaluate_llm_judge(llm_judge_1, num_threads=1)\n",
    "print(f\"------------- Final DSPy Evaluation score :::: {eval_score} ---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cdefe6-f938-400c-8a1e-cff14807ad49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6375"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragc_sonnet_score_1 = eval_score/100\n",
    "ragc_sonnet_score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f9c3b",
   "metadata": {},
   "source": [
    "### Benchmarking the performance across RAG with foundation models and fine-tuned models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3660bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_class_type = ['RAG_Haiku','RAG_Haiku_Compiled','SFT(Llama3-8B)','DPO(Llama3-8B)','ORPO(Llama3-8B)']\n",
    "train_class_count = [rag_haiku_score_1,ragc_haiku_score_1,sft_score_1,dpo_score_1,orpo_score_1,]\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "\n",
    "# creating the bar plot\n",
    "plt.bar(train_class_type, train_class_count, color ='green', width = 0.4)\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy by LLM-as-a-judge (Score 0~1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13794f37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
