{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b5e70f0",
   "metadata": {},
   "source": [
    "## RAG and prompt automation in dspy - batch invocation    \n",
    "\n",
    "In this notebook, we conduct batch invocation on RAG pipeline defined by dspy, and generate dataset for benchmarking in the notebook dspy_rag_ft.ipynb. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a83a15",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17544499-79b4-40ec-8ccb-6dfd29fd0e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install dspy pypdf chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8dc840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys\n",
    "import io, base64\n",
    "import logging\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "import dspy\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91d0d213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "session = boto3.Session()\n",
    "boto_session = boto3.session.Session()\n",
    "region_name = boto_session.region_name\n",
    "print(region_name)\n",
    "\n",
    "bedrock = session.client(\"bedrock\", region_name=region_name)\n",
    "br = session.client(\"bedrock-runtime\", region_name=region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5780fa",
   "metadata": {},
   "source": [
    "### DSPy Language Model and Retriever Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aef97f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_sonnet_model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "clade_haiku_model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "llama_model_id = \"meta.llama3-8b-instruct-v1:0\"\n",
    "titan_embed_model_id = \"amazon.titan-embed-text-v2:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c10beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp_bedrock = dspy.Bedrock(region_name=region_name)\n",
    "\n",
    "bedrock_sonnet = dspy.AWSAnthropic(aws_provider=dsp_bedrock,\n",
    "                                  model=claude_sonnet_model_id,\n",
    "                                  max_new_tokens=4096,\n",
    "                                  max_tokens=4096)\n",
    "\n",
    "bedrock_haiku = dspy.AWSAnthropic(aws_provider=dsp_bedrock,\n",
    "                                 model=clade_haiku_model_id,\n",
    "                                 max_new_tokens=4096,\n",
    "                                 max_tokens=4096)\n",
    "\n",
    "bedrock_llama = dspy.AWSMeta(aws_provider=dsp_bedrock, \n",
    "                             model=llama_model_id, \n",
    "                             #max_new_tokens=2048,\n",
    "                             #max_tokens=2048\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b29ae8",
   "metadata": {},
   "source": [
    "### Splitters and chunking configuration    \n",
    "\n",
    "We will be using the RecursiveCharacterTextSplitter to generate logical and syntactically readable chunks. The size and overlap percentage can be empirically determined based on the dataset. For more flexibility it is possible to generate multiple files from the dataset file and make 1 file 1 chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81f46be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load documents \n",
    "loader = PyPDFLoader(\"../cuad_data/CUAD_v1/full_contract_pdf/Part_I/Strategic Alliance//ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALLIANCE AGREEMENT.PDF\")\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "# Split documents by setting chunk size\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \" \",\n",
    "        \".\",\n",
    "        \",\",\n",
    "        \"\\u200b\",  # Zero-width space\n",
    "        \"\\uff0c\",  # Fullwidth comma\n",
    "        \"\\u3001\",  # Ideographic comma\n",
    "        \"\\uff0e\",  # Fullwidth full stop\n",
    "        \"\\u3002\",  # Ideographic full stop\n",
    "        \"\",\n",
    "    ],\n",
    "    chunk_size = 5000, #5000(25)     \n",
    "    chunk_overlap = 30, #20 (25)\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ece36d5",
   "metadata": {},
   "source": [
    "### Clean and remove any empty pages in the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff63a972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n",
    "clean_docs = []\n",
    "for doc in docs:\n",
    "    if len(doc.page_content):\n",
    "        clean_docs.append(doc)\n",
    "\n",
    "docs = clean_docs\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06343f5c",
   "metadata": {},
   "source": [
    "### Setup Retriever on local disk using ChromaDB    \n",
    "\n",
    "We are using chromaDB to demonstrate the use of vector databases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "407e2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.utils.embedding_functions import AmazonBedrockEmbeddingFunction\n",
    "\n",
    "bedrock_ef = AmazonBedrockEmbeddingFunction(session=session, model_name=titan_embed_model_id)\n",
    "\n",
    "bedrock_embeddings = bedrock_ef([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbfca2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "\n",
    "collection_name=\"contexts\"\n",
    "persist_dir=\"cuad_db/\"\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(persist_dir)\n",
    "collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "if collection.count() == 0:\n",
    "    collection.add(embeddings=bedrock_embeddings,\n",
    "                   documents=[doc.page_content for doc in docs],\n",
    "                   ids=[str(i) for i in range(len(docs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f559d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = ChromadbRM(collection_name=collection_name, \n",
    "                persist_directory=persist_dir, \n",
    "                embedding_function=bedrock_ef,\n",
    "                k=3)\n",
    "\n",
    "dspy.settings.configure(rm=rm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc05161",
   "metadata": {},
   "source": [
    "### Dataset setup in DSPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b296f99",
   "metadata": {},
   "source": [
    "Contract Understanding Atticus DatasetÂ (CUAD) is a dataset for legal contract review. CUAD was created with dozens of legal experts from The Atticus Project and consists of over 13,000 annotations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d932a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>input</th>\n",
       "      <th>answer</th>\n",
       "      <th>qa_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What is The name of the contract?</td>\n",
       "      <td>Highlight the parts (if any) of this contract ...</td>\n",
       "      <td>STRATEGIC ALLIANCE AGREEMENT</td>\n",
       "      <td>ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is The two or more parties who signed the...</td>\n",
       "      <td>Highlight the parts (if any) of this contract ...</td>\n",
       "      <td>Dialog Semiconductor (UK) Ltd., DIALOG, Energo...</td>\n",
       "      <td>ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What is The date of the contract?</td>\n",
       "      <td>Highlight the parts (if any) of this contract ...</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What is The date when the contract is effective?</td>\n",
       "      <td>Highlight the parts (if any) of this contract ...</td>\n",
       "      <td>November 6, 2016</td>\n",
       "      <td>ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>On what date will the contract's initial term ...</td>\n",
       "      <td>Highlight the parts (if any) of this contract ...</td>\n",
       "      <td>Unless earlier terminated as provided herein, ...</td>\n",
       "      <td>ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           question  \\\n",
       "0      0                  What is The name of the contract?   \n",
       "1      1  What is The two or more parties who signed the...   \n",
       "2      2                  What is The date of the contract?   \n",
       "3      3   What is The date when the contract is effective?   \n",
       "4      4  On what date will the contract's initial term ...   \n",
       "\n",
       "                                               input  \\\n",
       "0  Highlight the parts (if any) of this contract ...   \n",
       "1  Highlight the parts (if any) of this contract ...   \n",
       "2  Highlight the parts (if any) of this contract ...   \n",
       "3  Highlight the parts (if any) of this contract ...   \n",
       "4  Highlight the parts (if any) of this contract ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0                       STRATEGIC ALLIANCE AGREEMENT   \n",
       "1  Dialog Semiconductor (UK) Ltd., DIALOG, Energo...   \n",
       "2                                   November 6, 2016   \n",
       "3                                   November 6, 2016   \n",
       "4  Unless earlier terminated as provided herein, ...   \n",
       "\n",
       "                                               qa_id  \n",
       "0  ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...  \n",
       "1  ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...  \n",
       "2  ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...  \n",
       "3  ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...  \n",
       "4  ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALL...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRN_FILE = '../cuad_data/CUAD_v1/ENERGOUSCORP_qa.csv'\n",
    "df_cuad_data = pd.read_csv(TRN_FILE)\n",
    "df_cuad_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "175a1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cuad = []\n",
    "\n",
    "for index, question, input, answer, qa_id in df_cuad_data.values:\n",
    "    dataset_cuad.append(dspy.Example(question=question, answer=answer).with_inputs(\"question\"))\n",
    "\n",
    "trainset = [x.with_inputs('question') for x in dataset_cuad[0:28]]\n",
    "devset = [x.with_inputs('question') for x in dataset_cuad[28:32]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e56ec3",
   "metadata": {},
   "source": [
    "### Setup RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce8cdbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "    \n",
    "    \n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = [r for r in self.retrieve(question).passages]\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812497ab",
   "metadata": {},
   "source": [
    "### Batch Invocation on RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dd006a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_OUTPUT_FILE = 'rag_haiku_results_2.csv'\n",
    "\n",
    "dspy.settings.configure(lm=bedrock_haiku)\n",
    "rag_pipeline = RAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39fcae2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated, underperform, and are about to be deleted. ***\n",
      " \t\tYou are using the client AWSAnthropic, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0|1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|"
     ]
    }
   ],
   "source": [
    "# Batch invocation\n",
    "question_list=[]\n",
    "ref_answer_list=[]\n",
    "rag_answer_list=[]\n",
    "\n",
    "for i in range(len(dataset_cuad)):\n",
    "    print(i,end='|')\n",
    "    question_list.append(dataset_cuad[i].question)\n",
    "    ref_answer_list.append(dataset_cuad[i].answer) \n",
    "    pred = rag_pipeline(dataset_cuad[i].question)\n",
    "    rag_answer_list.append(pred.answer)\n",
    "    \n",
    "# store responses in csv \n",
    "df_response = pd.DataFrame()  \n",
    "df_response[\"question\"] = question_list\n",
    "df_response[\"ref_answer\"] = ref_answer_list\n",
    "df_response[\"response\"] = rag_answer_list\n",
    "\n",
    "df_response.to_csv(TEST_OUTPUT_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a207a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_OUTPUT_FILE = 'rag_sonnet_results_2.csv'\n",
    "\n",
    "dspy.settings.configure(lm=bedrock_sonnet)\n",
    "rag_pipeline = RAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea1f1aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0|1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|"
     ]
    }
   ],
   "source": [
    "# Batch invocation\n",
    "question_list=[]\n",
    "ref_answer_list=[]\n",
    "rag_answer_list=[]\n",
    "\n",
    "for i in range(len(dataset_cuad)):\n",
    "    print(i,end='|')\n",
    "    question_list.append(dataset_cuad[i].question)\n",
    "    ref_answer_list.append(dataset_cuad[i].answer) \n",
    "    pred = rag_pipeline(dataset_cuad[i].question)\n",
    "    rag_answer_list.append(pred.answer)\n",
    "    \n",
    "# store responses in csv \n",
    "df_response = pd.DataFrame()  \n",
    "df_response[\"question\"] = question_list\n",
    "df_response[\"ref_answer\"] = ref_answer_list\n",
    "df_response[\"response\"] = rag_answer_list\n",
    "\n",
    "df_response.to_csv(TEST_OUTPUT_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849091ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8675812f",
   "metadata": {},
   "source": [
    "### RAG Prompt Optimization by DSPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d29f39",
   "metadata": {},
   "source": [
    "Create a Factuality Judge that will adjudicate if the predicted answer factually correct to the groundtruth answer and means the same as the groundtruth answer. This is used to compile RAG in dspy to optimize the response. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f75c92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactJudge(dspy.Signature):\n",
    "    \"\"\"Judge if the predicted answer factually correct to the groundtruth answer and same as groundtruth answer. Answer either Factual[True] or Factual[False]\"\"\"\n",
    "\n",
    "    question = dspy.InputField(desc=\"Question to be answered\")\n",
    "    groundtruth_answer = dspy.InputField(desc=\"groundtruth answer for the question\")\n",
    "    predicted_answer = dspy.InputField(desc=\"predicted answer for the question\")\n",
    "    factually_correct = dspy.OutputField(desc=\"Is the predicted answer factually correct to the groundtruth answer and same as groundtruth answer ?\", prefix=\"Factual[True/False]:\")\n",
    "\n",
    "\n",
    "judge = dspy.ChainOfThought(FactJudge)\n",
    "\n",
    "\n",
    "def factuality_metric(example, pred):\n",
    "    factual = judge(question=example.question, groundtruth_answer=example.answer, predicted_answer=pred.answer) #context=pred.context, \n",
    "    #logging.info(f\"\\n factual LLM judge {factual}\")\n",
    "    #logging.info(f\"\\n example.answer {example.answer}\")\n",
    "    #logging.info(f\"\\n pred.answer {pred.answer}\")\n",
    "    llm_judge_ans = bool(\"Factual[True]\" in factual.factually_correct \n",
    "                         or '100% True' in factual.factually_correct\n",
    "                         or '100% factually correct' in factual.factually_correct\n",
    "                         or factual.factually_correct=='True') #or \"correct\" in factual.factually_correct.lower()\n",
    "    #print(f\"llm_judge_ans = {llm_judge_ans}\")\n",
    "    logging.info(f\"llm_judge_ans = {llm_judge_ans}\")\n",
    "    return llm_judge_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37a76f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "        answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "        answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "        answer_LLMJudge = factuality_metric(example, pred)\n",
    "\n",
    "        logging.info(f\"\\n example question :: {example.question} , example answer :: {example.answer} \")\n",
    "        logging.info(f\"\\n pred answer :: {pred.answer}\")\n",
    "        logging.info(f\"\\n answer_EM :: {answer_EM}, answer_PM ::{answer_PM} answer_LLMJudge :: {answer_LLMJudge}\")\n",
    "        return answer_LLMJudge or answer_EM or answer_PM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd6c53c",
   "metadata": {},
   "source": [
    "Set up a basic teleprompter, which will compile our RAG program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f33017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e270c78",
   "metadata": {},
   "source": [
    "Prepare groundtruth data as the training set for compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ca2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMP_FILE = './cuad_data/rag_compile_data.csv'\n",
    "COMP_FILE = '../cuad_data/CUAD_v1/ENERGOUSCORP_qa.csv'\n",
    "\n",
    "df_comp_data = pd.read_csv(COMP_FILE)\n",
    "df_comp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c175c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_comp = []\n",
    "\n",
    "for index,question,input,answer,qa_id in df_comp_data.values:\n",
    "    dataset_comp.append(dspy.Example(question=question, answer=answer).with_inputs(\"question\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19114a39",
   "metadata": {},
   "source": [
    "### Batch Invocation on Compiled RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9925ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_OUTPUT_FILE = 'ragc_haiku_results_2.csv'\n",
    "\n",
    "dspy.settings.configure(lm=bedrock_haiku)\n",
    "rag_pipeline = RAG()\n",
    "\n",
    "# Compile!\n",
    "compiled_rag = teleprompter.compile(rag_pipeline, trainset=dataset_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f684cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch invocation\n",
    "question_list=[]\n",
    "ref_answer_list=[]\n",
    "rag_answer_list=[]\n",
    "\n",
    "for i in range(len(dataset_cuad)):\n",
    "    print(i,end='|')\n",
    "    question_list.append(dataset_cuad[i].question)\n",
    "    ref_answer_list.append(dataset_cuad[i].answer) \n",
    "    pred = compiled_rag(dataset_cuad[i].question)\n",
    "    rag_answer_list.append(pred.answer)\n",
    "    \n",
    "# store responses in csv \n",
    "df_response = pd.DataFrame()  \n",
    "df_response[\"question\"] = question_list\n",
    "df_response[\"ref_answer\"] = ref_answer_list\n",
    "df_response[\"response\"] = rag_answer_list\n",
    "\n",
    "df_response.to_csv(TEST_OUTPUT_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cace6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_OUTPUT_FILE = 'ragc_sonnet_results_2.csv'\n",
    "\n",
    "dspy.settings.configure(lm=bedrock_sonnet)\n",
    "rag_pipeline = RAG()\n",
    "\n",
    "# Compile!\n",
    "compiled_rag = teleprompter.compile(rag_pipeline, trainset=dataset_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch invocation\n",
    "question_list=[]\n",
    "ref_answer_list=[]\n",
    "rag_answer_list=[]\n",
    "\n",
    "for i in range(len(dataset_cuad)):\n",
    "    print(i,end='|')\n",
    "    question_list.append(dataset_cuad[i].question)\n",
    "    ref_answer_list.append(dataset_cuad[i].answer) \n",
    "    pred = compiled_rag(dataset_cuad[i].question)\n",
    "    rag_answer_list.append(pred.answer)\n",
    "    \n",
    "# store responses in csv \n",
    "df_response = pd.DataFrame()  \n",
    "df_response[\"question\"] = question_list\n",
    "df_response[\"ref_answer\"] = ref_answer_list\n",
    "df_response[\"response\"] = rag_answer_list\n",
    "\n",
    "df_response.to_csv(TEST_OUTPUT_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acafd47-e9ca-43d6-97f7-8c3660bd8fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
